{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Generator for Dinosaurs\n",
    "\n",
    "### @Author : HADDOU Amine\n",
    "\n",
    "The goal of this project is to developp different neural network models to generates new dinosaur names.<br>\n",
    "The objective is to developp the following two models : \n",
    "- n-grams model language\n",
    "- a pre-trained model (from hugginface) finetuned to the project goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, BatchNormalization, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data from `data/dinos.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/dinos.txt\", names=[\"dino_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachenosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aardonyx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abdallahsaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abelisaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abrictosaurus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dino_name\n",
       "0   Aachenosaurus\n",
       "1        Aardonyx\n",
       "2  Abdallahsaurus\n",
       "3     Abelisaurus\n",
       "4   Abrictosaurus"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an overview of the imported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1536 entries, 0 to 1535\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   dino_name  1536 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 12.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring 20 random rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Avisaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>Nqwebasaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Xinjiangtitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Dongbeititan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>Thecodontosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Ohmdenosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>Magnapaulia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Gargoyleosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>Tochisaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>Lapampasaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Dakosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Epachthosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Anserimimus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Ceratonykus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>Iliosuchus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Mendozasaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Belodon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Antetonitrus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Daxiatitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>Secernosaurus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dino_name\n",
       "163          Avisaurus\n",
       "948       Nqwebasaurus\n",
       "1477     Xinjiangtitan\n",
       "400       Dongbeititan\n",
       "1361  Thecodontosaurus\n",
       "954      Ohmdenosaurus\n",
       "824        Magnapaulia\n",
       "527    Gargoyleosaurus\n",
       "1381       Tochisaurus\n",
       "749      Lapampasaurus\n",
       "355         Dakosaurus\n",
       "465     Epachthosaurus\n",
       "95         Anserimimus\n",
       "272        Ceratonykus\n",
       "650         Iliosuchus\n",
       "863      Mendozasaurus\n",
       "196            Belodon\n",
       "98        Antetonitrus\n",
       "372         Daxiatitan\n",
       "1208     Secernosaurus"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there punctuation (composed names, etc) ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No non-alphabetical characters found in the dataset\n"
     ]
    }
   ],
   "source": [
    "def print_non_alphabetical_chars(word):\n",
    "    non_alphabetical = [char for char in word if char.lower() not in \"abcdefghijklmnopqrstuvwxyz\"]\n",
    "    if non_alphabetical:\n",
    "        print(\"Non-alphabetical characters in '{}': {}\".format(word, ''.join(non_alphabetical)))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def print_non_alphabetical(data):\n",
    "    presence = False # flag to check if there are any non-alphabetical characters\n",
    "    for name in data[\"dino_name\"]:\n",
    "        if print_non_alphabetical_chars(name):\n",
    "            presence = True\n",
    "    if not presence:\n",
    "        print(\"No non-alphabetical characters found in the dataset\")\n",
    "\n",
    "print_non_alphabetical(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the data contains recurrent names ? If so, we should get rid of them later in the pre-processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in the dataset: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicates in the dataset: {}\".format(data.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore words length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average length of dino names\n",
    "avg_word_length = data[\"dino_name\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max length of dino names\n",
    "max_word_length = data[\"dino_name\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min length of dino names\n",
    "min_word_length = data[\"dino_name\"].str.len().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile of dino names\n",
    "quantile = data[\"dino_name\"].str.len().quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique dino names\n",
    "unique_dino_names = data[\"dino_name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 11.962239583333334\n",
      "Max word length: 26\n",
      "Min word length: 3\n",
      "Quantiles : {25% : 10.0, 50% : 12.0, 75% : 13.0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average word length: {avg_word_length}\")\n",
    "print(f\"Max word length: {max_word_length}\")\n",
    "print(f\"Min word length: {min_word_length}\")\n",
    "print(f\"Quantiles : {{25% : {quantile[0.25]}, 50% : {quantile[0.5]}, 75% : {quantile[0.75]}}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are interesting. Dinosaur names are, in average, very long. So, if I want to generate a name, model has to take in account enough context from previous letters to generate remaining part.\n",
    "\n",
    "My first idea for the __n_gram model__ is to select `n_gram=3`. Because, I want to catch syllables in name. In my opinion, last syllables is enough context. It corresponds to the last 3 words before the word we want to predict.<br>\n",
    "In this context, a *syllable* is defined as a sequence of three characters, usually at least the middle one is a vowel.<br>\n",
    "It seems that using trigrams (3-grams) is a good choice since many words have lengths that are multiples of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Case Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should start with lower case all letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aachenosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardonyx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dino_name\n",
       "0  aachenosaurus\n",
       "1       aardonyx"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"dino_name\"] = data[\"dino_name\"].str.lower()\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Recurrent values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to delete previous identified dublicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in dino names: 0\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset='dino_name')\n",
    "num_duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicates in dino names: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add padding at the end of worlds to regularize names' length. We will try the `n-gram` model without padding.<br>\n",
    "Maybe by adding a padding, the model will be able to learn __how__ dino names finish usally (\"aurus\", \"tor\", etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(names: list[str], max_length: int) -> list[str]:\n",
    "    padded_names = []\n",
    "    for name in names :\n",
    "        if len(name) < max_length:\n",
    "            padded_names.append(name + \"1\" * (max_length - len(name)))\n",
    "        else:\n",
    "            padded_names.append(name[:max_length])\n",
    "    return padded_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"paddded_dino_name\"] = add_padding(data[\"dino_name\"].values, max_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "      <th>paddded_dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aachenosaurus</td>\n",
       "      <td>aachenosaurus1111111111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardonyx</td>\n",
       "      <td>aardonyx111111111111111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dino_name           paddded_dino_name\n",
       "0  aachenosaurus  aachenosaurus1111111111111\n",
       "1       aardonyx  aardonyx111111111111111111"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add `0` at the start and the `1` chat added during pading will be considered as an `end` token. The `0` will be usefull at the begenning of the generation to generate a first letter. For `k-gram` model, we will adjust the names by adding `k-2`*`\"0\"` to help model learn prediction from first letter of a name.\n",
    "\n",
    "For the `1`, it will help us determine when the generation is finished. And it may help the model in *learning* how dino names end (\"tor\", \"saurus\",etc).. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_token(names: list[str], n: int) -> list[str]:\n",
    "    \"\"\"Adds start '0' token at the beginning of each name.\"\"\"\n",
    "    return [\"0\" + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "      <th>paddded_dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aachenosaurus</td>\n",
       "      <td>0aachenosaurus1111111111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardonyx</td>\n",
       "      <td>0aardonyx111111111111111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dino_name            paddded_dino_name\n",
       "0  aachenosaurus  0aachenosaurus1111111111111\n",
       "1       aardonyx  0aardonyx111111111111111111"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"paddded_dino_name\"] = add_start_token(data[\"paddded_dino_name\"].values, max_word_length)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will add more `0` at the begenning of names. This will only be usefull for **n-gram** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_token_ngram(names: list[str], ngram: int) -> list[str]:\n",
    "    \"\"\"Adds start (n-2) '0' at the beginning of each name.\"\"\"\n",
    "    # (n-2) because there is already one '0' (start token) then we add the other `0` need to make a start token\n",
    "    # n = 3, start toekn should be '00'. Because with \"00\", the model will predict the first character.\n",
    "    # n = 4, start token should be '000'  \n",
    "    if ngram < 2 :\n",
    "        return names\n",
    "    else : \n",
    "        return [\"0\" * (ngram-2) + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00aachenosaurus1111111111111', '00aardonyx111111111111111111']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple for a 3-gram model\n",
    "names = add_start_token_ngram(names = data[\"paddded_dino_name\"].values, ngram = 3)\n",
    "names[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a first function to generates a list of n-grams from a list of names at a **character** level.\n",
    "\n",
    "When building the vocabulary and tokens, we will add an `<UNK>` token that will be used for any unseen tokens or characters during generation. it is important because if the model produce a token which was not in the initial dataset, it won't be able to complete the generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_tokens(names: list[str], ngram: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Generates and returns all unique n-grams from the names.\n",
    "    \n",
    "    Parameters:\n",
    "        names (list[str]): List of names to extract tokens from.\n",
    "        ngram (int): The size of the n-gram (e.g., 3 for trigram).\n",
    "    \n",
    "    Returns:\n",
    "        list[str]: List of unique n-gram tokens, with <UNK> as the first token.\n",
    "    \"\"\"\n",
    "    context_length = ngram - 1\n",
    "    token_set = set()  # Use a set to store unique tokens\n",
    "    \n",
    "    for name in names:\n",
    "        for i in range(len(name) - context_length + 1):\n",
    "            token = name[i:i+context_length]\n",
    "            token_set.add(token)  # Add token to set, ensuring uniqueness\n",
    "    \n",
    "    # Convert set to list and add <UNK> at the beginning\n",
    "    return [\"<UNK>\"] + sorted(token_set)  # Sorting optional for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<UNK>', 'din', 'ino', 'nos', 'oso', 'our', 'rus', 'sou', 'uru']\n"
     ]
    }
   ],
   "source": [
    "print(list_all_tokens([\"dino\", \"dinosour\", \"dinosourus\"], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaing of the project, we will work with the padded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0aachenosaurus1111111111111\n",
       "1    0aardonyx111111111111111111\n",
       "Name: paddded_dino_name, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = data[\"paddded_dino_name\"]\n",
    "DATA.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) N-gram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some usefull functions usefull for this model __only__. Each models needs his own tool functions. Some times the difference is only a line or a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dertermining tokens of language, it is also necessary to determine our vocabulary. In our case, it is all the characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(names: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Builds and returns a list of all unique characters (vocabulary) from the names.\n",
    "    \n",
    "    Parameters:\n",
    "        names (list[str]): List of names to extract characters from.\n",
    "    \n",
    "    Returns:\n",
    "        list[str]: List of unique characters with <UNK> as the first item.\n",
    "    \"\"\"\n",
    "    # Use a set for unique characters\n",
    "    unique_chars = set()\n",
    "    \n",
    "    for name in names:\n",
    "        unique_chars.update(name)  # Add all characters in the name to the set\n",
    "    \n",
    "    # Convert set to a sorted list and add <UNK> at the beginning\n",
    "    return [\"<UNK>\"] + sorted(unique_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute probability of a letter appearing after a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_probabilities(probabilities: np.ndarray, tokens: list[str], vocab: list[str]) -> None:\n",
    "    \"\"\"Prints the probabilities of generating each letter for each token.\"\"\"\n",
    "    for i, token in enumerate(tokens):\n",
    "        print(f\"Token: {token}\")\n",
    "        for j, letter in enumerate(vocab):\n",
    "            prob = probabilities[i][j]\n",
    "            if prob > 0:\n",
    "                print(f\"    {letter}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilities(names: list[str], tokens: list[str], vocab: list[str], context: int) -> np.ndarray:\n",
    "    \"\"\"Computes the conditional probabilities of each token generating a letter from the vocabulary.\"\"\"\n",
    "    probabilities_array = np.zeros((len(tokens), len(vocab)))\n",
    "\n",
    "    # Count occurrences of letters following each token\n",
    "    for name in names:\n",
    "        for i in range(len(name) - context):\n",
    "            token = name[i:i+context]\n",
    "            next_letter = name[i+context]  # The letter after the token\n",
    "            if next_letter in vocab:\n",
    "                token_index = tokens.index(token) if token in tokens else tokens.index(\"<UNK>\")\n",
    "                letter_index = vocab.index(next_letter)\n",
    "                probabilities_array[token_index][letter_index] += 1\n",
    "            else:\n",
    "                print(f\"Letter {next_letter} not in vocabulary\")\n",
    "                probabilities_array[tokens.index(\"<UNK>\")][vocab.index(\"<UNK>\")] += 1\n",
    "\n",
    "    # Normalize the probabilities by dividing by row sums\n",
    "    row_sums = probabilities_array.sum(axis=1, keepdims=True)\n",
    "    probabilities_array = np.divide(probabilities_array, row_sums, where=row_sums != 0, out=probabilities_array)\n",
    "\n",
    "    # print_probabilities(probabilities_array, tokens, vocab)\n",
    "    \n",
    "    return probabilities_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add some randomness and not generating alwas the same name, we will not retrieve the most predicted letter but one of the first k letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_top_k(top_k: int, probabilities: np.array, token_index: int, vocab: list[str], verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Chooses one of the top k letters based on probabilities. Only selects letters with probability > 0.\n",
    "    \n",
    "    Parameters:\n",
    "        top_k (int): Number of top probabilities to consider.\n",
    "        probabilities (np.array): 2D array of conditional probabilities (tokens x vocab).\n",
    "        token_index (int): Index of the token in the probabilities array.\n",
    "        vocab (list[str]): List of vocabulary characters.\n",
    "        verbose (bool): If True, outputs detailed information.\n",
    "    \n",
    "    Returns:\n",
    "        str: Chosen letter from the top k predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort the probabilities for the token and get indices in descending order\n",
    "    sorted_indices = np.argsort(probabilities[token_index])[::-1]\n",
    "    \n",
    "    # Filter indices with probability > 0\n",
    "    valid_indices = [idx for idx in sorted_indices if probabilities[token_index][idx] > 0]\n",
    "    \n",
    "    # Limit top_k to available valid options\n",
    "    top_k = min(top_k, len(valid_indices))\n",
    "    \n",
    "    if top_k == 0:\n",
    "        # No valid letters with probability > 0, defaulting to <UNK>\n",
    "        if verbose:\n",
    "            print(\"No valid letters with probability > 0. Falling back to <UNK>.\")\n",
    "        return \"<UNK>\"\n",
    "\n",
    "    # Take the top_k valid indices\n",
    "    best_k_indices = valid_indices[:top_k]\n",
    "    \n",
    "    # Display top-k letters if verbose is True\n",
    "    if verbose:\n",
    "        print(f\"\\nTop {top_k} predicted letters for token index {token_index}:\")\n",
    "        for idx in best_k_indices:\n",
    "            print(f\"Letter: {vocab[idx]}, Probability: {probabilities[token_index][idx]:.4f}\")\n",
    "\n",
    "    # Choose one of the top-k indices randomly (or the top one if k=1)\n",
    "    chosen_index = np.random.choice(best_k_indices) if top_k > 1 else best_k_indices[0]\n",
    "    \n",
    "    chosen_letter = vocab[chosen_index]\n",
    "    if verbose:\n",
    "        print(f\"Chosen letter: {chosen_letter}\")\n",
    "    \n",
    "    return chosen_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have all the tools to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_generate_name(tokens: list[str], vocab: list[str], probabilities: np.array, ngram: int, \n",
    "                        max_length: int = 10, top_k: int = 5, verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Generates a new name using an n-gram model with <UNK> token handling.\n",
    "    \n",
    "    Parameters:\n",
    "        tokens (list[str]): List of possible n-gram tokens.\n",
    "        vocab (list[str]): List of letters in the vocabulary.\n",
    "        probabilities (np.array): Array of conditional probabilities for each token generating a letter.\n",
    "        ngram (int): The size of the n-gram model (e.g., 3 for trigram).\n",
    "        max_length (int): Maximum number of letters in the generated name.\n",
    "        top_k (int): Number of top probable letters to consider at each step.\n",
    "        verbose (bool): If True, prints debugging information.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated name.\n",
    "    \"\"\"\n",
    "    \n",
    "    generated_name = \"\"  # Initialize with an empty string\n",
    "    context_length = ngram - 1  # Number of letters to use as context\n",
    "    current_token = \"0\" * context_length  # Start token is represented by repeated \"0\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nStarting name generation:\")\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        # Get the index for the current token, falling back to <UNK> if not found\n",
    "        token_index = tokens.index(current_token) if current_token in tokens else tokens.index(\"<UNK>\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nCurrent token: {current_token}\")\n",
    "            print(f\"Name under construction: {generated_name}\")\n",
    "        \n",
    "        # Use all possible letters at the start, otherwise limit to top_k\n",
    "        # -3 to exclude <UNK>, 0 and 1 tokens\n",
    "        if current_token == \"0\" * context_length:\n",
    "            next_letter = choose_top_k(top_k=len(vocab) - 3, probabilities=probabilities, token_index=token_index, vocab=vocab, verbose=verbose)\n",
    "        else:\n",
    "            next_letter = choose_top_k(top_k=top_k, probabilities=probabilities, token_index=token_index, vocab=vocab, verbose=verbose)\n",
    "        \n",
    "        if next_letter == \"1\":  # End token reached\n",
    "            if verbose:\n",
    "                print(f\"End of name reached with letter: 1\\n\")\n",
    "            break\n",
    "        \n",
    "        # Append the selected letter to the generated name\n",
    "        generated_name += next_letter\n",
    "        # Update the token by shifting and adding the new letter\n",
    "        current_token = (current_token + next_letter)[-context_length:]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Final generated name: {generated_name}\\n\")\n",
    "    \n",
    "    return generated_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_model(names: list[str], ngram: int, num_predictions: int, max_length: int, top_k: int, verbose: bool = False) -> list[str]:\n",
    "    \"\"\"\n",
    "    Trains an n-gram model and generates new names.\n",
    "    \n",
    "    Parameters:\n",
    "        names (list[str]): List of input names to train the model.\n",
    "        ngram (int): The size of the n-gram model (e.g., 3 for trigram).\n",
    "        num_predictions (int): Number of names to generate.\n",
    "        max_length (int): Maximum length of each generated name.\n",
    "        top_k (int): Number of top probable letters to consider at each generation step.\n",
    "        verbose (bool): If True, outputs detailed information for debugging.\n",
    "    \n",
    "    Returns:\n",
    "        list[str]: A list of generated names.\n",
    "    \"\"\"\n",
    "    context = ngram - 1  # Number of letters in the context (n-gram - 1)\n",
    "    \n",
    "    # Preprocess names by adding the right number of start tokens\n",
    "    names_with_tokens = add_start_token_ngram(names=names, ngram=ngram)\n",
    "    \n",
    "    # Build model components\n",
    "    tokens = list_all_tokens(names=names_with_tokens, ngram=ngram)\n",
    "    vocab = build_vocabulary(names=names_with_tokens)\n",
    "    probabilities = compute_probabilities(names=names_with_tokens, tokens=tokens, vocab=vocab, context=context)\n",
    "    \n",
    "    # Generate new names based on the n-gram model\n",
    "    generated_names = []\n",
    "    for _ in range(num_predictions):\n",
    "        name = ngram_generate_name(tokens=tokens, vocab=vocab, probabilities=probabilities, ngram=ngram, max_length=max_length, top_k=top_k, verbose=verbose)\n",
    "        generated_names.append(name)\n",
    "    \n",
    "    return generated_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the process, there is a last function to train and print generated names in one command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_generate_names(names: list[str], ngram: int, num_predictions: int, max_length: int, top_k: int, verbose: bool = False) -> list[str]:\n",
    "    \"\"\"\n",
    "    Trains an n-gram model and prints generated names, including model parameters and \n",
    "    whether each generated name exists in the original data.\n",
    "    \n",
    "    Parameters:\n",
    "        names (list[str]): List of input names to train the model.\n",
    "        ngram (int): The size of the n-gram model (e.g., 3 for trigram).\n",
    "        num_predictions (int): Number of names to generate.\n",
    "        max_length (int): Maximum length of each generated name.\n",
    "        top_k (int): Number of top probable letters to consider at each generation step.\n",
    "        verbose (bool): If True, outputs detailed information for debugging.\n",
    "    \n",
    "    Returns:\n",
    "        list[str]: List of generated names.\n",
    "    \"\"\"\n",
    "    # Train the n-gram model and generate names\n",
    "    generated_names = ngram_model(\n",
    "        names=names,\n",
    "        ngram=ngram,\n",
    "        num_predictions=num_predictions,\n",
    "        max_length=max_length,\n",
    "        top_k=top_k,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Print the generated names with model parameters\n",
    "    print(f\"\\nn-gram = {ngram}, top_k = {top_k}:\")\n",
    "    \n",
    "    # Check if each generated name exists in the original data\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Generated Name | In Original Data\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for name in generated_names:\n",
    "        in_original = \"True\" if name in names else \"False\"\n",
    "        print(f\"{name:<15} | {in_original}\")\n",
    "    print(\"*\" * 40)\n",
    "    \n",
    "    return generated_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Names with n-gramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 000\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.1089\n",
      "Letter: s, Probability: 0.0945\n",
      "Letter: p, Probability: 0.0794\n",
      "Letter: c, Probability: 0.0709\n",
      "Letter: t, Probability: 0.0643\n",
      "Letter: m, Probability: 0.0597\n",
      "Letter: l, Probability: 0.0538\n",
      "Letter: d, Probability: 0.0531\n",
      "Letter: b, Probability: 0.0492\n",
      "Letter: e, Probability: 0.0427\n",
      "Letter: h, Probability: 0.0420\n",
      "Letter: g, Probability: 0.0394\n",
      "Letter: n, Probability: 0.0315\n",
      "Letter: o, Probability: 0.0269\n",
      "Letter: r, Probability: 0.0262\n",
      "Letter: k, Probability: 0.0256\n",
      "Letter: j, Probability: 0.0171\n",
      "Letter: z, Probability: 0.0171\n",
      "Letter: y, Probability: 0.0157\n",
      "Letter: i, Probability: 0.0157\n",
      "Letter: f, Probability: 0.0138\n",
      "Letter: v, Probability: 0.0131\n",
      "Letter: u, Probability: 0.0112\n",
      "Letter: w, Probability: 0.0112\n",
      "Letter: x, Probability: 0.0105\n",
      "Letter: q, Probability: 0.0066\n",
      "Chosen letter: m\n",
      "\n",
      "Current token: 00m\n",
      "Name under construction: m\n",
      "\n",
      "Top 1 predicted letters for token index 14:\n",
      "Letter: a, Probability: 0.4286\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: 0ma\n",
      "Name under construction: ma\n",
      "\n",
      "Top 1 predicted letters for token index 135:\n",
      "Letter: c, Probability: 0.2051\n",
      "Chosen letter: c\n",
      "\n",
      "Current token: mac\n",
      "Name under construction: mac\n",
      "\n",
      "Top 1 predicted letters for token index 1522:\n",
      "Letter: r, Probability: 0.5000\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: acr\n",
      "Name under construction: macr\n",
      "\n",
      "Top 1 predicted letters for token index 267:\n",
      "Letter: o, Probability: 0.7778\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: cro\n",
      "Name under construction: macro\n",
      "\n",
      "Top 1 predicted letters for token index 624:\n",
      "Letter: c, Probability: 0.2632\n",
      "Chosen letter: c\n",
      "\n",
      "Current token: roc\n",
      "Name under construction: macroc\n",
      "\n",
      "Top 1 predicted letters for token index 2144:\n",
      "Letter: e, Probability: 0.4375\n",
      "Chosen letter: e\n",
      "\n",
      "Current token: oce\n",
      "Name under construction: macroce\n",
      "\n",
      "Top 1 predicted letters for token index 1797:\n",
      "Letter: r, Probability: 0.7391\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: cer\n",
      "Name under construction: macrocer\n",
      "\n",
      "Top 1 predicted letters for token index 577:\n",
      "Letter: a, Probability: 0.9250\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: era\n",
      "Name under construction: macrocera\n",
      "\n",
      "Top 1 predicted letters for token index 841:\n",
      "Letter: t, Probability: 0.8916\n",
      "Chosen letter: t\n",
      "Final generated name: macrocerat\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 000\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.1089\n",
      "Letter: s, Probability: 0.0945\n",
      "Letter: p, Probability: 0.0794\n",
      "Letter: c, Probability: 0.0709\n",
      "Letter: t, Probability: 0.0643\n",
      "Letter: m, Probability: 0.0597\n",
      "Letter: l, Probability: 0.0538\n",
      "Letter: d, Probability: 0.0531\n",
      "Letter: b, Probability: 0.0492\n",
      "Letter: e, Probability: 0.0427\n",
      "Letter: h, Probability: 0.0420\n",
      "Letter: g, Probability: 0.0394\n",
      "Letter: n, Probability: 0.0315\n",
      "Letter: o, Probability: 0.0269\n",
      "Letter: r, Probability: 0.0262\n",
      "Letter: k, Probability: 0.0256\n",
      "Letter: j, Probability: 0.0171\n",
      "Letter: z, Probability: 0.0171\n",
      "Letter: y, Probability: 0.0157\n",
      "Letter: i, Probability: 0.0157\n",
      "Letter: f, Probability: 0.0138\n",
      "Letter: v, Probability: 0.0131\n",
      "Letter: u, Probability: 0.0112\n",
      "Letter: w, Probability: 0.0112\n",
      "Letter: x, Probability: 0.0105\n",
      "Letter: q, Probability: 0.0066\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: 00i\n",
      "Name under construction: i\n",
      "\n",
      "Top 1 predicted letters for token index 10:\n",
      "Letter: s, Probability: 0.2917\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: 0is\n",
      "Name under construction: is\n",
      "\n",
      "Top 1 predicted letters for token index 113:\n",
      "Letter: c, Probability: 0.4286\n",
      "Chosen letter: c\n",
      "\n",
      "Current token: isc\n",
      "Name under construction: isc\n",
      "\n",
      "Top 1 predicted letters for token index 1260:\n",
      "Letter: u, Probability: 0.5000\n",
      "Chosen letter: u\n",
      "\n",
      "Current token: scu\n",
      "Name under construction: iscu\n",
      "\n",
      "Top 1 predicted letters for token index 2230:\n",
      "Letter: s, Probability: 0.8000\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: cus\n",
      "Name under construction: iscus\n",
      "\n",
      "Top 1 predicted letters for token index 635:\n",
      "Letter: 1, Probability: 0.8889\n",
      "Chosen letter: 1\n",
      "End of name reached with letter: 1\n",
      "\n",
      "Final generated name: iscus\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 000\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.1089\n",
      "Letter: s, Probability: 0.0945\n",
      "Letter: p, Probability: 0.0794\n",
      "Letter: c, Probability: 0.0709\n",
      "Letter: t, Probability: 0.0643\n",
      "Letter: m, Probability: 0.0597\n",
      "Letter: l, Probability: 0.0538\n",
      "Letter: d, Probability: 0.0531\n",
      "Letter: b, Probability: 0.0492\n",
      "Letter: e, Probability: 0.0427\n",
      "Letter: h, Probability: 0.0420\n",
      "Letter: g, Probability: 0.0394\n",
      "Letter: n, Probability: 0.0315\n",
      "Letter: o, Probability: 0.0269\n",
      "Letter: r, Probability: 0.0262\n",
      "Letter: k, Probability: 0.0256\n",
      "Letter: j, Probability: 0.0171\n",
      "Letter: z, Probability: 0.0171\n",
      "Letter: y, Probability: 0.0157\n",
      "Letter: i, Probability: 0.0157\n",
      "Letter: f, Probability: 0.0138\n",
      "Letter: v, Probability: 0.0131\n",
      "Letter: u, Probability: 0.0112\n",
      "Letter: w, Probability: 0.0112\n",
      "Letter: x, Probability: 0.0105\n",
      "Letter: q, Probability: 0.0066\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: 00a\n",
      "Name under construction: a\n",
      "\n",
      "Top 1 predicted letters for token index 2:\n",
      "Letter: n, Probability: 0.1566\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: 0an\n",
      "Name under construction: an\n",
      "\n",
      "Top 1 predicted letters for token index 40:\n",
      "Letter: t, Probability: 0.1923\n",
      "Chosen letter: t\n",
      "\n",
      "Current token: ant\n",
      "Name under construction: ant\n",
      "\n",
      "Top 1 predicted letters for token index 379:\n",
      "Letter: h, Probability: 0.2941\n",
      "Chosen letter: h\n",
      "\n",
      "Current token: nth\n",
      "Name under construction: anth\n",
      "\n",
      "Top 1 predicted letters for token index 1758:\n",
      "Letter: o, Probability: 0.7000\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: tho\n",
      "Name under construction: antho\n",
      "\n",
      "Top 1 predicted letters for token index 2381:\n",
      "Letter: s, Probability: 0.2195\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: hos\n",
      "Name under construction: anthos\n",
      "\n",
      "Top 1 predicted letters for token index 1102:\n",
      "Letter: a, Probability: 0.8077\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: osa\n",
      "Name under construction: anthosa\n",
      "\n",
      "Top 1 predicted letters for token index 1906:\n",
      "Letter: u, Probability: 0.9954\n",
      "Chosen letter: u\n",
      "\n",
      "Current token: sau\n",
      "Name under construction: anthosau\n",
      "\n",
      "Top 1 predicted letters for token index 2219:\n",
      "Letter: r, Probability: 1.0000\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: aur\n",
      "Name under construction: anthosaur\n",
      "\n",
      "Top 1 predicted letters for token index 464:\n",
      "Letter: u, Probability: 0.9431\n",
      "Chosen letter: u\n",
      "Final generated name: anthosauru\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 000\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.1089\n",
      "Letter: s, Probability: 0.0945\n",
      "Letter: p, Probability: 0.0794\n",
      "Letter: c, Probability: 0.0709\n",
      "Letter: t, Probability: 0.0643\n",
      "Letter: m, Probability: 0.0597\n",
      "Letter: l, Probability: 0.0538\n",
      "Letter: d, Probability: 0.0531\n",
      "Letter: b, Probability: 0.0492\n",
      "Letter: e, Probability: 0.0427\n",
      "Letter: h, Probability: 0.0420\n",
      "Letter: g, Probability: 0.0394\n",
      "Letter: n, Probability: 0.0315\n",
      "Letter: o, Probability: 0.0269\n",
      "Letter: r, Probability: 0.0262\n",
      "Letter: k, Probability: 0.0256\n",
      "Letter: j, Probability: 0.0171\n",
      "Letter: z, Probability: 0.0171\n",
      "Letter: y, Probability: 0.0157\n",
      "Letter: i, Probability: 0.0157\n",
      "Letter: f, Probability: 0.0138\n",
      "Letter: v, Probability: 0.0131\n",
      "Letter: u, Probability: 0.0112\n",
      "Letter: w, Probability: 0.0112\n",
      "Letter: x, Probability: 0.0105\n",
      "Letter: q, Probability: 0.0066\n",
      "Chosen letter: l\n",
      "\n",
      "Current token: 00l\n",
      "Name under construction: l\n",
      "\n",
      "Top 1 predicted letters for token index 13:\n",
      "Letter: a, Probability: 0.2683\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: 0la\n",
      "Name under construction: la\n",
      "\n",
      "Top 1 predicted letters for token index 129:\n",
      "Letter: n, Probability: 0.1818\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: lan\n",
      "Name under construction: lan\n",
      "\n",
      "Top 1 predicted letters for token index 1398:\n",
      "Letter: c, Probability: 0.2143\n",
      "Chosen letter: c\n",
      "\n",
      "Current token: anc\n",
      "Name under construction: lanc\n",
      "\n",
      "Top 1 predicted letters for token index 363:\n",
      "Letter: h, Probability: 0.6250\n",
      "Chosen letter: h\n",
      "\n",
      "Current token: nch\n",
      "Name under construction: lanch\n",
      "\n",
      "Top 1 predicted letters for token index 1626:\n",
      "Letter: i, Probability: 0.4118\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: chi\n",
      "Name under construction: lanchi\n",
      "\n",
      "Top 1 predicted letters for token index 582:\n",
      "Letter: s, Probability: 0.3077\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: his\n",
      "Name under construction: lanchis\n",
      "\n",
      "Top 1 predicted letters for token index 1076:\n",
      "Letter: a, Probability: 0.7895\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: isa\n",
      "Name under construction: lanchisa\n",
      "\n",
      "Top 1 predicted letters for token index 1258:\n",
      "Letter: u, Probability: 0.9474\n",
      "Chosen letter: u\n",
      "\n",
      "Current token: sau\n",
      "Name under construction: lanchisau\n",
      "\n",
      "Top 1 predicted letters for token index 2219:\n",
      "Letter: r, Probability: 1.0000\n",
      "Chosen letter: r\n",
      "Final generated name: lanchisaur\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 000\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.1089\n",
      "Letter: s, Probability: 0.0945\n",
      "Letter: p, Probability: 0.0794\n",
      "Letter: c, Probability: 0.0709\n",
      "Letter: t, Probability: 0.0643\n",
      "Letter: m, Probability: 0.0597\n",
      "Letter: l, Probability: 0.0538\n",
      "Letter: d, Probability: 0.0531\n",
      "Letter: b, Probability: 0.0492\n",
      "Letter: e, Probability: 0.0427\n",
      "Letter: h, Probability: 0.0420\n",
      "Letter: g, Probability: 0.0394\n",
      "Letter: n, Probability: 0.0315\n",
      "Letter: o, Probability: 0.0269\n",
      "Letter: r, Probability: 0.0262\n",
      "Letter: k, Probability: 0.0256\n",
      "Letter: j, Probability: 0.0171\n",
      "Letter: z, Probability: 0.0171\n",
      "Letter: y, Probability: 0.0157\n",
      "Letter: i, Probability: 0.0157\n",
      "Letter: f, Probability: 0.0138\n",
      "Letter: v, Probability: 0.0131\n",
      "Letter: u, Probability: 0.0112\n",
      "Letter: w, Probability: 0.0112\n",
      "Letter: x, Probability: 0.0105\n",
      "Letter: q, Probability: 0.0066\n",
      "Chosen letter: g\n",
      "\n",
      "Current token: 00g\n",
      "Name under construction: g\n",
      "\n",
      "Top 1 predicted letters for token index 8:\n",
      "Letter: a, Probability: 0.2667\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: 0ga\n",
      "Name under construction: ga\n",
      "\n",
      "Top 1 predicted letters for token index 92:\n",
      "Letter: l, Probability: 0.3750\n",
      "Chosen letter: l\n",
      "\n",
      "Current token: gal\n",
      "Name under construction: gal\n",
      "\n",
      "Top 1 predicted letters for token index 940:\n",
      "Letter: v, Probability: 0.2500\n",
      "Chosen letter: v\n",
      "\n",
      "Current token: alv\n",
      "Name under construction: galv\n",
      "\n",
      "Top 1 predicted letters for token index 348:\n",
      "Letter: e, Probability: 0.6667\n",
      "Chosen letter: e\n",
      "\n",
      "Current token: lve\n",
      "Name under construction: galve\n",
      "\n",
      "Top 1 predicted letters for token index 1508:\n",
      "Letter: s, Probability: 0.3333\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: ves\n",
      "Name under construction: galves\n",
      "\n",
      "Top 1 predicted letters for token index 2612:\n",
      "Letter: a, Probability: 1.0000\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: esa\n",
      "Name under construction: galvesa\n",
      "\n",
      "Top 1 predicted letters for token index 861:\n",
      "Letter: u, Probability: 1.0000\n",
      "Chosen letter: u\n",
      "\n",
      "Current token: sau\n",
      "Name under construction: galvesau\n",
      "\n",
      "Top 1 predicted letters for token index 2219:\n",
      "Letter: r, Probability: 1.0000\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: aur\n",
      "Name under construction: galvesaur\n",
      "\n",
      "Top 1 predicted letters for token index 464:\n",
      "Letter: u, Probability: 0.9431\n",
      "Chosen letter: u\n",
      "Final generated name: galvesauru\n",
      "\n",
      "\n",
      "n-gram = 4, top_k = 1:\n",
      "----------------------------------------\n",
      "Generated Name | In Original Data\n",
      "----------------------------------------\n",
      "macrocerat      | False\n",
      "iscus           | False\n",
      "anthosauru      | False\n",
      "lanchisaur      | False\n",
      "galvesauru      | False\n",
      "****************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['macrocerat', 'iscus', 'anthosauru', 'lanchisaur', 'galvesauru']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ngram Model (n = 4), top_k = 1\n",
    "train_and_generate_names(names=DATA, ngram=4, num_predictions=5, max_length=10, top_k=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is multiple results for different models. **Scroll** (enable the option) to display all models' generated names if it is too long.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n-gram = 4, top_k = 1:\n",
      "----------------------------------------\n",
      "Generated Name | In Original Data\n",
      "----------------------------------------\n",
      "iscus           | False\n",
      "neosaurus       | False\n",
      "raptor          | False\n",
      "fukuivria       | False\n",
      "macrocerat      | False\n",
      "****************************************\n",
      "\n",
      "n-gram = 4, top_k = 2:\n",
      "----------------------------------------\n",
      "Generated Name | In Original Data\n",
      "----------------------------------------\n",
      "indasasaur      | False\n",
      "neme            | False\n",
      "paloninosp      | False\n",
      "oshansauru      | False\n",
      "barischusa      | False\n",
      "****************************************\n",
      "\n",
      "n-gram = 5, top_k = 2:\n",
      "----------------------------------------\n",
      "Generated Name | In Original Data\n",
      "----------------------------------------\n",
      "tanis           | False\n",
      "lamacelogn      | False\n",
      "baryonyx        | False\n",
      "yinlongjia      | False\n",
      "xuanhanosa      | False\n",
      "****************************************\n",
      "\n",
      "n-gram = 3, top_k = 1:\n",
      "----------------------------------------\n",
      "Generated Name | In Original Data\n",
      "----------------------------------------\n",
      "jia             | False\n",
      "venator         | False\n",
      "or              | False\n",
      "anosaurus       | False\n",
      "ungosaurus      | False\n",
      "****************************************\n",
      "\n",
      "n-gram = 3, top_k = 2:\n",
      "----------------------------------------\n",
      "Generated Name | In Original Data\n",
      "----------------------------------------\n",
      "danostrisa      | False\n",
      "walosauros      | False\n",
      "kanostes        | False\n",
      "vasaurusau      | False\n",
      "walosausan      | False\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "# Ngram Model (n = 4), top_k = 1\n",
    "_ = train_and_generate_names(names=DATA, ngram=4, num_predictions=5, max_length=10, top_k=1, verbose=False)\n",
    "# Ngram Model (n = 4), top_k = 2\n",
    "_ =train_and_generate_names(names=DATA, ngram=4, num_predictions=5, max_length=10, top_k=2, verbose=False)\n",
    "# Ngram Model (n = 5), top_k = 2\n",
    "_ =train_and_generate_names(names=DATA, ngram=5, num_predictions=5, max_length=10, top_k=2, verbose=False)\n",
    "# Ngram Model (n = 3), top_k = 1\n",
    "_ =train_and_generate_names(names=DATA, ngram=3, num_predictions=5, max_length=10, top_k=1, verbose=False)\n",
    "# Ngram Model (n = 3), top_k = 2\n",
    "_ =train_and_generate_names(names=DATA, ngram=3, num_predictions=5, max_length=10, top_k=2, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of my generator with different parameters' values : \n",
    "-  `n = 3` and `k = 2`<br>\n",
    "['neoversosuccingshadros', 'bator', 'quilmayisaurutichodosuccin', 'dasylossus', 'inosphagros']\n",
    "-  `n = 3` and `k = 3`<br>\n",
    "['yungonius', 'elaplossuesiohadromaia', 'venescelusothostospinax', 'xingsauros', 'euskelyx']\n",
    "-  `n = 2` and `k = 3`<br>\n",
    "['heisaudasilis', 'kan', 'ale', 'xiasaustesaudiangobistrops', 'raptastriong']\n",
    "- `n = 4` and `k=3`<br>\n",
    "['unicerosaurophale', 'yurgovuchia', 'ischyrophus', 'ovirapterovenatosaurus', 'magnapartenykus']\n",
    "- `n = 4` and `k=5`<br>\n",
    "['cristatus', 'vouivria', 'yongjianosaurutitanius', 'mojoceratusauravusaurornit', 'epachthosuchomimoides']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like with a 4-gram model, we generate name that looks like real dino names. Even with a high randomness (k=5), results are still good.\n",
    "\n",
    "Even with the 3-gram model, the results are good (with low randomness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "The results from the n-gram models, particularly the 4-gram models, were quite promising. The generated dinosaur names were realistic and closely resembled actual dinosaur names. Notably, when using a 4-gram model with `k = 1`, the generated names were of high quality and showed a good balance between randomness and coherence.\n",
    "\n",
    "During multiple tests, only one generated name was found in the original dataset, indicating that the model is capable of generating unique and plausible dinosaur names. This demonstrates the effectiveness of the n-gram approach in capturing the patterns and structures present in the original data.\n",
    "\n",
    "Overall, the 4-gram model with `k = 1` proved to be the most effective configuration for generating new dinosaur names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Deep LEarning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs model are usually used for sequence prediction tasks. They are capable of learning long-term dependencies in data. This is the reason why they are used for text generation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First function to implement is the victory build. Remember that our data is pre-processed in the following format :<br>\n",
    "`0name1` (without necessary padding), `0name1111` (when padding is needed).\n",
    "\n",
    "So, we can immediately move to the build vocabulary function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(names: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Builds a vocabulary dictionary mapping each unique character to a unique integer ID,\n",
    "    with \"0\" as the start token and \"1\" as the end/padding token.\n",
    "    \n",
    "    Parameters:\n",
    "        names (list[str]): List of names to extract characters from.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with characters as keys and integer IDs as values.\n",
    "    \"\"\"\n",
    "    unique_chars = set(\"01\")  # Include \"0\" (start) and \"1\" (end/padding)\n",
    "    for name in names:\n",
    "        unique_chars.update(name)\n",
    "    \n",
    "    # Assign an integer ID to each character\n",
    "    vocab = {char: idx for idx, char in enumerate(sorted(unique_chars))}\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep leanring model can't work with strings and chars. They need number to do all the computation and predictions. So, encoding is a must."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_names(names: list[str], vocab: dict) -> tuple[list[list[int]], dict]:\n",
    "    \"\"\"\n",
    "    Encodes each name as a list of integer IDs based on the vocabulary and returns a reverse vocabulary.\n",
    "    \n",
    "    Parameters:\n",
    "        names (list[str]): List of names to encode.\n",
    "        vocab (dict): Vocabulary dictionary with character-to-integer mappings.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple (encoded_names, reverse_vocab), where:\n",
    "            - encoded_names is a list of encoded names, each represented as a list of integers.\n",
    "            - reverse_vocab is a dictionary mapping integer IDs back to characters.\n",
    "    \"\"\"\n",
    "    reverse_vocab = {idx: char for char, idx in vocab.items()}\n",
    "    encoded_names = [[vocab[char] for char in name] for name in names]\n",
    "    return encoded_names, reverse_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is finally ready for LSTM. Now, we will create `X` and `y` sets to train the model.\n",
    "\n",
    "To define `X` and `y`, we will re-use the previous notion of **n-gram**. Indeed, RNN will learn to predict `y` letter, based on previous $k$-characteres contained in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_data(encoded_names: list[list[int]], sequence_length: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Prepares the training data (X, y) for an RNN model (LSTM, GRU, etc.).\n",
    "    \n",
    "    Parameters:\n",
    "        encoded_names (list[list[int]]): List of encoded names where each character is an integer ID.\n",
    "        sequence_length (int): The fixed length of each input sequence for the model.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple (X, y) where X is an array of input sequences and y is an array of target characters as integer IDs.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # For each name, create input-output pairs by sliding a window of size `sequence_length`\n",
    "    for name in encoded_names:\n",
    "        for i in range(len(name) - sequence_length):\n",
    "            input_seq = name[i:i + sequence_length]  # List of integer IDs\n",
    "            target_char = name[i + sequence_length]  # Integer ID for target character\n",
    "            X.append(input_seq)\n",
    "            y.append(target_char)\n",
    "    \n",
    "    # Ensure X and y are integer arrays\n",
    "    X = np.array(X, dtype=int)\n",
    "    y = np.array(y, dtype=int)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I will implement a global variable that use the *helpers* functions implemented. That's will be usefull for generating multiple data to try LSTM on different *n-gram* setup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_data(names: list[str], sequence_length: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Prepares all necessary components for training an RNN model to generate names.\n",
    "    \n",
    "    Parameters:\n",
    "        names (list[str]): List of names to use for training.\n",
    "        sequence_length (int): The fixed length of each input sequence for the model.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple (X, y, vocab, reverse_vocab), where:\n",
    "            - X is an array of input sequences\n",
    "            - y is an array of target characters as integer IDs\n",
    "            - vocab is a dictionary mapping characters to integer IDs\n",
    "            - reverse_vocab is a dictionary mapping integer IDs back to characters\n",
    "    \"\"\"\n",
    "    # Step 1: Build vocabulary\n",
    "    vocab = build_vocabulary(names)\n",
    "    \n",
    "    # Step 2: Encode names and create the reverse vocabulary\n",
    "    encoded_names, reverse_vocab = encode_names(names, vocab)\n",
    "    \n",
    "    # Step 3: Prepare X and y for model training\n",
    "    X, y = prepare_sequence_data(encoded_names, sequence_length)\n",
    "    \n",
    "    return X, y, vocab, reverse_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different models will be implemented. All are RNN based models but with different architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Standard LSTM Model\n",
    "- __Input Layer__: Accepts input sequences of length `sequence_length`.\n",
    "- __Embedding Layer__: Maps each character (represented by an integer index) into a dense vector, enabling the model to capture relationships between characters.\n",
    "- __LSTM Layer__: An LSTM layer learns sequential dependencies in the input data.\n",
    "- __Dense Layer__: Outputs a probability distribution across possible characters, predicting the next character in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(vocab_size: int, sequence_length: int, embedding_dim: int = 50, lstm_units: int = 64) -> Model :\n",
    "    \"\"\"\n",
    "    Builds an LSTM model for name generation.\n",
    "    \n",
    "    Parameters:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        sequence_length (int): Length of each input sequence.\n",
    "        embedding_dim (int): Dimension of the embedding layer.\n",
    "        lstm_units (int): Number of LSTM units.\n",
    "    \n",
    "    Returns:\n",
    "        Model : Compiled LSTM model.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(sequence_length,))\n",
    "    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs)\n",
    "    lstm1 = LSTM(lstm_units, return_sequences=False)(embedding) # return_sequences=False because we only need the last output\n",
    "    output = Dense(vocab_size, activation='softmax')(lstm1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. LSTM Model with Dropout\n",
    "- **Input Layer**: Processes sequences of length `sequence_length`.\n",
    "- **Embedding Layer**: Converts each character (integer index) to a dense embedding vector, allowing the model to learn character patterns.\n",
    "- **LSTM Layer with Dropout**: An LSTM layer, equipped with dropout and recurrent dropout, to improve generalization and reduce overfitting on sequence patterns. Overfitting is **not** wanted here to not have a model that generates exact names from data.\n",
    "- **Dropout Layer**: Adds an additional dropout layer after the LSTM layer to further improve regularization.\n",
    "- **Dense Layer**: Outputs a probability distribution to predict the next character in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_dropIn_model(vocab_size: int, sequence_length: int, embedding_dim: int = 50, lstm_units: int = 64) -> Model:\n",
    "    \"\"\"\n",
    "    Builds an LSTM model for name generation with dropout for regularization.\n",
    "    \n",
    "    Parameters:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        sequence_length (int): Length of each input sequence.\n",
    "        embedding_dim (int): Dimension of the embedding layer.\n",
    "        lstm_units (int): Number of LSTM units.\n",
    "    \n",
    "    Returns:\n",
    "        Model: Compiled LSTM model.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(sequence_length,))\n",
    "    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs)\n",
    "    \n",
    "    # First LSTM layer with dropout in the LSTM and after it\n",
    "    lstm1 = LSTM(lstm_units, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(embedding)\n",
    "    dropout1 = Dropout(0.2)(lstm1)\n",
    "    \n",
    "    # Output layer\n",
    "    output = Dense(vocab_size, activation='softmax')(dropout1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GRU Model for Name Generation\n",
    "\n",
    "- **Source**: Adapted from [Using RNN Model for Text Generation](https://medium.com/analytics-vidhya/using-rnn-model-for-text-generation-c5a37017d142) on Medium.\n",
    "  \n",
    "- **Input Layer**: Accepts input sequences of length `sequence_length`, each integer representing a character.\n",
    "- **Embedding Layer**: Maps each character index into a 200-dimensional vector, allowing the model to learn relationships between characters.\n",
    "- **GRU Layers with Batch Normalization and Dropout**:\n",
    "  - **First GRU Layer**: Contains 64 units with batch normalization and dropout, returning sequences to pass to the next layer.\n",
    "  - **Second GRU Layer**: Contains 128 units, also with batch normalization and dropout, capturing more complex patterns.\n",
    "  - **Third GRU Layer**: Contains 256 units, with batch normalization and dropout, outputting a single vector for the final dense layers.\n",
    "- **Dense Layer with ReLU**: Fully connected layer with 200 units, ReLU activation, and L2 regularization to add non-linearity.\n",
    "- **Output Layer**: A softmax layer that produces a probability distribution over `vocab_size` characters, allowing the model to predict the next character in the sequence.\n",
    "\n",
    "This configuration enables the model to learn sequential dependencies and generate names by predicting one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(vocab_size: int, sequence_length: int, embedding_size : int) -> Model:\n",
    "    \"\"\"\n",
    "    Builds a GRU-based model for name generation using the Keras functional API.\n",
    "    \n",
    "    Parameters:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        sequence_length (int): Length of each input sequence.\n",
    "    \n",
    "    Returns:\n",
    "        Model: Compiled GRU model.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(sequence_length,))\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_size)(inputs)\n",
    "    \n",
    "    # First GRU layer with Batch Normalization and Dropout\n",
    "    gru1 = GRU(64, return_sequences=True)(embedding)\n",
    "    bn1 = BatchNormalization()(gru1)\n",
    "    dropout1 = Dropout(0.2)(bn1)\n",
    "    \n",
    "    # Second GRU layer with Batch Normalization and Dropout\n",
    "    gru2 = GRU(128, return_sequences=True)(dropout1)\n",
    "    bn2 = BatchNormalization()(gru2)\n",
    "    dropout2 = Dropout(0.2)(bn2)\n",
    "    \n",
    "    # Third GRU layer with Batch Normalization and Dropout\n",
    "    gru3 = GRU(256, return_sequences=False)(dropout2)\n",
    "    bn3 = BatchNormalization()(gru3)\n",
    "    dropout3 = Dropout(0.2)(bn3)\n",
    "    \n",
    "    # Dense layer with ReLU activation and L2 regularization\n",
    "    dense = Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout3)\n",
    "    bn4 = BatchNormalization()(dense)\n",
    "    dropout4 = Dropout(0.2)(bn4)\n",
    "    \n",
    "    # Output layer with Softmax activation\n",
    "    outputs = Dense(vocab_size, activation='softmax')(dropout4)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiallization of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36576, 3), (36576,), 28, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = data[\"paddded_dino_name\"]\n",
    "sequence_length = 3\n",
    "embedding_size = max_word_length\n",
    "X, y, vocab, reverse_vocab = prepare_model_data(names=DATA, sequence_length=sequence_length)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "X.shape, y.shape, vocab_size, sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = build_lstm_model(vocab_size=vocab_size, sequence_length=sequence_length, embedding_dim=embedding_size, lstm_units=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dropout = build_lstm_dropIn_model(vocab_size=vocab_size, sequence_length=sequence_length, embedding_dim=embedding_size, lstm_units=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = build_gru_model(vocab_size=vocab_size, sequence_length=sequence_length, embedding_size=embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to simply training new models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(name: str, model: Model, X: np.array, y: np.array, batch_size: int, epochs: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Trains the given model on the input data.\n",
    "    \n",
    "    Parameters:\n",
    "        name (str): Name of the model.\n",
    "        model (Model): Keras model to train.\n",
    "        X (np.array): Input data for training.\n",
    "        y (np.array): Target data for training.\n",
    "        batch_size (int): Number of samples per batch.\n",
    "        epochs (int): Number of epochs to train.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Trained Keras model and training history.\n",
    "    \"\"\"\n",
    "    print(f\"Training {name} model...\")\n",
    "    early_stopping = EarlyStopping(patience=10)\n",
    "    \n",
    "    # Train the model with validation split and early stopping\n",
    "    history = model.fit(X, y, batch_size=batch_size, epochs=epochs, validation_split=0.2, \n",
    "                        callbacks=[early_stopping], verbose=1)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model...\n",
      "Epoch 1/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5840 - loss: 1.6962 - val_accuracy: 0.7079 - val_loss: 1.0533\n",
      "Epoch 2/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7165 - loss: 1.0111 - val_accuracy: 0.7288 - val_loss: 0.9254\n",
      "Epoch 3/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.8695 - val_accuracy: 0.7444 - val_loss: 0.8692\n",
      "Epoch 4/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7541 - loss: 0.8398 - val_accuracy: 0.7562 - val_loss: 0.8296\n",
      "Epoch 5/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7619 - loss: 0.8047 - val_accuracy: 0.7574 - val_loss: 0.8081\n",
      "Epoch 6/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7717 - loss: 0.7735 - val_accuracy: 0.7695 - val_loss: 0.7927\n",
      "Epoch 7/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.7657 - val_accuracy: 0.7758 - val_loss: 0.7771\n",
      "Epoch 8/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.7482 - val_accuracy: 0.7808 - val_loss: 0.7672\n",
      "Epoch 9/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7866 - loss: 0.7279 - val_accuracy: 0.7806 - val_loss: 0.7602\n",
      "Epoch 10/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.7162 - val_accuracy: 0.7821 - val_loss: 0.7534\n",
      "Epoch 11/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.7047 - val_accuracy: 0.7859 - val_loss: 0.7501\n",
      "Epoch 12/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.6957 - val_accuracy: 0.7876 - val_loss: 0.7473\n",
      "Epoch 13/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8010 - loss: 0.6823 - val_accuracy: 0.7900 - val_loss: 0.7417\n",
      "Epoch 14/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8051 - loss: 0.6724 - val_accuracy: 0.7933 - val_loss: 0.7373\n",
      "Epoch 15/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8096 - loss: 0.6596 - val_accuracy: 0.7894 - val_loss: 0.7377\n",
      "Epoch 16/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8080 - loss: 0.6610 - val_accuracy: 0.7951 - val_loss: 0.7344\n",
      "Epoch 17/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8116 - loss: 0.6438 - val_accuracy: 0.7952 - val_loss: 0.7338\n",
      "Epoch 18/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8177 - loss: 0.6258 - val_accuracy: 0.7932 - val_loss: 0.7380\n",
      "Epoch 19/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.6391 - val_accuracy: 0.7943 - val_loss: 0.7313\n",
      "Epoch 20/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8191 - loss: 0.6187 - val_accuracy: 0.7970 - val_loss: 0.7324\n",
      "Epoch 21/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.6030 - val_accuracy: 0.7989 - val_loss: 0.7312\n",
      "Epoch 22/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.6055 - val_accuracy: 0.8007 - val_loss: 0.7329\n",
      "Epoch 23/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.5920 - val_accuracy: 0.8003 - val_loss: 0.7341\n",
      "Epoch 24/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8219 - loss: 0.5968 - val_accuracy: 0.7991 - val_loss: 0.7365\n",
      "Epoch 25/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.5881 - val_accuracy: 0.7988 - val_loss: 0.7343\n",
      "Epoch 26/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.5916 - val_accuracy: 0.7995 - val_loss: 0.7343\n",
      "Epoch 27/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.5951 - val_accuracy: 0.7957 - val_loss: 0.7392\n",
      "Epoch 28/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8292 - loss: 0.5779 - val_accuracy: 0.7972 - val_loss: 0.7378\n",
      "Epoch 29/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.5733 - val_accuracy: 0.7988 - val_loss: 0.7416\n",
      "Epoch 30/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.5670 - val_accuracy: 0.8002 - val_loss: 0.7385\n",
      "Epoch 31/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.5655 - val_accuracy: 0.8003 - val_loss: 0.7467\n"
     ]
    }
   ],
   "source": [
    "lstm_model, lstm_history = training(\"LSTM\", lstm_model, X, y, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM with Dropout model...\n",
      "Epoch 1/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5843 - loss: 1.7366 - val_accuracy: 0.6899 - val_loss: 1.0740\n",
      "Epoch 2/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7095 - loss: 1.0245 - val_accuracy: 0.7317 - val_loss: 0.9287\n",
      "Epoch 3/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7361 - loss: 0.9204 - val_accuracy: 0.7351 - val_loss: 0.8844\n",
      "Epoch 4/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7486 - loss: 0.8646 - val_accuracy: 0.7419 - val_loss: 0.8516\n",
      "Epoch 5/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.8725 - val_accuracy: 0.7499 - val_loss: 0.8284\n",
      "Epoch 6/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7591 - loss: 0.8194 - val_accuracy: 0.7594 - val_loss: 0.8077\n",
      "Epoch 7/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7619 - loss: 0.8141 - val_accuracy: 0.7624 - val_loss: 0.7940\n",
      "Epoch 8/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.7982 - val_accuracy: 0.7717 - val_loss: 0.7811\n",
      "Epoch 9/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.7778 - val_accuracy: 0.7734 - val_loss: 0.7734\n",
      "Epoch 10/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.7606 - val_accuracy: 0.7760 - val_loss: 0.7644\n",
      "Epoch 11/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7747 - loss: 0.7670 - val_accuracy: 0.7735 - val_loss: 0.7607\n",
      "Epoch 12/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7795 - loss: 0.7582 - val_accuracy: 0.7828 - val_loss: 0.7503\n",
      "Epoch 13/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7763 - loss: 0.7582 - val_accuracy: 0.7831 - val_loss: 0.7469\n",
      "Epoch 14/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7810 - loss: 0.7577 - val_accuracy: 0.7839 - val_loss: 0.7435\n",
      "Epoch 15/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.7378 - val_accuracy: 0.7844 - val_loss: 0.7391\n",
      "Epoch 16/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.7360 - val_accuracy: 0.7870 - val_loss: 0.7363\n",
      "Epoch 17/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.7338 - val_accuracy: 0.7868 - val_loss: 0.7365\n",
      "Epoch 18/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: 0.7214 - val_accuracy: 0.7892 - val_loss: 0.7319\n",
      "Epoch 19/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7886 - loss: 0.7253 - val_accuracy: 0.7879 - val_loss: 0.7299\n",
      "Epoch 20/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7916 - loss: 0.7209 - val_accuracy: 0.7932 - val_loss: 0.7279\n",
      "Epoch 21/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.7335 - val_accuracy: 0.7955 - val_loss: 0.7256\n",
      "Epoch 22/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7905 - loss: 0.7164 - val_accuracy: 0.7931 - val_loss: 0.7268\n",
      "Epoch 23/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.6965 - val_accuracy: 0.7925 - val_loss: 0.7234\n",
      "Epoch 24/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7914 - loss: 0.7160 - val_accuracy: 0.7941 - val_loss: 0.7244\n",
      "Epoch 25/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8008 - loss: 0.6814 - val_accuracy: 0.7969 - val_loss: 0.7200\n",
      "Epoch 26/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.6826 - val_accuracy: 0.7976 - val_loss: 0.7214\n",
      "Epoch 27/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7988 - loss: 0.6869 - val_accuracy: 0.7947 - val_loss: 0.7216\n",
      "Epoch 28/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.6997 - val_accuracy: 0.7925 - val_loss: 0.7222\n",
      "Epoch 29/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.6848 - val_accuracy: 0.7967 - val_loss: 0.7183\n",
      "Epoch 30/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7990 - loss: 0.6818 - val_accuracy: 0.7948 - val_loss: 0.7201\n",
      "Epoch 31/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.6770 - val_accuracy: 0.7951 - val_loss: 0.7217\n",
      "Epoch 32/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.6750 - val_accuracy: 0.7984 - val_loss: 0.7194\n",
      "Epoch 33/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8039 - loss: 0.6713 - val_accuracy: 0.7996 - val_loss: 0.7152\n",
      "Epoch 34/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.6807 - val_accuracy: 0.7991 - val_loss: 0.7165\n",
      "Epoch 35/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.6768 - val_accuracy: 0.7967 - val_loss: 0.7185\n",
      "Epoch 36/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8022 - loss: 0.6753 - val_accuracy: 0.7980 - val_loss: 0.7172\n",
      "Epoch 37/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.6750 - val_accuracy: 0.7988 - val_loss: 0.7173\n",
      "Epoch 38/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8023 - loss: 0.6665 - val_accuracy: 0.7999 - val_loss: 0.7184\n",
      "Epoch 39/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.6775 - val_accuracy: 0.7974 - val_loss: 0.7194\n",
      "Epoch 40/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.6668 - val_accuracy: 0.7981 - val_loss: 0.7166\n",
      "Epoch 41/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8036 - loss: 0.6620 - val_accuracy: 0.7974 - val_loss: 0.7198\n",
      "Epoch 42/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.6669 - val_accuracy: 0.7981 - val_loss: 0.7198\n",
      "Epoch 43/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8036 - loss: 0.6618 - val_accuracy: 0.7984 - val_loss: 0.7186\n"
     ]
    }
   ],
   "source": [
    "lstm_dropout, lstm_dropout_history = training(\"LSTM with Dropout\", lstm_dropout, X, y, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GRU model...\n",
      "Epoch 1/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.6692 - loss: 2.8885 - val_accuracy: 0.7176 - val_loss: 1.4665\n",
      "Epoch 2/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7502 - loss: 1.0774 - val_accuracy: 0.7597 - val_loss: 0.9079\n",
      "Epoch 3/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7595 - loss: 0.9393 - val_accuracy: 0.7783 - val_loss: 0.8760\n",
      "Epoch 4/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7683 - loss: 0.8940 - val_accuracy: 0.7750 - val_loss: 0.8569\n",
      "Epoch 5/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7756 - loss: 0.8589 - val_accuracy: 0.7858 - val_loss: 0.8464\n",
      "Epoch 6/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7791 - loss: 0.8541 - val_accuracy: 0.7873 - val_loss: 0.8285\n",
      "Epoch 7/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7832 - loss: 0.8267 - val_accuracy: 0.7888 - val_loss: 0.8279\n",
      "Epoch 8/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7902 - loss: 0.8140 - val_accuracy: 0.7978 - val_loss: 0.8232\n",
      "Epoch 9/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7923 - loss: 0.7951 - val_accuracy: 0.7933 - val_loss: 0.8217\n",
      "Epoch 10/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7958 - loss: 0.7945 - val_accuracy: 0.7909 - val_loss: 0.8324\n",
      "Epoch 11/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7960 - loss: 0.7885 - val_accuracy: 0.7974 - val_loss: 0.8162\n",
      "Epoch 12/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8047 - loss: 0.7625 - val_accuracy: 0.7952 - val_loss: 0.8164\n",
      "Epoch 13/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8052 - loss: 0.7571 - val_accuracy: 0.7955 - val_loss: 0.8284\n",
      "Epoch 14/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7968 - loss: 0.7777 - val_accuracy: 0.7963 - val_loss: 0.8188\n",
      "Epoch 15/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8063 - loss: 0.7501 - val_accuracy: 0.8025 - val_loss: 0.8167\n",
      "Epoch 16/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8064 - loss: 0.7416 - val_accuracy: 0.7946 - val_loss: 0.8257\n",
      "Epoch 17/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8112 - loss: 0.7325 - val_accuracy: 0.7940 - val_loss: 0.8234\n",
      "Epoch 18/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8113 - loss: 0.7340 - val_accuracy: 0.8018 - val_loss: 0.8139\n",
      "Epoch 19/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8085 - loss: 0.7313 - val_accuracy: 0.7972 - val_loss: 0.8372\n",
      "Epoch 20/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8148 - loss: 0.7258 - val_accuracy: 0.7991 - val_loss: 0.8215\n",
      "Epoch 21/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8092 - loss: 0.7286 - val_accuracy: 0.8024 - val_loss: 0.8172\n",
      "Epoch 22/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8160 - loss: 0.7058 - val_accuracy: 0.8011 - val_loss: 0.8322\n",
      "Epoch 23/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8180 - loss: 0.6996 - val_accuracy: 0.7944 - val_loss: 0.8339\n",
      "Epoch 24/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8157 - loss: 0.7077 - val_accuracy: 0.7981 - val_loss: 0.8219\n",
      "Epoch 25/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8226 - loss: 0.6946 - val_accuracy: 0.7955 - val_loss: 0.8337\n",
      "Epoch 26/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8206 - loss: 0.6949 - val_accuracy: 0.7972 - val_loss: 0.8352\n",
      "Epoch 27/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8175 - loss: 0.7060 - val_accuracy: 0.7995 - val_loss: 0.8161\n",
      "Epoch 28/50\n",
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8188 - loss: 0.6845 - val_accuracy: 0.8021 - val_loss: 0.8159\n"
     ]
    }
   ],
   "source": [
    "gru_model, gru_history = training(\"GRU\", gru_model, X, y, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is hard to evaluate and compare different models in this type of problem. We want to overfitt to generate name that looks like dino names. But in the same time, we would like to not overfitt to much in order to generate new names.\n",
    "\n",
    "I propose to see how models learnt (overfitting ? generalization ?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_comparison(histories, model_names):\n",
    "    \"\"\"\n",
    "    Plots training and validation loss for multiple models on the same graph, with different line styles.\n",
    "    \n",
    "    Parameters:\n",
    "        histories (list): List of history objects from training different models.\n",
    "        model_names (list): List of model names corresponding to each history object.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Define line styles for each model\n",
    "    line_styles = ['-', '--', '-.', ':']  # Cycle through these styles for distinction\n",
    "    \n",
    "    for i, (history, model_name) in enumerate(zip(histories, model_names)):\n",
    "        style = line_styles[i % len(line_styles)]  # Cycle through line styles\n",
    "        \n",
    "        # Plot training and validation loss with distinct styles\n",
    "        plt.plot(history.history['loss'], linestyle=style, label=f'{model_name} Training Loss')\n",
    "        plt.plot(history.history['val_loss'], linestyle=style, label=f'{model_name} Validation Loss', alpha=0.7)\n",
    "    \n",
    "    plt.title('Training and Validation Loss for Multiple Models')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAD4AElEQVR4nOzdeXwM5x8H8M9kk93NHbkTSeSQkChJKu4r6gxSN3WHoIqijqpqCS1aRymqtCpBpVrq6OFWQcOvKNGUUEckjrhJJHLuzu+PNFMr97lLPu/Xa18v+8zzzHxndxLzzXOMIIqiCCIiIiIiIiqUnrYDICIiIiIi0nVMnIiIiIiIiIrBxImIiIiIiKgYTJyIiIiIiIiKwcSJiIiIiIioGEyciIiIiIiIisHEiYiIiIiIqBhMnIiIiIiIiIrBxImIiIiIiKgYTJyIqMKFhITA1dW1TG3DwsIgCELFBqRjrl27BkEQEBERUeXHFgQBYWFh0vuIiAgIgoBr164V29bV1RUhISEVGk95rpXq4tKlS+jYsSPMzc0hCAJ27Nih7ZDKJSoqCoIgICoqqti65f1Zef56f1GV5/cif8aIKg4TJ6JqRBCEEr1KckNDlWvChAkQBAGXL18utM7MmTMhCAL++uuvKoys9G7duoWwsDDExMRoOxRJ3g354sWLtR1KsYYNG4bY2FjMmzcPGzduREBAQKUdK+9zEQQBH3/8cYF1Bg0aBEEQYGJiUmHHjYyMxLJlyypsf5XF1dUVgiCgffv2BW7/+uuvpc/v1KlTVRwdEVU2fW0HQERVZ+PGjRrvN2zYgP379+cr9/b2Ltdxvv76a6jV6jK1/eCDD/Dee++V6/gvg0GDBmHFihWIjIzErFmzCqzz3XffoX79+mjQoEGZjzNkyBC88cYbUCgUZd5HcW7duoU5c+bA1dUVfn5+GtvKc61UB+np6Th+/DhmzpyJ8ePHV9lxlUolvvvuO3zwwQca5Wlpadi5cyeUSmWFHi8yMhJ///03Jk2apFFeq1YtpKenw8DAoEKPVx5KpRKHDh3C7du3YW9vr7Ft06ZNUCqVyMjI0FJ0RFSZ2ONEVI0MHjxY4+Xl5VVguZ2dnUa7p0+fluo4BgYGZb4R19fXr/CbshdRkyZNULt2bXz33XcFbj9+/Dji4+MxaNCgch1HJpNBqVRqbXhkea6V6uDevXsAAAsLiwrbZ1paWrF1unTpgvPnz+Ps2bMa5Tt37kRWVhY6dOhQYfEURRAEKJVKyGSyKjleSbRo0QImJib4/vvvNcpv3LiBo0ePomvXrlqKjIgqGxMnItIQGBiIV155BX/++Sdat24NIyMjvP/++wByb5q6du0KR0dHKBQKeHh44KOPPoJKpdLYx/Nj6p8dFvXVV1/Bw8MDCoUCjRo1wsmTJzXaFjSWXxAEjB8/Hjt27MArr7wChUKBevXqYc+ePfnij4qKQkBAAJRKJTw8PLBmzZoSzw84evQo+vbtCxcXFygUCjg7O+Odd95Benp6vvMzMTHBzZs30aNHD5iYmMDGxgZTp07N91k8fvwYISEhMDc3h4WFBYYNG4bHjx8XGwuQ2+t04cIFnD59Ot+2yMhICIKAAQMGICsrC7NmzULDhg1hbm4OY2NjtGrVCocOHSr2GAXNcRJFER9//DGcnJxgZGSEtm3b4ty5c/naPnz4EFOnTkX9+vVhYmICMzMzBAUFadxsR0VFoVGjRgCA4cOHS8OY8uasFDT/Ii0tDVOmTIGzszMUCgXq1KmDxYsXQxRFjXqluS7K6u7duwgNDYWdnR2USiV8fX2xfv36fPU2b96Mhg0bwtTUFGZmZqhfvz4+//xzaXt2djbmzJkDT09PKJVKWFlZoWXLlti/f3+hxw4LC0OtWrUAANOmTYMgCBqf1ZkzZxAUFAQzMzOYmJigXbt2+N///qexj7zv9/Dhwxg7dixsbW3h5ORU7Hk3a9YMbm5uiIyM1CjftGkTOnfuDEtLy3xtCptPVNzcuMDAQPz6669ISEiQro+88yxojlPez9/Vq1fRqVMnGBsbw9HREXPnzs13jRTk5s2bGDFiBOzs7KRrZt26dcW2y6NUKtGrV698n813332HGjVqoFOnTgW2++2339CqVSsYGxvDwsIC3bt3R1xcXL56v//+Oxo1aqTxO6ww3377LRo2bAhDQ0NYWlrijTfewPXr14s9h+KuVyIqGIfqEVE+Dx48QFBQEN544w2NHqiIiAiYmJhg8uTJMDExwW+//YZZs2YhJSUFixYtKna/kZGRePLkCd58800IgoCFCxeiV69euHr1arFDcX7//Xds27YNY8eOhampKZYvX47evXsjMTERVlZWAHJvJDt37gwHBwfMmTMHKpUKc+fOhY2NTYnOe8uWLXj69CneeustWFlZ4cSJE1ixYgVu3LiBLVu2aNRVqVTo1KkTmjRpgsWLF+PAgQNYsmQJPDw88NZbbwHITUC6d++O33//HWPGjIG3tze2b9+OYcOGlSieQYMGYc6cOYiMjMSrr76qcewffvgBrVq1gouLC+7fv4+1a9diwIABGDVqFJ48eYJvvvkGnTp1wokTJ/INjyvOrFmz8PHHH6NLly7o0qULTp8+jY4dOyIrK0uj3tWrV7Fjxw707dsXbm5uuHPnDtasWYM2bdrg/PnzcHR0hLe3N+bOnYtZs2Zh9OjRaNWqFQCgefPmBR5bFEW8/vrrOHToEEJDQ+Hn54e9e/di2rRpuHnzJpYuXapRvyTXRVmlp6cjMDAQly9fxvjx4+Hm5oYtW7YgJCQEjx8/xsSJEwEA+/fvx4ABA9CuXTt8+umnAIC4uDhER0dLdcLCwrBgwQKMHDkSjRs3RkpKCk6dOoXTp08X2nvTq1cvWFhY4J133sGAAQPQpUsXaV7RuXPn0KpVK5iZmeHdd9+FgYEB1qxZg8DAQBw+fBhNmjTR2NfYsWNhY2ODWbNmlajHCQAGDBiAb7/9Fp988gkEQcD9+/exb98+bNy4sUKT05kzZyI5ORk3btyQvt/i5k+pVCp07twZTZs2xcKFC7Fnzx7Mnj0bOTk5mDt3bqHt7ty5g6ZNm0pJt42NDXbv3o3Q0FCkpKTkGypYmIEDB6Jjx464cuUKPDw8AOT+fuvTp0+Bv8sOHDiAoKAguLu7IywsDOnp6VixYgVatGiB06dPS4libGwsOnbsCBsbG4SFhSEnJwezZ8/ONwoAAObNm4cPP/wQ/fr1w8iRI3Hv3j2sWLECrVu3xpkzZwrtpSzJ9UpEhRCJqNoaN26c+PyvgTZt2ogAxNWrV+er//Tp03xlb775pmhkZCRmZGRIZcOGDRNr1aolvY+PjxcBiFZWVuLDhw+l8p07d4oAxJ9//lkqmz17dr6YAIhyuVy8fPmyVHb27FkRgLhixQqpLDg4WDQyMhJv3rwplV26dEnU19fPt8+CFHR+CxYsEAVBEBMSEjTOD4A4d+5cjbr+/v5iw4YNpfc7duwQAYgLFy6UynJycsRWrVqJAMTw8PBiY2rUqJHo5OQkqlQqqWzPnj0iAHHNmjXSPjMzMzXaPXr0SLSzsxNHjBihUQ5AnD17tvQ+PDxcBCDGx8eLoiiKd+/eFeVyudi1a1dRrVZL9d5//30RgDhs2DCpLCMjQyMuUcz9rhUKhcZnc/LkyULP9/lrJe8z+/jjjzXq9enTRxQEQeMaKOl1UZC8a3LRokWF1lm2bJkIQPz222+lsqysLLFZs2aiiYmJmJKSIoqiKE6cOFE0MzMTc3JyCt2Xr6+v2LVr1yJjKk2cPXr0EOVyuXjlyhWp7NatW6KpqanYunVrqSzv+23ZsmWR8RV0vL///lsEIB49elQURVH84osvRBMTEzEtLU0cNmyYaGxsrNH2+WsrT61atTSum0OHDokAxEOHDkllXbt21bgOno/n2Wsn7+fv7bfflsrUarXYtWtXUS6Xi/fu3Ss0ptDQUNHBwUG8f/++xnHeeOMN0dzcvMDfAc+fS9euXcWcnBzR3t5e/Oijj0RRFMXz58+LAMTDhw9Ln/nJkyeldn5+fqKtra344MEDqezs2bOinp6eOHToUKmsR48eolKp1Ph9c/78eVEmk2n8Drt27Zook8nEefPmacQXGxsr6uvra5Q//zNWkuuViArGoXpElI9CocDw4cPzlRsaGkr/fvLkCe7fv49WrVrh6dOnuHDhQrH77d+/P2rUqCG9z+t9uHr1arFt27dvL/1lFwAaNGgAMzMzqa1KpcKBAwfQo0cPODo6SvVq166NoKCgYvcPaJ5fWloa7t+/j+bNm0MURZw5cyZf/TFjxmi8b9Wqlca57Nq1C/r6+lIPFJA7p+jtt98uUTxA7vyzGzdu4MiRI1JZZGQk5HI5+vbtK+1TLpcDANRqNR4+fIicnBwEBAQUOMyvKAcOHEBWVhbefvttjeGNBf0lXqFQQE8v978RlUqFBw8ewMTEBHXq1Cn1cfPs2rULMpkMEyZM0CifMmUKRFHE7t27NcqLuy7KY9euXbC3t8eAAQOkMgMDA0yYMAGpqak4fPgwgNz5R2lpaUUOu7OwsMC5c+dw6dKlcselUqmwb98+9OjRA+7u7lK5g4MDBg4ciN9//x0pKSkabUaNGlXqeUL16tVDgwYNpHl2kZGR6N69O4yMjMp9DhXh2cUy8nqQsrKycODAgQLri6KIH3/8EcHBwRBFEffv35denTp1QnJycomvW5lMhn79+kmfzaZNm+Ds7Cz9TntWUlISYmJiEBISojHEsUGDBujQoQN27doFIPd73bt3L3r06AEXFxepnre3d77hf9u2bYNarUa/fv00zsPe3h6enp5FDtMtyfVKRAVj4kRE+dSsWVO6EX/WuXPn0LNnT5ibm8PMzAw2NjYYPHgwACA5ObnY/T57MwBASqIePXpU6rZ57fPa3r17F+np6ahdu3a+egWVFSQxMVG6ucmbt9SmTRsA+c9PqVTmGwL4bDwAkJCQAAcHh3zDjurUqVOieADgjTfegEwmk+ZTZGRkYPv27QgKCtJIQtevX48GDRpI82dsbGzw66+/luh7eVZCQgIAwNPTU6PcxsZG43hAbpK2dOlSeHp6QqFQwNraGjY2Nvjrr79Kfdxnj+/o6AhTU1ON8ryVHvPiy1PcdVEeCQkJ8PT0lJLDwmIZO3YsvLy8EBQUBCcnJ4wYMSLfULa5c+fi8ePH8PLyQv369TFt2rQyLyN/7949PH36tMDryNvbG2q1Ot88Fzc3tzIda+DAgdiyZQsuX76MY8eOYeDAgWXaT0XT09PTSBoBSIvdFPZMsnv37uHx48f46quvYGNjo/HK+0PR3bt3SxzDwIEDpQU0IiMj8cYbbxQ4lzLvOins+7p//z7S0tJw7949pKen5/vZK6jtpUuXIIoiPD09851LXFxckedRkuuViArGOU5ElM+zPS95Hj9+jDZt2sDMzAxz586Fh4cHlEolTp8+jenTp5doSenC/uItlmBCd3naloRKpUKHDh3w8OFDTJ8+HXXr1oWxsTFu3ryJkJCQfOdXVat82draokOHDvjxxx/xxRdf4Oeff8aTJ080VtP79ttvERISgh49emDatGmwtbWFTCbDggULcOXKlUqLbf78+fjwww8xYsQIfPTRR7C0tISenh4mTZpUZUuMV/Z1URK2traIiYnB3r17sXv3buzevRvh4eEYOnSotJBE69atceXKFezcuRP79u3D2rVrsXTpUqxevRojR46s9BgL+pkuiQEDBmDGjBkYNWoUrKys0LFjx1Lv4/kFU7Ql75ocPHhwofMMS7O0f5MmTeDh4YFJkyYhPj6+SpNKtVoNQRCwe/fuAn8GipojVpLrlYgKxsSJiEokKioKDx48wLZt29C6dWupPD4+XotR/cfW1hZKpbLAB8YW9RDZPLGxsfjnn3+wfv16DB06VCovz3CWWrVq4eDBg0hNTdW4kbl48WKp9jNo0CDs2bMHu3fvRmRkJMzMzBAcHCxt37p1K9zd3bFt2zaNv3jPnj27TDEDuX/RfvYv+vfu3cvXi7N161a0bdsW33zzjUb548ePYW1tLb0vzVLntWrVwoEDB/DkyRONXqe8oaB58VWFWrVq4a+//oJardbodSooFrlcjuDgYAQHB0OtVmPs2LFYs2YNPvzwQ6nH09LSEsOHD8fw4cORmpqK1q1bIywsrNSJk42NDYyMjAq8ji5cuAA9PT04OzuX5ZTzcXFxQYsWLRAVFYW33noL+vqF3zbUqFEj34qRWVlZSEpKKvY4pV0OX61W4+rVq1IvEwD8888/AJBvlcY8NjY2MDU1hUqlKvQBtqU1YMAAfPzxx/D29i50EZa866Sw78va2hrGxsZQKpUwNDQscDjn8209PDwgiiLc3Nw0PoOSKsn1SkT5cageEZVI3l81n/1LflZWFlatWqWtkDTIZDK0b98eO3bswK1bt6Tyy5cv55sXU1h7QPP8RFEs1xK9Xbp0QU5ODr788kupTKVSYcWKFaXaT48ePWBkZIRVq1Zh9+7d6NWrl8azrgqK/Y8//sDx48dLHXP79u1hYGCAFStWaOxv2bJl+erKZLJ8PTtbtmzBzZs3NcqMjY0BoETLsHfp0gUqlQorV67UKF+6dCkEQSjxfLWK0KVLF9y+fVvjeT05OTlYsWIFTExMpGGcDx480Ginp6cn9VxkZmYWWMfExAS1a9eWtpeGTCZDx44dsXPnTo1haXfu3EFkZCRatmwJMzOzUu+3MB9//DFmz55d7Nw8Dw8Pjbl4APDVV1+VqMfJ2Ni41MM7n71GRFHEypUrYWBggHbt2hVYXyaToXfv3vjxxx/x999/59ue98ys0hg5ciRmz56NJUuWFFrHwcEBfn5+WL9+vcbPwN9//419+/ahS5cuUnydOnXCjh07kJiYKNWLi4vD3r17NfbZq1cvyGQyzJkzJ9/PoCiK+a63Z5XkeiWigrHHiYhKpHnz5qhRowaGDRuGCRMmQBAEbNy4sUqHRBUnLCwM+/btQ4sWLfDWW29JN+CvvPIKYmJiimxbt25deHh4YOrUqbh58ybMzMzw448/lmuuTHBwMFq0aIH33nsP165dg4+PD7Zt21bqG0QTExP06NFDmuf0/ENvu3Xrhm3btqFnz57o2rUr4uPjsXr1avj4+CA1NbVUx8p7HtWCBQvQrVs3dOnSBWfOnMHu3bs1epHyjjt37lwMHz4czZs3R2xsLDZt2pRv7omHhwcsLCywevVqmJqawtjYGE2aNClw3k1wcDDatm2LmTNn4tq1a/D19cW+ffuwc+dOTJo0SWMhiIpw8OBBZGRk5Cvv0aMHRo8ejTVr1iAkJAR//vknXF1dsXXrVkRHR2PZsmVSj9jIkSPx8OFDvPbaa3ByckJCQgJWrFgBPz8/aT6Uj48PAgMD0bBhQ1haWuLUqVPYunWrxgIHpfHxxx9j//79aNmyJcaOHQt9fX2sWbMGmZmZWLhwYdk/kAK0adNGShKLMnLkSIwZMwa9e/dGhw4dcPbsWezduzffdVOQhg0b4vvvv8fkyZPRqFEjmJiYaPSqPk+pVGLPnj0YNmwYmjRpgt27d+PXX3/F+++/X+TjBz755BMcOnQITZo0wahRo+Dj44OHDx/i9OnTOHDgAB4+fFhsrM+qVatWgc+uet6iRYsQFBSEZs2aITQ0VFqO3NzcXKP9nDlzsGfPHrRq1Qpjx46VEvV69eppzInz8PDAxx9/jBkzZuDatWvo0aMHTE1NER8fj+3bt2P06NGYOnVqgbGU5HolokJU8Sp+RKRDCluOvF69egXWj46OFps2bSoaGhqKjo6O4rvvvivu3bs339LChS1HXtDSz3huueDCliMfN25cvrbPL3MsiqJ48OBB0d/fX5TL5aKHh4e4du1accqUKaJSqSzkU/jP+fPnxfbt24smJiaitbW1OGrUKGl56+eXQ35+KebCYn/w4IE4ZMgQ0czMTDQ3NxeHDBkinjlzpsTLkef59ddfRQCig4NDviXA1Wq1OH/+fLFWrVqiQqEQ/f39xV9++SXf9yCKxS9HLoqiqFKpxDlz5ogODg6ioaGhGBgYKP7999/5Pu+MjAxxypQpUr0WLVqIx48fF9u0aSO2adNG47g7d+4UfXx8pKXh8869oBifPHkivvPOO6Kjo6NoYGAgenp6iosWLdJYHj3vXEp6XTwv75os7LVx40ZRFEXxzp074vDhw0Vra2tRLpeL9evXz/e9bd26VezYsaNoa2sryuVy0cXFRXzzzTfFpKQkqc7HH38sNm7cWLSwsBANDQ3FunXrivPmzROzsrJKFGdBPzunT58WO3XqJJqYmIhGRkZi27ZtxWPHjmnUKWhp7LIe71kF/QyoVCpx+vTporW1tWhkZCR26tRJvHz5comWI09NTRUHDhwoWlhYiACka6Kw5ciNjY3FK1euiB07dhSNjIxEOzs7cfbs2fl+Np6/3kUx9zsdN26c6OzsLBoYGIj29vZiu3btxK+++qrYzydvOfKiFPaZHzhwQGzRooVoaGgompmZicHBweL58+fztT98+LDYsGFDUS6Xi+7u7uLq1asL/N0iiqL4448/ii1bthSNjY1FY2NjsW7duuK4cePEixcvSnWe/xkryfVKRAUTRFGH/lxMRFQJevToUWFLQRORdoWEhGDr1q2l7k0lIiovznEiopdKenq6xvtLly5h165dCAwM1E5ARERE9FLgHCcieqm4u7sjJCQE7u7uSEhIwJdffgm5XI53331X26ERERHRC4yJExG9VDp37ozvvvsOt2/fhkKhQLNmzTB//vwCHypJREREVFKc40RERERERFQMznEiIiIiIiIqBhMnIiIiIiKiYlS7OU5qtRq3bt2CqakpBEHQdjhERERERKQloijiyZMncHR0hJ5e0X1K1S5xunXrFpydnbUdBhERERER6Yjr16/DycmpyDrVLnEyNTUFkPvhmJmZaTkaIiIiIiLSlpSUFDg7O0s5QlGqXeKUNzzPzMyMiRMREREREZVoCg8XhyAiIiIiIioGEyciIiIiIqJiMHEiIiIiIiIqRrWb40RERETaIYoicnJyoFKptB0KEVUjBgYGkMlk5d4PEyciIiKqdFlZWUhKSsLTp0+1HQoRVTOCIMDJyQkmJibl2g8TJyIiIqpUarUa8fHxkMlkcHR0hFwu50PoiahKiKKIe/fu4caNG/D09CxXzxMTJyIiIqpUWVlZUKvVcHZ2hpGRkbbDIaJqxsbGBteuXUN2dna5EicuDkFERERVQk+Ptx1EVPUqqoebv8GIiIiIiIiKwcSJiIiIiIioGEyciIiIiEgSFhYGPz+/UrVxdXXFsmXLKiUeIl3BxImIiIioACEhIejRo0eh28+ePYvXX38dtra2UCqVcHV1Rf/+/XH37l2EhYVBEIQiX3nHEAQBY8aMybf/cePGQRAEhISEFBpfUft3dXUt03lPnToVBw8eLFWbkydPYvTo0WU6XmkwQSNtYuJEREREVEr37t1Du3btYGlpib179yIuLg7h4eFwdHREWloapk6diqSkJOnl5OSEuXPnapTlcXZ2xubNm5Geni6VZWRkIDIyEi4uLoXG8Pnnn+fbX3h4uPT+5MmTGvWzsrJKdG4mJiawsrIqzccBGxsbrphILz0mTkRERFTlRFHE06ycKn+Jolgh8UdHRyM5ORlr166Fv78/3Nzc0LZtWyxduhRubm4wMTGBvb299JLJZDA1NdUoy/Pqq6/C2dkZ27Ztk8q2bdsGFxcX+Pv7FxqDubl5vv1ZWFhI7xs1aoSPPvoIQ4cOhZmZmdQjNH36dHh5ecHIyAju7u748MMPkZ2dLe33+aF6eT1vixcvhoODA6ysrDBu3DiNNs/3BAmCgLVr16Jnz54wMjKCp6cnfvrpJ434f/rpJ3h6ekKpVKJt27ZYv349BEHA48ePS/VdPOvLL7+Eh4cH5HI56tSpg40bN0rbRFFEWFgYXFxcoFAo4OjoiAkTJkjbV61aJcVjZ2eHPn36lDkOejnxOU5ERERU5dKzVfCZtbfKj3t+bicYyct/+2Nvb4+cnBxs374dffr0KfdyxyNGjEB4eDgGDRoEAFi3bh2GDx+OqKiocu138eLFmDVrFmbPni2VmZqaIiIiAo6OjoiNjcWoUaNgamqKd999t9D9HDp0CA4ODjh06BAuX76M/v37w8/PD6NGjSq0zZw5c7Bw4UIsWrQIK1aswKBBg5CQkABLS0vEx8ejT58+mDhxIkaOHIkzZ85g6tSp5TrX7du3Y+LEiVi2bBnat2+PX375BcOHD4eTkxPatm2LH3/8EUuXLsXmzZtRr1493L59G2fPngUAnDp1ChMmTMDGjRvRvHlzPHz4EEePHi1XPPTyYY8TERERUSk1bdoU77//PgYOHAhra2sEBQVh0aJFuHPnTpn2N3jwYPz+++9ISEhAQkICoqOjMXjw4HLH+dprr2HKlCnw8PCAh4cHAOCDDz5A8+bN4erqiuDgYEydOhU//PBDkfupUaMGVq5cibp166Jbt27o2rVrsfOgQkJCMGDAANSuXRvz589HamoqTpw4AQBYs2YN6tSpg0WLFqFOnTp44403Cp3LVVKLFy9GSEgIxo4dCy8vL0yePBm9evXC4sWLAQCJiYmwt7dH+/bt4eLigsaNG0uJX2JiIoyNjdGtWzfUqlUL/v7+Gr1RRAB7nIiIiEgLDA1kOD+3k1aOW1HmzZuHyZMn47fffsMff/yB1atXY/78+Thy5Ajq169fqn3Z2Niga9euiIiIgCiK6Nq1K6ytrcsdY0BAQL6y77//HsuXL8eVK1eQmpqKnJwcmJmZFbmfevXqQSb777NzcHBAbGxskW0aNGgg/dvY2BhmZma4e/cuAODixYto1KiRRv3GjRsXez5FiYuLy7dARYsWLfD5558DAPr27Ytly5bB3d0dnTt3RpcuXRAcHAx9fX106NABtWrVkrZ17txZGmZIlIc9TlqUlpyJxPMPcPtqsrZDISIiqlKCIMBIrl/lr/IOqXuelZUV+vbti8WLFyMuLg6Ojo5SD0dpjRgxAhEREVi/fj1GjBhRIfEZGxtrvD9+/DgGDRqELl264JdffsGZM2cwc+bMYheOMDAw0HgvCALUanWFt6lMzs7OuHjxIlatWgVDQ0OMHTsWrVu3RnZ2NkxNTXH69Gl89913cHBwwKxZs+Dr61uu+Vb08mHipEXXzz/Ez8vP4uQv8doOhYiIiMpJLpfDw8MDaWlpZWrfuXNnZGVlITs7G506VU5v3LFjx1CrVi3MnDkTAQEB8PT0REJCQqUcqyh16tTBqVOnNMqeXwWwtLy9vREdHa1RFh0dDR8fH+m9oaEhgoODsXz5ckRFReH48eNSz5m+vj7at2+PhQsX4q+//sK1a9fw22+/lSsmerlwqJ4WyQ1zP/7M9BwtR0JEREQFSU5ORkxMjEaZlZUVzp49i82bN+ONN96Al5cXRFHEzz//jF27diE8PLxMx5LJZIiLi5P+XRk8PT2RmJiIzZs3o1GjRvj111+xffv2SjlWUd5880189tlnmD59OkJDQxETE4OIiAgAKLZX8ObNm/m+k1q1amHatGno168f/P390b59e/z888/Ytm0bDhw4AACIiIiASqVCkyZNYGRkhG+//RaGhoaoVasWfvnlF1y9ehWtW7dGjRo1sGvXLqjVatSpU6cyTp9eUEyctCgvccpi4kRERKSToqKi8i0JHhoaivfffx9GRkaYMmUKrl+/DoVCAU9PT6xduxZDhgwp8/GKm2tUXq+//jreeecdjB8/HpmZmejatSs+/PBDhIWFVepxn+fm5oatW7diypQp+Pzzz9GsWTPMnDkTb731FhQKRZFtFy9enG845MaNGzF48GB8/vnnWLx4MSZOnAg3NzeEh4cjMDAQQO5S7Z988gkmT54MlUqF+vXr4+eff4aVlRUsLCywbds2hIWFISMjA56envjuu+9Qr169yvoI6AUkiBX1QIMXREpKCszNzZGcnFzpv5yKczchBVsWnIKxuRwhn7bUaixERESVJSMjA/Hx8XBzc4NSqdR2OKSj5s2bh9WrV+P69evaDoVeMkX9DipNbsAeJy2ShuplqLQcCREREVHVWrVqFRo1agQrKytER0dj0aJFGD9+vLbDIioUEyctUvybOOVkqqBWi9DTq9iVfoiIiIh01aVLl/Dxxx/j4cOHcHFxwZQpUzBjxgxth0VUKCZOWpTX4wTkznNSGhsUUZuIiIjo5bF06VIsXbpU22EQlZhWlyNfsGABGjVqBFNTU9ja2qJHjx64ePFise22bNmCunXrQqlUon79+ti1a1cVRFvxZPp6kBnkfgVcIIKIiIiISHdpNXE6fPgwxo0bh//973/Yv38/srOz0bFjxyKff3Ds2DEMGDAAoaGhOHPmDHr06IEePXrg77//rsLIK460sl4GEyciIiIiIl2l1aF6e/bs0XgfEREBW1tb/Pnnn2jdunWBbT7//HN07twZ06ZNAwB89NFH2L9/P1auXInVq1dXeswVTWGoj/SULPY4ERERERHpMK32OD0vOTkZAGBpaVlonePHj6N9+/YaZZ06dcLx48cLrJ+ZmYmUlBSNly6RK3MfcJeVzpX1iIiIiIh0lc4kTmq1GpMmTUKLFi3wyiuvFFrv9u3bsLOz0yizs7PD7du3C6y/YMECmJubSy9nZ+cKjbu8pCXJ2eNERERERKSzdCZxGjduHP7++29s3ry5Qvc7Y8YMJCcnSy9de6haXuKUnckeJyIiIiIiXaUTidP48ePxyy+/4NChQ3Byciqyrr29Pe7cuaNRdufOHdjb2xdYX6FQwMzMTOOlS9oN88aYFYF4pXVNbYdCRERE1VBERAQsLCyk92FhYfDz8yuyTUhICHr06FHuY1fUfoiqglYTJ1EUMX78eGzfvh2//fYb3Nzcim3TrFkzHDx4UKNs//79aNasWWWFWankSn1pSXIiIiLSHcXd1J89exavv/46bG1toVQq4erqiv79++Pu3bsICwuDIAhFvvKOIQgCxowZk2//48aNgyAICAkJKfD4P/74I2QyGW7evFngdk9PT0yePLnU5z116tR891rlde3aNQiCgJiYGI3yzz//HBERERV6rIIIgoAdO3ZU+nHo5abVO/Zx48bh22+/RWRkJExNTXH79m3cvn0b6enpUp2hQ4dqPEV64sSJ2LNnD5YsWYILFy4gLCwMp06dwvjx47VxCkRERFQN3bt3D+3atYOlpSX27t2LuLg4hIeHw9HREWlpaZg6dSqSkpKkl5OTE+bOnatRlsfZ2RmbN2/WuP/JyMhAZGQkXFxcCo3h9ddfh5WVFdavX59v25EjR3D58mWEhoaW+txMTExgZWVV6nZlYW5urtHbRaTLtJo4ffnll0hOTkZgYCAcHByk1/fffy/VSUxM1Pjl0rx5c0RGRuKrr76Cr68vtm7dih07dhS5oIQuu3HxEfaHn8OZ/YnaDoWIiKjqiCKQnVH1L1GskPCjo6ORnJyMtWvXwt/fH25ubmjbti2WLl0KNzc3mJiYwN7eXnrJZDKYmppqlOV59dVX4ezsjG3btkll27Ztg4uLC/z9/QuNwcDAAEOGDCmwx2bdunVo0qQJ6tWrh88++wz169eHsbExnJ2dMXbsWKSmpha63+eH6qlUKkyePBkWFhawsrLCu+++C/G5z3HPnj1o2bKlVKdbt264cuWKtD1vVJG/vz8EQUBgYCCA/L16mZmZmDBhgtSL17JlS5w8eVLaHhUVBUEQcPDgQQQEBMDIyAjNmzfHxYsXCz2f4qjVasydOxdOTk5QKBTw8/PTeGROVlYWxo8fDwcHByiVStSqVQsLFiwAkDt6KiwsDC4uLlAoFHB0dMSECRPKHAvpNq0+x+n5H7qCREVF5Svr27cv+vbtWwkRVb2U++n45487yEzLgX+Hwv+qRERE9FLJyQS2DKv64/ZdDxgoy70be3t75OTkYPv27ejTp4809K6sRowYgfDwcAwaNAhAbuIzfPjwAu+DnhUaGorPPvsMR44ckZ6BmZqaiq1bt2Lp0qUAAD09PSxfvhxubm64evUqxo4di3fffRerVq0qUWxLlixBREQE1q1bB29vbyxZsgTbt2/Ha6+9JtVJS0vD5MmT0aBBA6SmpmLWrFno2bMnYmJioKenhxMnTqBx48Y4cOAA6tWrB7lcXuCx3n33Xfz4449Yv349atWqhYULF6JTp064fPmyxuNqZs6ciSVLlsDGxgZjxozBiBEjEB0dXaLzed7nn3+OJUuWYM2aNfD398e6devw+uuv49y5c/D09MTy5cvx008/4YcffoCLiwuuX78uLTb2448/YunSpdi8eTPq1auH27dv4+zZs2WKg3QfJ9domZ2bGZr3qo16XByCiIjohdG0aVO8//77GDhwIKytrREUFIRFixblW8CqpAYPHozff/8dCQkJSEhIQHR0NAYPHlxsOx8fHzRt2hTr1q2Tyn744QeIoog33ngDADBp0iS0bdsWrq6ueO211/Dxxx/jhx9+KHFsy5Ytw4wZM9CrVy94e3tj9erVMDc316jTu3dv9OrVC7Vr14afnx/WrVuH2NhYnD9/HgBgY2MDALCysoK9vX2Bz+xMS0vDl19+iUWLFiEoKAg+Pj74+uuvYWhoiG+++Uaj7rx589CmTRv4+Pjgvffew7Fjx5CRkVHic3rW4sWLMX36dLzxxhuoU6cOPv30U/j5+WHZsmUAckc/eXp6omXLlqhVqxZatmyJAQMGSNvs7e3Rvn17uLi4oHHjxhg1alSZ4iDdp9UeJwKsHE1g5Wii7TCIiIiqlr4it/dHG8etIPPmzcPkyZPx22+/4Y8//sDq1asxf/58HDlyBPXr1y/VvmxsbNC1a1dERERAFEV07doV1tbWJWo7YsQIvPPOO1ixYgVMTU2xbt069O3bF6ampgCAAwcOYMGCBbhw4QJSUlKQk5ODjIwMPH36FEZGRkXuOzk5GUlJSWjSpIlUpq+vj4CAAI2RQ5cuXcKsWbPwxx9/4P79+1Cr1QByE4uSTqe4cuUKsrOz0aJFC6nMwMAAjRs3RlxcnEbdBg0aSP92cHAAANy9e7fIOWEFSUlJwa1btzSOCQAtWrSQeo5CQkLQoUMH1KlTB507d0a3bt3QsWNHALmjoJYtWwZ3d3d07twZXbp0QXBwMPT1eYv9MmKPExEREVU9QcgdMlfVr3IOqXuelZUV+vbti8WLFyMuLg6Ojo5YvHhxmfY1YsQIREREYP369RgxYkSJ2+X1LP3www+4dOkSoqOjpUUhrl27hm7duqFBgwb48ccf8eeff+KLL74AkDt3p6IEBwfj4cOH+Prrr/HHH3/gjz/+qPBjPMvAwED6d94wybxkraK9+uqriI+Px0cffYT09HT069cPffr0AZC7sMfFixexatUqGBoaYuzYsWjdujWys7MrJRbSLiZOWqbKUeNOfApuXHio7VCIiIioHORyOTw8PJCWllam9p07d0ZWVhays7PRqVOnErczNTVF3759sW7dOoSHh8PLywutWrUCAPz5559Qq9VYsmQJmjZtCi8vL9y6davE+zY3N4eDg4OUCAFATk4O/vzzT+n9gwcPcPHiRXzwwQdo164dvL298ejRI4395M1pUqlUhR7Lw8MDcrlcY65SdnY2Tp48CR8fnxLHXBpmZmZwdHTMNz8qOjpa45hmZmbo378/vv76a3z//ff48ccf8fBh7r2boaEhgoODsXz5ckRFReH48eOIjY2tlHhJu9iPqGUZadnY+ukpQADGftEWgl7F/iWMiIiIyi45OTnfs4esrKxw9uxZbN68GW+88Qa8vLwgiiJ+/vln7Nq1C+Hh4WU6lkwmk4akyWSyUrUNDQ1Fq1atEBcXh+nTp0vltWvXRnZ2NlasWIHg4GBER0dj9erVpdr3xIkT8cknn8DT0xN169bFZ599hsePH0vba9SoASsrK3z11VdwcHBAYmIi3nvvPY192NrawtDQEHv27IGTkxOUSmW+eVLGxsZ46623MG3aNFhaWsLFxQULFy7E06dPy7Ss+vPi4+PzfZeenp6YNm0aZs+eDQ8PD/j5+SE8PBwxMTHYtGkTAOCzzz6Dg4MD/P39oaenhy1btsDe3h4WFhaIiIiASqVCkyZNYGRkhG+//RaGhoaoVatWueMl3cPEScsUhv9+BSKQnamC3JBfCRERka6IiorKtyR4aGgo3n//fRgZGWHKlCm4fv06FAoFPD09sXbtWgwZMqTMxzMzMytTu5YtW6JOnTq4fPkyhg4dKpX7+vris88+w6effooZM2agdevWWLBggUad4kyZMgVJSUkYNmwY9PT0MGLECPTs2RPJyckAclft27x5MyZMmIBXXnkFderUwfLly6Ulx4HceVHLly/H3LlzMWvWLLRq1arAFQM/+eQTqNVqDBkyBE+ePEFAQAD27t2LGjVqlOlzeVZBDwM+evQoJkyYgOTkZEyZMgV3796Fj48PfvrpJ3h6egLI7dFbuHAhLl26BJlMhkaNGmHXrl3Q09ODhYUFPvnkE0yePBkqlQr169fHzz//XGXPwaKqJYglWRP8JZKSkgJzc3MkJyeX+ZdTRRJFEavHR0GtEjFsQXOY1Cj/EqlERES6JCMjA/Hx8XBzc4NSyf/niKhqFfU7qDS5Aec4aZkgCFIvU2Z6jpajISIiIiKigjBx0gF5iVNWeuETJomIiIiISHuYOOkAuTJ3AmgWe5yIiIiIiHQSEycdoJB6nJg4ERERERHpIiZOOoBznIiIiIiIdBsTJx0gZ48TEREREZFOY+KkA5g4ERERERHpNiZOOkCa45TBVfWIiIiIiHQREycdIFeyx4mIiIiISJcxcdIBcsPc5ci5OAQRERFVJkEQsGPHjiLrhISEoEePHlUSD2lydXXFsmXLSlw/KioKgiDg8ePHlRYT/YeJkw7wbGSH4QtbotOoetoOhYiIiP5VXAJx9uxZvP7667C1tYVSqYSrqyv69++Pu3fvIiwsDIIgFPnKO4YgCBgzZky+/Y8bNw6CICAkJKTCzikpKQlBQUEAgGvXrkEQBMTExJR7vxEREdJ5yWQy1KhRA02aNMHcuXORnJxc7v1XpZIkjsV9t2FhYWU69smTJzF69OgS12/evDmSkpJgbm5epuOVFBO0XEycdIBcqQ8jMzn0DWTaDoWIiIhK4N69e2jXrh0sLS2xd+9exMXFITw8HI6OjkhLS8PUqVORlJQkvZycnDB37lyNsjzOzs7YvHkz0tPTpbKMjAxERkbCxcWlQuO2t7eHQqGo0H3mMTMzQ1JSEm7cuIFjx45h9OjR2LBhA/z8/HDr1q1C22VlZVVKPJXp2e9x2bJl0rnnvaZOnSrVFUUROTklG1VkY2MDIyOjEschl8thb28vJeJUuZg4ERERkdY8zX5a6CtTlVniuhk5GcXWrUjR0dFITk7G2rVr4e/vDzc3N7Rt2xZLly6Fm5sbTExMYG9vL71kMhlMTU01yvK8+uqrcHZ2xrZt26Sybdu2wcXFBf7+/oXGIIoibGxssHXrVqnMz88PDg4O0vvff/8dCoUCT5/mnv+zQ/Xc3NwAAP7+/hAEAYGBgRr7X7x4MRwcHGBlZYVx48YhOzu7yM9EEATY29vDwcEB3t7eCA0NxbFjx5Camop3331XqhcYGIjx48dj0qRJsLa2RqdOnQAAhw8fRuPGjaFQKODg4ID33ntPI+HIazd+/HiYm5vD2toaH374IURRlOo8evQIQ4cORY0aNWBkZISgoCBcunRJ2h4WFgY/Pz+NuJctWwZXV1dp+/r167Fz506p9ygqKirfuT77PZqbm0vnbm9vjwsXLsDU1BS7d+9Gw4YNoVAo8Pvvv+PKlSvo3r077OzsYGJigkaNGuHAgQMa+31+qJ4gCFi7di169uwJIyMjeHp64qeffpK2P98TFBERAQsLC+zduxfe3t4wMTFB586dNRL1nJwcTJgwARYWFrCyssL06dMxbNiwcg3PLO5zT0hIQHBwMGrUqAFjY2PUq1cPu3btktoOGjQINjY2MDQ0hKenJ8LDw8scS2XS13YABKQ/ycLJX69BrRYROLCOtsMhIiKqMk0imxS6rVXNVljVfpX0PvCHQKTnpBdYN8AuAOGd/7vZ6vxjZzzKfKRRJ3ZYbDmj/Y+9vT1ycnKwfft29OnTp9x/8R8xYgTCw8MxaNAgAMC6deswfPjwAm/a8wiCgNatWyMqKgp9+vTBo0ePEBcXB0NDQ1y4cAF169bF4cOH0ahRowJ7MU6cOIHGjRvjwIEDqFevHuRyubTt0KFDcHBwwKFDh3D58mX0798ffn5+GDVqVKnOy9bWFoMGDcK6deugUqkgk+WOrlm/fj3eeustREdHAwBu3ryJLl26ICQkBBs2bMCFCxcwatQoKJVKjWFv69evR2hoKE6cOIFTp05h9OjRcHFxkeIKCQnBpUuX8NNPP8HMzAzTp09Hly5dcP78eRgYGBQb79SpUxEXF4eUlBTp5t3S0rJU55znvffew+LFi+Hu7o4aNWrg+vXr6NKlC+bNmweFQoENGzYgODgYFy9eLLJncc6cOVi4cCEWLVqEFStWYNCgQUhISCg0rqdPn2Lx4sXYuHEj9PT0MHjwYEydOhWbNm0CAHz66afYtGkTwsPD4e3tjc8//xw7duxA27Zty3SeQPGf+7hx45CVlYUjR47A2NgY58+fh4mJCQDgww8/xPnz57F7925YW1vj8uXLGr2vuoSJkw5Q5agRG3UDgp6ANgO82N1KRESk45o2bYr3338fAwcOxJgxY9C4cWO89tprGDp0KOzs7Eq9v8GDB2PGjBlISEgAkNujtXnz5iITJyC3F2bNmjUAgCNHjsDf3x/29vaIiopC3bp1ERUVhTZt2hTY1sbGBgBgZWWl0QMGADVq1MDKlSshk8lQt25ddO3aFQcPHix14gQAdevWxZMnT/DgwQPY2toCADw9PbFw4UKpzsyZM+Hs7IyVK1dCEATUrVsXt27dwvTp0zFr1izo6eUOknJ2dsbSpUshCALq1KmD2NhYLF26FKNGjZJu3KOjo9G8eXMAwKZNm+Ds7IwdO3agb9++xcZqYmICQ0NDZGZm5vtMSmvu3Lno0KGD9N7S0hK+vr7S+48++gjbt2/HTz/9hPHjxxe6n5CQEAwYMAAAMH/+fCxfvhwnTpxA586dC6yfnZ2N1atXw8PDAwAwfvx4zJ07V9q+YsUKzJgxAz179gQArFy5Uur9KYuSfO6JiYno3bs36tevDwBwd3eX2icmJsLf3x8BAQEAIPX+6SImTjpAaWyAhkG1IDfUhygCzJuIiKi6+GPgH4Vuk+lpzv2N6hdVaF09QXP2wZ7ee8oVV0nMmzcPkydPxm+//YY//vgDq1evxvz583HkyBHpBrGkbGxs0LVrV0REREAURXTt2hXW1tbFtmvTpg0mTpyIe/fu4fDhwwgMDJQSp7yhcs8OkyupevXqSb1DAODg4IDY2LL12OUNpXv2D8MNGzbUqBMXF4dmzZpp1GnRogVSU1Nx48YNqUemadOmGnWaNWuGJUuWQKVSIS4uDvr6+mjS5L9eTCsrK9SpUwdxcXFlir088hKBPKmpqQgLC8Ovv/6KpKQk5OTkID09HYmJiUXup0GDBtK/jY2NYWZmhrt37xZa38jISEqagNzvLq9+cnIy7ty5g8aNG0vbZTIZGjZsCLVaXarzy1OSz33ChAl46623sG/fPrRv3x69e/eWzuutt95C7969cfr0aXTs2BE9evSQEjBdwzlOOkBfLkPT7h54tWMt6OkxayIiourDyMCo0JdCpihxXaW+sti6lcHKygp9+/bF4sWLERcXB0dHRyxevLhM+xoxYgQiIiKwfv16jBgxokRt6tevD0tLSxw+fFhKnAIDA3H48GGcPHkS2dnZZboJfX5YmyAI5bqxNjMzg5WVlVRmbGxcpn2Vl56ensacKADFzt0qq+fPcerUqdi+fTvmz5+Po0ePIiYmBvXr1y92cYzSfhcF1X/+nKvayJEjcfXqVQwZMgSxsbEICAjAihUrAABBQUFISEjAO++8g1u3bqFdu3Yai2voEiZORERERBVALpfDw8MDaWlpZWrfuXNnZGVlITs7W1owoTiCIKBVq1bYuXMnzp07h5YtW6JBgwbIzMzEmjVrEBAQUGiSkjenSaVSlSnekrh79y4iIyPRo0cPabhdQby9vXH8+HGNG/zo6GiYmprCyclJKvvjD80eyv/973/w9PSETCaDt7c3cnJyNOo8ePAAFy9ehI+PD4Dcnr3bt29rHOf55djlcnmlfCbR0dEICQlBz549Ub9+fdjb2+PatWsVfpyimJubw87ODidPnpTKVCoVTp8+XeZ9luRzB3KHWY4ZMwbbtm3DlClT8PXXX0vbbGxsMGzYMHz77bdYtmwZvvrqqzLHU5k4VE9HpNxPR3pqNizsjKAw5NdCRESkC5KTk/PdWFtZWeHs2bPYvHkz3njjDXh5eUEURfz888/YtWtXmVcEk8lk0tCmZ4fJFScwMBBTpkxBQECANOG+devW2LRpE6ZNm1ZoO1tbWxgaGmLPnj1wcnKCUqks1/OARFGUkpLHjx/j+PHjmD9/PszNzfHJJ58U2Xbs2LFYtmwZ3n77bYwfPx4XL17E7NmzMXnyZI2EKzExEZMnT8abb76J06dPY8WKFViyZAmA3HlT3bt3x6hRo7BmzRqYmprivffeQ82aNdG9e3fps7p37x4WLlyIPn36YM+ePdi9ezfMzMykY7i6umLv3r24ePEirKysYG5uXqKFJYrj6emJbdu2ITg4GIIg4MMPPyxzL155vP3221iwYAFq166NunXrYsWKFXj06FGJ5tjHxsbC1NRUei8IAnx9fYv93CdNmoSgoCB4eXnh0aNHOHToELy9vQEAs2bNQsOGDVGvXj1kZmbil19+kbbpGvY46YhdX8Zi6yencCf+xXpIHBER0cssKioK/v7+Gq85c+bAx8cHRkZGmDJlCvz8/NC0aVP88MMPWLt2LYYMGVLm45mZmWncxJdEmzZtoFKpNJYTDwwMzFf2PH19fSxfvhxr1qyBo6OjdJNbVikpKXBwcEDNmjXRrFkzrFmzBsOGDcOZM2c0lkgvSM2aNbFr1y6cOHECvr6+GDNmDEJDQ/HBBx9o1Bs6dCjS09PRuHFjjBs3DhMnTtR4YGx4eDgaNmyIbt26oVmzZhBFEbt27ZISH29vb6xatQpffPEFfH19ceLEiXzDwkaNGoU6deogICAANjY20sp/5fXZZ5+hRo0aaN68OYKDg9GpUye8+uqrFbLv0pg+fToGDBiAoUOHolmzZjAxMUGnTp2gVCqLbdu6dWuNn4W8uWrFfe4qlQrjxo2Dt7c3OnfuDC8vL6xalbtiplwux4wZM9CgQQO0bt0aMpkMmzdvrrwPoBwEUduDHqtYSkoKzM3NkZycXOpfTJVp2+I/kXQ5GZ1GvYLaDW21HQ4REVGFycjIQHx8PNzc3Ep0c0ZUkMDAQPj5+Wk854jKT61Ww9vbG/369cNHH32k7XAqRVG/g0qTG3BMmI7IG56XlV6yJ0sTEREREZVWQkIC9u3bhzZt2iAzMxMrV65EfHw8Bg4cqO3QdB6H6ukI+b+JUyYTJyIiIiKqJHp6eoiIiECjRo3QokULxMbG4sCBAzo7r0iXsMdJR8jZ40RERERUqOIeBkwl4+zsXGHztqob9jjpCClxymDiRERERESka5g46QjOcSIiIiIi0l1MnHSEXJn7vIas9Mp7CB0REREREZUNEycdwcUhiIiIiIh0FxMnHcHFIYiIiIiIdBcTJx3BxImIiIiISHcxcdIRCq6qR0RERJVMEATs2LGjyDohISHo0aNHlcRT3QUGBmLSpEnSe1dXVyxbtqzINiX5DkuiovZTnTBx0hGc40RERKRbiksgzp49i9dffx22trZQKpVwdXVF//79cffuXYSFhUEQhCJfeccQBAFjxozJt/9x48ZBEASEhIRU2DklJSUhKCgIAHDt2jUIgoCYmJhy7zciIkI6L5lMhho1aqBJkyaYO3cukpOTy73/qlSSxDE4OBidO3cucNvRo0chCAL++uuvUh/75MmTGD16dKnbFSUsLAx+fn75yp+9FipLREQELCwsKvUYVYmJk44wNpdjYFgTDJ3XHKIoajscIiIiKsK9e/fQrl07WFpaYu/evYiLi0N4eDgcHR2RlpaGqVOnIikpSXo5OTlh7ty5GmV5nJ2dsXnzZqSnp0tlGRkZiIyMhIuLS4XGbW9vD4VCUaH7zGNmZoakpCTcuHEDx44dw+jRo7Fhwwb4+fnh1q1bhbbLysqqlHgqU2hoKPbv348bN27k2xYeHo6AgAA0aNCg1Pu1sbGBkZFRRYRYrMq8Fl5WTJx0hJ5MDzXsjWFsrpD+CkVERPSyU2dmFvoSn7uhLm/dihQdHY3k5GSsXbsW/v7+cHNzQ9u2bbF06VK4ubnBxMQE9vb20ksmk8HU1FSjLM+rr74KZ2dnbNu2TSrbtm0bXFxc4O/vX2gMoijCxsYGW7dulcr8/Pzg4OAgvf/999+hUCjw9OlTAJrDs9zc3AAA/v7+EAQBgYGBGvtfvHgxHBwcYGVlhXHjxiE7O7vIz0QQBNjb28PBwQHe3t4IDQ3FsWPHkJqainfffVeqFxgYiPHjx2PSpEmwtrZGp06dAACHDx9G48aNoVAo4ODggPfeew85OTn52o0fPx7m5uawtrbGhx9+qPEH50ePHmHo0KGoUaMGjIyMEBQUhEuXLknbC+p9WbZsGVxdXaXt69evx86dO6UetKioqHzn2q1bN9jY2CAiIkKjPDU1FVu2bEFoaCgePHiAAQMGoGbNmjAyMkL9+vXx3XffFfkZPj9U79KlS2jdujWUSiV8fHywf//+fG2mT58OLy8vGBkZwd3dHR9++KH0XUVERGDOnDk4e/asdD55MT8/VC82NhavvfYaDA0NYWVlhdGjRyM1NVXantcTV9rroiiJiYno3r07TExMYGZmhn79+uHOnTvS9rNnz6Jt27YwNTWFmZkZGjZsiFOnTgEAEhISEBwcjBo1asDY2Bj16tXDrl27yhxLSehX6t6JiIiIinBz4qRCtylfeQU248dJ729NezdfgpRH4ekJ2ymTpfdJMz+A+pmbPgBwXv1l+YJ9hr29PXJycrB9+3b06dOn3H/0HDFiBMLDwzFo0CAAwLp16zB8+PACb9rzCIKA1q1bIyoqCn369MGjR48QFxcHQ0NDXLhwAXXr1sXhw4fRqFGjAnsxTpw4gcaNG+PAgQOoV68e5HK5tO3QoUNwcHDAoUOHcPnyZfTv3x9+fn4YNWpUqc7L1tYWgwYNwrp166BSqSCT5T63cv369XjrrbcQHR0NALh58ya6dOmCkJAQbNiwARcuXMCoUaOgVCoRFhYm7W/9+vUIDQ3FiRMncOrUKYwePRouLi5SXCEhIbh06RJ++uknmJmZYfr06ejSpQvOnz8PAwODYuOdOnUq4uLikJKSgvDwcACApaVlvnr6+voYOnQoIiIiMHPmTOn737JlC1QqFQYMGIDU1FQ0bNgQ06dPh5mZGX799VcMGTIEHh4eaNy4cbGxqNVq9OrVC3Z2dvjjjz+QnJysMR8qj6mpKSIiIuDo6IjY2FiMGjUKpqamePfdd9G/f3/8/fff2LNnDw4cOAAAMDc3z7ePtLQ0dOrUCc2aNcPJkydx9+5djBw5EuPHj9dIDivqusg7v7yk6fDhw8jJycG4cePQv39/6bofNGgQ/P398eWXX0ImkyEmJkb6HseNG4esrCwcOXIExsbGOH/+PExMTEodR2kwcdIhZ/Yn4snDDPi+5gxzG0Nth0NERESFaNq0Kd5//30MHDgQY8aMQePGjfHaa69h6NChsLOzK/X+Bg8ejBkzZiAhIQFAbo/W5s2bi0ycgNxemDVr1gAAjhw5An9/f9jb2yMqKgp169ZFVFQU2rRpU2BbGxsbAICVlZVGDxgA1KhRAytXroRMJkPdunXRtWtXHDx4sEw3yHXr1sWTJ0/w4MED2NraAgA8PT2xcOFCqc7MmTPh7OyMlStXQhAE1K1bF7du3cL06dMxa9Ys6OnlDpJydnbG0qVLIQgC6tSpg9jYWCxduhSjRo2SEqbo6Gg0b94cALBp0yY4Oztjx44d6Nu3b7GxmpiYwNDQEJmZmfk+k+eNGDECixYtwuHDh6XeuvDwcPTu3Rvm5uYwNzfH1KlTpfpvv/029u7dix9++KFEidOBAwdw4cIF7N27F46OjgCA+fPn55uX9MEHH0j/dnV1xdSpU7F582a8++67MDQ0hImJCfT19Ys8n8jISGRkZGDDhg0wNjYGAKxcuRLBwcH49NNPpWu6Iq+LgwcPIjY2FvHx8XB2dgYAbNiwAfXq1cPJkyfRqFEjJCYmYtq0aahbty6A3OsmT2JiInr37o369esDANzd3UsdQ2kxcdIhF44n4eGtNLj5WjNxIiKiaqHm58sK3fZ8L47jooWF1Mxf12Hex+WKqyTmzZuHyZMn47fffsMff/yB1atXY/78+Thy5Ih0M1dSNjY26Nq1KyIiIiCKIrp27Qpra+ti27Vp0wYTJ07EvXv3pBv4vMQpb6jcs8PkSqpevXpS7xAAODg4IDY2ttT7ASANpXv2O2rYsKFGnbi4ODRr1kyjTosWLZCamoobN25Ic72aNm2qUadZs2ZYsmQJVCoV4uLioK+vjyZNmkjbraysUKdOHcTFxZUp9qLUrVsXzZs3x7p16xAYGIjLly/j6NGjmDt3LgBApVJh/vz5+OGHH3Dz5k1kZWUhMzOzxHOY4uLi4OzsLCVNQO75Pu/777/H8uXLceXKFaSmpiInJwdmZmalOpe4uDj4+vpKSROQ+/mr1WpcvHhRSpwq8rrIO7+8pAkAfHx8YGFhgbi4ODRq1AiTJ0/GyJEjsXHjRrRv3x59+/aFh4cHAGDChAl46623sG/fPrRv3x69e/cu07yy0uAcJx3i3dwBDTvXgmkNpbZDISIiqhJ6CkWhL+GZoWMVUbcyWFlZoW/fvli8eDHi4uLg6OiIxYsXl2lfI0aMQEREBNavX48RI0aUqE39+vVhaWmJw4cPS4lTYGAgDh8+jJMnTyI7O1vqfSmN54e1CYIAtVpd6v0AuTfIZmZmsLKyksqevUGvSnp6evkW4SrPHJ3Q0FD8+OOPePLkCcLDw+Hh4SH18C1atAiff/45pk+fjkOHDiEmJgadOnWq0MUwjh8/jkGDBqFLly745ZdfcObMGcycObPSFtyoyOuiJMLCwnDu3Dl07doVv/32G3x8fLB9+3YAwMiRI3H16lUMGTIEsbGxCAgIwIoVKyotFoCJk07xa++Cpj08YGFXNaupEBERUcWRy+Xw8PBAWlpamdp37twZWVlZyM7OlhZMKI4gCGjVqhV27tyJc+fOoWXLlmjQoAEyMzOxZs0aBAQEFJqk5M1pUqlUZYq3JO7evYvIyEj06NFDGm5XEG9vbxw/flwjqYmOjoapqSmcnJyksj/++EOj3f/+9z94enpCJpPB29sbOTk5GnUePHiAixcvwsfHB0Buz97t27c1jvP8cuxyubzEn0m/fv2gp6eHyMhIbNiwASNGjJB6xKKjo9G9e3cMHjwYvr6+cHd3xz///FOi/QK5n8n169c1VmD83//+p1Hn2LFjqFWrFmbOnImAgAB4enpKwz1Lcz7e3t44e/asxrUbHR0NPT091KlTp8Qxl0be+V2/fl0qO3/+PB4/fix9XwDg5eWFd955B/v27UOvXr2kuWdA7tDNMWPGYNu2bZgyZQq+/vrrSok1j1YTpyNHjiA4OBiOjo4lfgjXpk2b4OvrCyMjIzg4OGDEiBF48OBB5QdLRERE1U5ycjJiYmI0XtevX8cvv/yCwYMH45dffsE///yDixcvYvHixdi1axe6d+9epmPJZDLExcXh/PnzGsOhihMYGIjvvvsOfn5+MDExgZ6eHlq3bo1NmzYVOr8JyF24wdDQEHv27MGdO3fK/bwlURRx+/ZtJCUlIS4uDuvWrUPz5s1hbm6OTz75pMi2Y8eOxfXr1/H222/jwoUL2LlzJ2bPno3JkydrJFyJiYmYPHkyLl68iO+++w4rVqzAxIkTAeTOf+nevTtGjRqF33//HWfPnsXgwYNRs2ZN6TsJDAzEvXv3sHDhQly5cgVffPEFdu/erRGLq6sr/vrrL1y8eBH3798vskfKxMQE/fv3x4wZM5CUlKTxzC1PT0/s378fx44dQ1xcHN58802NFeOK0759e3h5eWHYsGE4e/Ysjh49ipkzZ2rU8fT0RGJiIjZv3owrV65g+fLlUo/Ms+cTHx+PmJgY3L9/H5kFrDA5aNAgKJVKDBs2DH///TcOHTqEt99+G0OGDCnTnL1nqVSqfD9DcXFxaN++PerXr49Bgwbh9OnTOHHiBIYOHYo2bdogICAA6enpGD9+PKKiopCQkIDo6GicPHkS3t7eAIBJkyZh7969iI+Px+nTp3Ho0CFpW2XRauKUlpYGX19ffPHFFyWqHx0djaFDhyI0NBTnzp3Dli1bcOLEiTJNSNNFWek5eHznKdKSK3bJVCIiIiqbqKgo+Pv7a7zmzJkDHx8fGBkZYcqUKfDz80PTpk3xww8/YO3atRgyZEiZj2dmZlbq+Slt2rSBSqXSWE48MDAwX9nz9PX1sXz5cqxZswaOjo5lTvjypKSkwMHBATVr1kSzZs2wZs0aDBs2DGfOnNFYIr0gNWvWxK5du3DixAn4+vpizJgxCA0N1Vj4AACGDh2K9PR0NG7cGOPGjcPEiRM1HhgbHh6Ohg0bolu3bmjWrBlEUcSuXbukIWbe3t5YtWoVvvjiC/j6+uLEiRMaCzgAwKhRo1CnTh0EBATAxsZGWvmvMKGhoXj06BE6deqkMR/pgw8+wKuvvopOnTpJc8+Ke7Dus/T09LB9+3bpfEeOHIl58+Zp1Hn99dfxzjvvYPz48fDz88OxY8fw4YcfatTp3bs3OnfujLZt28LGxqbAJdGNjIywd+9ePHz4EI0aNUKfPn3Qrl07rFy5ssTxFiY1NTXfz1BwcDAEQcDOnTtRo0YNtG7dGu3bt4e7uzu+//57ALl/SHjw4AGGDh0KLy8v9OvXD0FBQZgzZw6A3IRs3Lhx8Pb2RufOneHl5YVVq1aVO96iCKKOPG1VEARs3769yAtq8eLF+PLLL3HlyhWpbMWKFfj0008LfABZQVJSUmBubo7k5ORS/2KqbMe2XcaZfYnwbe+Mln08i29ARET0AsjIyEB8fDzc3NygVHIeL5VNYGAg/Pz8NJ5zRFQSRf0OKk1u8ELNcWrWrBmuX7+OXbt2QRRF3LlzB1u3bkWXLl0KbZOZmYmUlBSNl66SG+YucpiVnlNMTSIiIiIiqkovVOLUokULbNq0Cf3794dcLoe9vT3Mzc2LHOq3YMECaS19c3NzjSUPdY1cycSJiIiIiEgXvVCJ0/nz5zFx4kTMmjULf/75J/bs2YNr165hzJgxhbaZMWMGkpOTpdezK3foGoVh7kRQJk5EREREmqKiojhMj7TqhXoA7oIFC9CiRQtMmzYNANCgQQMYGxujVatW+PjjjwuceKhQKKCopGc3VLS8oXqZ6ZW3LCgREREREZXeC9Xj9PTp03zPAMhbrlNH1rgoF85xIiIiIiLSTVpNnFJTU6X13AFIa8wnJiYCyB1mN3ToUKl+cHAwtm3bhi+//BJXr15FdHQ0JkyYgMaNG2ss//iiYuJERERERKSbtDpU79SpU2jbtq30fvLkyQCAYcOGISIiAklJSVISBQAhISF48uQJVq5ciSlTpsDCwgKvvfYaPv300yqPvTIo8hKnDCZORERERES6RKuJU2BgYJFD7CIiIvKVvf3223j77bcrMSrtyetxyslSQ6VSQyZ7oUZSEhERERG9tHhnrkPkSpn072wuEEFEREREpDOYOOkQPZke9OW5X0km5zkRERFRJRIEATt27Chx/YiICFhYWFRaPES6jomTjuECEURERLrj9u3bmDhxImrXrg2lUgk7Ozu0aNECX375JZ4+fSrVc3V1hSAIEAQBRkZGqF+/PtauXauxr6ISj8KSmGvXrkn7LexV0NSGkkhKSkJQUFCJ6/fv3x///PNPmY5VGkzQSFe9UM9xqg4Uhvp4mpzFxImIiEjLrl69ihYtWsDCwgLz589H/fr1oVAoEBsbi6+++go1a9bE66+/LtWfO3cuRo0ahadPn2LLli0YNWoUatasWark5HnOzs5ISkqS3i9evBh79uzBgQMHpDJzc3Pp3yqVCoIg5Ht8S0Hs7e1LFYuhoSEMDQ1L1YboZcIeJx3TafQrGBjWBHZuZtoOhYiIqNJlZ6pK/VKr1FJ7tUqN7EwVcrJUxe63tMaOHQt9fX2cOnUK/fr1g7e3N9zd3dG9e3f8+uuvCA4O1qhvamoKe3t7uLu7Y/r06bC0tMT+/fvL9sH8SyaTwd7eXnqZmJhAX19fer9nzx44ODjgp59+go+PDxQKBRITE3Hy5El06NAB1tbWMDc3R5s2bXD69GmNfT/by5XXs7Vt2za0bdsWRkZG8PX1xfHjx6X6z/cEhYWFwc/PDxs3boSrqyvMzc3xxhtv4MmTJ1KdJ0+eYNCgQTA2NoaDgwOWLl2KwMBATJo0qcyfSWJiIrp37w4TExOYmZmhX79+uHPnjrT97NmzaNu2LUxNTWFmZoaGDRvi1KlTAICEhAQEBwejRo0aMDY2Rr169bBr164yx0LVC3ucdIyVo4m2QyAiIqoyX008XOo2nUa9gtoNbQEAV2PuY+/Xf8PR0wI9p7wq1dkw8xgyUrM12o1b/VqJj/HgwQPs27cP8+fPh7GxcYF1BEEosFytVmP79u149OgR5HJ5iY9ZVk+fPsWnn36KtWvXwsrKCra2trh69SqGDRuGFStWQBRFLFmyBF26dMGlS5dgampa6L5mzpyJxYsXw9PTEzNnzsSAAQNw+fJl6OsXfMt45coV7NixA7/88gsePXqEfv364ZNPPsG8efMA5D5qJjo6Gj/99BPs7Owwa9YsnD59Gn5+fmU6V7VaLSVNhw8fRk5ODsaNG4f+/fsjKioKADBo0CD4+/vjyy+/hEwmQ0xMDAwMDAAA48aNQ1ZWFo4cOQJjY2OcP38eJia896KSYeJERERE9JzLly9DFEXUqVNHo9za2hoZGRkAcm/Cn32W5PTp0/HBBx8gMzMTOTk5sLS0xMiRIys91uzsbKxatQq+vr5S2WuvaSaJX331FSwsLHD48GF069at0H1NnToVXbt2BQDMmTMH9erVw+XLl1G3bt0C66vVakREREjJ2JAhQ3Dw4EHMmzcPT548wfr16xEZGYl27doBAMLDw+Ho6Fjmcz148CBiY2MRHx8PZ2dnAMCGDRtQr149nDx5Eo0aNUJiYiKmTZsmxezp6Sm1T0xMRO/evVG/fn0AgLu7e5ljoeqHiZOOSTz/AEmXk+FQ2xwuPlbaDoeIiKhSjf68TanbyPT/6+lx97PG6M/b4PnOn6Hzmpc3tAKdOHECarUagwYNQmZmpsa2adOmISQkBElJSZg2bRrGjh2L2rVrV0ocz5LL5WjQoIFG2Z07d/DBBx8gKioKd+/ehUqlwtOnT5GYmFjkvp7dj4ODAwDg7t27hSZOrq6uGj1YDg4OuHv3LoDcOWLZ2dlo3LixtN3c3DxfMloacXFxcHZ2lpImAPDx8YGFhQXi4uLQqFEjTJ48GSNHjsTGjRvRvn179O3bFx4eHgCACRMm4K233sK+ffvQvn179O7dO99nR1QYznHSMYnnH+LUrmu4EfdI26EQERFVOgOFrNQvvWceEK8n04OBQgZ9uazY/ZZG7dq1IQgCLl68qFHu7u6O2rVrF7hIgrW1NWrXro1WrVphy5YtmDBhAs6fPy9tNzMzQ1paGtRqtUa7x48fA9Bc5KE0DA0N8w0bHDZsGGJiYvD555/j2LFjiImJgZWVFbKysorcV96QNuC/oYjPx1tY/bw2RdWvCmFhYTh37hy6du2K3377DT4+Pti+fTsAYOTIkbh69SqGDBmC2NhYBAQEYMWKFVqNl14cTJx0jKOHBV5pUxP2HmX75UlERETlZ2VlhQ4dOmDlypVIS0srdXtnZ2f0798fM2bMkMrq1KmDnJwcxMTEaNTNW7TBy8urXDE/Kzo6GhMmTECXLl1Qr149KBQK3L9/v8L2XxLu7u4wMDDAyZMnpbLk5ORyLWnu7e2N69ev4/r161LZ+fPn8fjxY/j4+EhlXl5eeOedd7Bv3z706tUL4eHh0jZnZ2eMGTMG27Ztw5QpU/D111+XOR6qXjhUT8e4+9vA3d9G22EQERFVe6tWrUKLFi0QEBCAsLAwNGjQAHp6ejh58iQuXLiAhg0bFtl+4sSJeOWVV3Dq1CkEBASgXr166NixI0aMGIElS5bA3d0dFy9exKRJk9C/f3/UrFmzwmL39PTExo0bERAQgJSUFEybNq3KlxI3NTXFsGHDMG3aNFhaWsLW1hazZ8+Gnp5eoQtr5FGpVPkSTIVCgfbt26N+/foYNGgQli1bhpycHIwdOxZt2rRBQEAA0tPTMW3aNPTp0wdubm64ceMGTp48id69ewMAJk2ahKCgIHh5eeHRo0c4dOgQvL29K+sjoJcMEyciIiKiAnh4eODMmTOYP38+ZsyYgRs3bkChUMDHxwdTp07F2LFji2zv4+ODjh07YtasWdKS199//z1mz56NN998E7du3YKTkxN69uyJDz/8sEJj/+abbzB69Gi8+uqrcHZ2xvz58zF16tQKPUZJfPbZZxgzZgy6desGMzMzvPvuu7h+/TqUSmWR7VJTU+Hv769R5uHhgcuXL2Pnzp14++230bp1a+jp6aFz587ScDuZTIYHDx5g6NChuHPnDqytrdGrVy/MmTMHQG5CNm7cONy4cQNmZmbo3Lkzli5dWjknTy8dQRRFUdtBVKWUlBSYm5sjOTkZZma696wktUqNzKc5UOWIMKmh0HY4RERE5ZaRkYH4+Hi4ubkVe8NML7e0tDTUrFkTS5YsQWhoqLbDoWqiqN9BpckN2OOkY25eeoyflsWghoMxBs5uou1wiIiIiMrszJkzuHDhAho3bozk5GTMnTsXANC9e3ctR0ZUekycdIzCMPcryUrP0XIkREREROW3ePFiXLx4EXK5HA0bNsTRo0dhbW2t7bCISo2Jk46RK/9NnDKYOBEREdGLzd/fH3/++ae2wyCqEFyOXMfI/+1xys5QQa2uVtPPiIiIiIh0FhMnHSM3/O8BfdnsdSIiIiIi0glMnHSMvoEMevq5zzbI5DwnIiIiIiKdwMRJB/23QIRKy5EQERERERHAxEknSQtEsMeJiIiIiEgnMHHSQXIuSU5EREREpFOYOOmgvMSJc5yIiIioori6umLZsmXSe0EQsGPHjkLrX7t2DYIgICYmplzHraj9EGkbEycdpJCWJGfiREREpE23b9/GxIkTUbt2bSiVStjZ2aFFixb48ssv8fTpU6meq6srBEGAIAgwMjJC/fr1sXbtWo19RUREwMLCosDjFJXE1K9fH2PGjClw28aNG6FQKHD//v1Sn1tSUhKCgoJK3a4oISEh6NGjh0aZs7MzkpKS8Morr1TosZ4XFhYGPz+/Sj0GVW9MnHRQ3pLk7HEiIiLSnqtXr8Lf3x/79u3D/PnzcebMGRw/fhzvvvsufvnlFxw4cECj/ty5c5GUlIS///4bgwcPxqhRo7B79+5yxxEaGorNmzcjPT0937bw8HC8/vrrsLa2LvV+7e3toVAoyh1fcWQyGezt7aGvr1/pxyKqTEycdNB/i0NwVT0iInq55WRllfqlVv/3/6NarUJOVhZUOdnF7re0xo4dC319fZw6dQr9+vWDt7c33N3d0b17d/z6668IDg7WqG9qagp7e3u4u7tj+vTpsLS0xP79+8v2wTxj8ODBSE9Px48//qhRHh8fj6ioKISGhuLKlSvo3r077OzsYGJigkaNGuVL7J73fC/XiRMn4O/vD6VSiYCAAJw5c0ajvkqlQmhoKNzc3GBoaIg6derg888/l7aHhYVh/fr12Llzp9T7FhUVVeBQvcOHD6Nx48ZQKBRwcHDAe++9h5yc//5gHBgYiAkTJuDdd9+FpaUl7O3tERYWVvoP7xmxsbF47bXXYGhoCCsrK4wePRqpqanS9qioKDRu3BjGxsawsLBAixYtkJCQAAA4e/Ys2rZtC1NTU5iZmaFhw4Y4depUueKhFw9Tfx1Uv60TPBvZwdRKqe1QiIiIKtXPSxeUuk2j7n3gVLceAODWPxdwcudWWDvXQquBIVKdvas/R1b6U412PafPLvExHjx4IPU0GRsbF1hHEIQCy9VqNbZv345Hjx5BLpeX+JiFsba2Rvfu3bFu3ToMHjxYKo+IiICTkxM6duyI2NhYdOnSBfPmzYNCocCGDRsQHByMixcvwsXFpdhjpKamolu3bujQoQO+/fZbxMfHY+LEifnOy8nJCVu2bIGVlRWOHTuG0aNHw8HBAf369cPUqVMRFxeHlJQUhIeHAwAsLS1x69Ytjf3cvHkTXbp0QUhICDZs2IALFy5g1KhRUCqVGsnR+vXrMXnyZPzxxx84fvw4QkJC0KJFC3To0KHUn2FaWho6deqEZs2a4eTJk7h79y5GjhyJ8ePHIyIiAjk5OejRowdGjRqF7777DllZWThx4oT0HQ8aNAj+/v748ssvIZPJEBMTAwMDg1LHQS82Jk46yMLWCLDVdhRERETV1+XLlyGKIurUqaNRbm1tjYyMDADAuHHj8Omnn0rbpk+fjg8++ACZmZnIycmBpaUlRo4cWSHxhIaGIigoCPHx8XBzc4Moili/fj2GDRsGPT09+Pr6wtfXV6r/0UcfYfv27fjpp58wfvz4YvcfGRkJtVqNb775BkqlEvXq1cONGzfw1ltvSXUMDAwwZ84c6b2bmxuOHz+OH374Af369YOJiQkMDQ2RmZkJe3v7Qo+1atUqODs7Y+XKlRAEAXXr1sWtW7cwffp0zJo1C3p6uQOiGjRogNmzc5NdT09PrFy5EgcPHixT4hQZGYmMjAxs2LBBSoRXrlyJ4OBgfPrppzAwMEBycjK6desGDw8PAIC3t7fUPjExEdOmTUPdunWleKj6YeJEREREWhP8zoxSt9HTl0n/dvSqi+B3ZkDQ0+z96TRm4vPNKsSJEyegVqsxaNAgZGZmamybNm0aQkJCkJSUhGnTpmHs2LGoXbt2hRy3Q4cOcHJyQnh4OObOnYuDBw8iMTERw4cPB5DbYxQWFoZff/0VSUlJyMnJQXp6OhITE0u0/7i4ODRo0ABK5X+jXZo1a5av3hdffIF169YhMTER6enpyMrKKvWCDHFxcWjWrJlGj12LFi2QmpqKGzduSD1kDRo00Gjn4OCAu3fvlupYzx7T19dXo/ewRYsWUKvVuHjxIlq3bo2QkBB06tQJHTp0QPv27dGvXz84ODgAACZPnoyRI0di48aNaN++Pfr27SslWFR9cI6TDkq5n46YA4k4H32r+MpEREQvMH25vNQvPb3/Eic9PRn05XLI9A2K3W9p1K5dG4Ig4OLFixrl7u7uqF27NgwNDfO1sba2Ru3atdGqVSts2bIFEyZMwPnz56XtZmZmSEtLg1qt1mj3+PFjAIC5uXmh8ejp6SEkJATr16+HWq1GeHg42rZtC3d3dwDA1KlTsX37dsyfPx9Hjx5FTEwM6tevj6wyzO0qzObNmzF16lSEhoZi3759iImJwfDhwyv0GM96fiicIAj5PruKFB4ejuPHj6N58+b4/vvv4eXlhf/9738AcudvnTt3Dl27dsVvv/0GHx8fbN++vdJiId3ExEkHPb77FNFbL+Ov325oOxQiIqJqycrKCh06dMDKlSuRlpZW6vbOzs7o378/Zsz4r0etTp06yMnJyfc8o9OnTwMAvLy8itzn8OHDcf36dWzbtg3bt29HaGiotC06OhohISHo2bMn6tevD3t7e1y7dq3E8Xp7e+Ovv/6ShiECkJKGZ4/RvHlzjB07Fv7+/qhduzauXLmiUUcul0OlKnpxK29vbxw/fhyiKGrs29TUFE5OTiWOuTS8vb1x9uxZje8yOjoaenp6GsMx/f39MWPGDBw7dgyvvPIKIiMjpW1eXl545513sG/fPvTq1Uuax0XVBxMnHWRqqYRnIzu4+ZZ+aVEiIiKqGKtWrUJOTg4CAgLw/fffIy4uDhcvXsS3336LCxcuQCaTFdl+4sSJ+Pnnn6XV1+rVq4eOHTtixIgROHjwIOLj47Fnzx6MHTsW/fv3R82aNYvcn5ubG1577TWMHj0aCoUCvXr1krZ5enpi27ZtiImJwdmzZzFw4MBS9c4MHDgQgiBg1KhROH/+PHbt2oXFixdr1PH09MSpU6ewd+9e/PPPP/jwww9x8uRJjTqurq7466+/cPHiRdy/fx/Z2ZqrHQK5qxVev34db7/9Ni5cuICdO3di9uzZmDx5sjS/qazS09MRExOj8bpy5QoGDRoEpVKJYcOG4e+//8ahQ4fw9ttvY8iQIbCzs0N8fDxmzJiB48ePIyEhAfv27cOlS5fg7e2N9PR0jB8/HlFRUUhISEB0dDROnjypMQeKqgfOcdJBNeyN0TG0nrbDICIiqtY8PDxw5swZzJ8/HzNmzMCNGzegUCjg4+ODqVOnYuzYsUW29/HxQceOHTFr1izs2rULAPD9999j9uzZePPNN3Hr1i04OTmhZ8+e+PDDD0sUU2hoKA4ePIixY8dqzEf67LPPMGLECDRv3hzW1taYPn06UlJSSnyuJiYm+PnnnzFmzBj4+/vDx8cHn376KXr37i3VefPNN3HmzBn0798fgiBgwIABGDt2rMazqkaNGoWoqCgEBAQgNTUVhw4dgqurq8axatasiV27dmHatGnw9fWFpaUlQkND8cEHH5Q43sL8888/8Pf31yhr164dDhw4gL1792LixIlo1KgRjIyM0Lt3b3z22WcAACMjI1y4cAHr16/HgwcP4ODggHHjxuHNN99ETk4OHjx4gKFDh+LOnTuwtrZGr169NBbKoOpBEJ/tJ60GUlJSYG5ujuTkZJiZmWk7HCIiopdeRkaGtBrcszf7RERVoajfQaXJDThUT0epVGpkpGZDra5WeS0RERERkU5i4qSDRFHEV28fxjdTj+JpcmbxDYiIiIiIqFIxcdJBgiDAwDB3wmlmeo6WoyEiIiIiIiZOOkphmLtuR1Z60Ut6EhERERFR5WPipKPkUuLEHiciIno5VObDS4mIClNRa+FxOXIdJVf+mzhlMHEiIqIXm1wuh56eHm7dugUbGxvI5XIIgqDtsIioGhBFEffu3cudCmNgUK59MXHSUexxIiKil4Wenh7c3NyQlJSEW7duaTscIqpmBEGAk5NTsQ+tLg4TJx2VN8eJi0MQEdHLQC6Xw8XFBTk5OVCpOH+XiKqOgYFBuZMmgImTzpIrc79c9jgREdHLIm+oTHmHyxARaQMXh9BRcq6qR0RERESkM5g46SjOcSIiIiIi0h1MnHSUnHOciIiIiIh0hlYTpyNHjiA4OBiOjo4QBAE7duwotk1mZiZmzpyJWrVqQaFQwNXVFevWrav8YKuYgj1OREREREQ6Q6uLQ6SlpcHX1xcjRoxAr169StSmX79+uHPnDr755hvUrl0bSUlJL+UD9aShenyOExERERGR1mk1cQoKCkJQUFCJ6+/ZsweHDx/G1atXYWlpCQBwdXWtpOi0y9bVFN3e9oWRqVzboRARERERVXsv1Bynn376CQEBAVi4cCFq1qwJLy8vTJ06Fenp6YW2yczMREpKisbrRWBoIketelawcTHVdihERERERNXeC/Ucp6tXr+L333+HUqnE9u3bcf/+fYwdOxYPHjxAeHh4gW0WLFiAOXPmVHGkRERERET0MnmhepzUajUEQcCmTZvQuHFjdOnSBZ999hnWr19faK/TjBkzkJycLL2uX79exVGXjVot4nz0LcQcSIQq++Wbw0VERERE9CJ5oXqcHBwcULNmTZibm0tl3t7eEEURN27cgKenZ742CoUCCoWiKsOsEIIARH17AaIIeDayg7H5i3cOREREREQvixeqx6lFixa4desWUlNTpbJ//vkHenp6cHJy0mJkFU8QBLj728KzkR0EQdB2OERERERE1ZpWE6fU1FTExMQgJiYGABAfH4+YmBgkJiYCyB1mN3ToUKn+wIEDYWVlheHDh+P8+fM4cuQIpk2bhhEjRsDQ0FAbp1CpOo9+BR1D68HIjCvrERERERFpk1YTp1OnTsHf3x/+/v4AgMmTJ8Pf3x+zZs0CACQlJUlJFACYmJhg//79ePz4MQICAjBo0CAEBwdj+fLlWomfiIiIiIiqB0EURVHbQVSllJQUmJubIzk5GWZmZtoOp1hqlRoiAJnshRpVSURERESk80qTG/BuXIftXhOLL8dF4eL/bms7FCIiIiKiao2Jkw6T6ed+PVnpOVqOhIiIiIioemPipMPkhrmrxWcycSIiIiIi0iomTjpMYSgDwB4nIiIiIiJtY+Kkw/J6nLIyVFqOhIiIiIioemPipMPkyn8TJ/Y4ERERERFpFRMnHSb1ODFxIiIiIiLSKiZOOkzBxImIiIiISCcwcdJhXFWPiIiIiEg3MHHSYfK8VfW4OAQRERERkVYxcdJhXByCiIiIiEg3MHHSYXlD9VTZaqhy1FqOhoiIiIio+mLipMPyEieAvU5ERERERNqkX3wV0hY9PQGdRr0CA4UMBkqZtsMhIiIiIqq2mDjpuNoNbbUdAhERERFRtcehekRERERERMVgj5OOu/nPI6TcT4dDbQtY2BppOxwiIiIiomqJPU467vTeBPy24QKSLidrOxQiIiIiomqLPU46ztbVDIAAIzO5tkMhIiIiIqq2mDjpuCbB7toOgYiIiIio2uNQPSIiIiIiomIwcXpBiKKo7RCIiIiIiKotJk467nz0LayZeBj71p7TdihERERERNUWEycdpycTkJOpQlZ6jrZDISIiIiKqtpg46Ti5Mnf9jkwmTkREREREWsPESccpDHMTJ/Y4ERERERFpDxMnHSdn4kREREREpHVMnHSc3FAGAMjMUGk5EiIiIiKi6ouJk47L63HKyVRBrVJrORoiIiIiouqJiZOOy0ucACCLvU5ERERERFrBxEnHyWR60DfI/Zo4z4mIiIiISDv0i69CleV+4jVcPH4UJpZW8O3QpdB6ckN95GRnISuDiRMRERERkTYwcdKinKws3L12FZnpT4usJzfUx9OULPY4ERERERFpCYfqaZHS1AwAkPHkSZH18uY5ZaZzjhMRERERkTYwcdIiQ1NTAEDm0zSoVYUnRXJl7pLk7HEiIiIiItIODtXTIrmhEfRkMqhVKmSkPoGRuUWB9fw7usC7hQPs3cyrNkAiIiIiIgLAxEmrBEGA0sQUT5MfI/1J4YmTi49V1QZGREREREQaOFRPywz/neeUnpqi5UiIiIiIiKgw7HHSMqVJ7jynohaISLmfjvvXU2FkLoe9O4frERERERFVNfY4aVlJepyuxtzD7jWx+Ou361UVFhERERERPYOJk5YpTYvvcTKzMoS9uxnMbY2qKiwiIiIiInoGh+ppmWHeUL3UwhMnd38buPvbVFVIRERERET0HPY4adl/Q/WKfgguERERERFpDxMnLXt2cQhRFLUcDRERERERFYRD9bRMaWIK91cbQ2liClGthiCT5auT8iAd2xadBgCEfNKiqkMkIiIiIqr2mDhpmUxfH74dgoqso28gQ9rjTEAARLUIQU+oouiIiIiIiAjQ8lC9I0eOIDg4GI6OjhAEATt27Chx2+joaOjr68PPz6/S4tMVcsN/e6FEICtTpd1giIiIiIiqIa0mTmlpafD19cUXX3xRqnaPHz/G0KFD0a5du0qKrGplZ2Qg+e4dPE1JLnC7voEMevq5vUxZ6TlVGRoREREREUHLQ/WCgoIQFFT0MLWCjBkzBgMHDoRMJitVL5Wuij20Hwl/nUbdloHwbtGmwDoKQ32kP8lm4kREREREpAUv3Kp64eHhuHr1KmbPnl2i+pmZmUhJSdF46RpDMzPIDY1Q1MwluTI3x2XiRERERERU9V6oxSEuXbqE9957D0ePHoW+fslCX7BgAebMmVPJkZVP3eatC+1pyiM3zD3fTCZORERERERV7oXpcVKpVBg4cCDmzJkDLy+vErebMWMGkpOTpdf169crMcqyEYTiV8nLWyAiK4OJExERERFRVXthepyePHmCU6dO4cyZMxg/fjwAQK1WQxRF6OvrY9++fXjttdfytVMoFFAoFFUdboX7b6geV9UjIiIiIqpqL0ziZGZmhtjYWI2yVatW4bfffsPWrVvh5uampcjKLyc7G//7cTMyUp+gbchoyAoYhqgw5BwnIiIiIiJt0WrilJqaisuXL0vv4+PjERMTA0tLS7i4uGDGjBm4efMmNmzYAD09Pbzyyisa7W1tbaFUKvOVv2hk+vp4cCMRalUOMtNSYWRuka8O5zgREREREWmPVuc4nTp1Cv7+/vD39wcATJ48Gf7+/pg1axYAICkpCYmJidoMsUoIggCliSkAIP3JkwLryNnjRERERESkNVrtcQoMDIQoioVuj4iIKLJ9WFgYwsLCKjYoLTE0NcXT5EdITy14uXQpceLiEEREREREVe6FmeP0ssvrccoopMfJ2bsG2gzwQg0H46oMi4iIiIiIwMRJZxiamgFAoT1O1k6msHYyrcqQiIiIiIjoXy/Mc5xedkrTonuciIiIiIhIe9jjpCMM8xaHSC04ccrOVOHOtRSoVWq4+FhVZWhERERERNUee5x0RN5QvYwnBQ/Ve/IwAzuXnsG+teeqMiwiIiIiIgJ7nHTGs8uRi6IIQRA0tiuM9FHD3ghKY4MCtxMRERERUeVh4qRF/zz6Bz9c/AGmclOMbzAOAKBW5SA7Ix1yQyONusbmCgwMa6qNMImIiIiIqj0O1dOi5MxkfH/xe+yJ3wOZvr6ULBX2EFwiIiIiItIOJk5a5G7uDgC4mXoTGTkZ/81zKmSBCCIiIiIi0o4yDdW7fv06BEGAk5MTAODEiROIjIyEj48PRo8eXaEBvswslZawUFjgceZjXEu5Bje/hsjOzICxRY0C6/+8IgYPb6UhaEx92NYyq+JoiYiIiIiqrzL1OA0cOBCHDh0CANy+fRsdOnTAiRMnMHPmTMydO7dCA3yZCYIg9TpdeXwFbv4B8GraEiaWBS83npachdRHmchIza7KMImIiIiIqr0yJU5///03GjduDAD44Ycf8Morr+DYsWPYtGkTIiIiKjK+l567xX+JU3EUhrkdhJnpOZUaExERERERaSrTUL3s7GwoFAoAwIEDB/D6668DAOrWrYukpKSKi64a8DD3AABcTb6KnOxspD58AFGtQg2Hmvnqyv9NnLKYOBERERERVaky9TjVq1cPq1evxtGjR7F//3507twZAHDr1i1YWRU8zIwKljdU71HGIzy4noBDEWtwZs8vBdaVG8oAAFnpqiqLj4iIiIiIytjj9Omnn6Jnz55YtGgRhg0bBl9fXwDATz/9JA3ho5JpaN8Qv7/xO8wV5ki+ewcKI2PIDQ0LrKtQ/tvjlMEeJyIiIiKiqlSmxCkwMBD3799HSkoKatT4bwW40aNHw8jIqIiW9DyFTAGFLHfYo7mtHbq8PbXQuhyqR0RERESkHWUaqpeeno7MzEwpaUpISMCyZctw8eJF2NraVmiAL7NT1x5i7s/nseXU9RLVZ+JERERERKQdZUqcunfvjg0bNgAAHj9+jCZNmmDJkiXo0aMHvvzyywoN8GX2981krIuOR+S5nRi9bzQ2xW0qsr6cq+oREREREWlFmRKn06dPo1WrVgCArVu3ws7ODgkJCdiwYQOWL19eoQG+zDztTAEAt1Jv43jSccTcjcFfB/di/9crceufuHz1pcUhOMeJiIiIiKhKlSlxevr0KUxNc2/69+3bh169ekFPTw9NmzZFQkJChQb4MvO0MwEAPHhkAQC4knwFmWmpSH34AGnJj/PVl+ctDsFV9YiIiIiIqlSZEqfatWtjx44duH79Ovbu3YuOHTsCAO7evQszM7MKDfBlZmOigIWRAVSZufPCEpITIDc2BgBkPHmSrz4fgEtEREREpB1lSpxmzZqFqVOnwtXVFY0bN0azZs0A5PY++fv7V2iALzNBEOBlawoxuwYMBAWy1Fl4apAFAEh/kpKvPheHICIiIiLSjjItR96nTx+0bNkSSUlJ0jOcAKBdu3bo2bNnhQVXHXjameDEtYcwkTngUc413BOTAQAZqfl7nIwtFGjawx1KY4OqDpOIiIiIqForU+IEAPb29rC3t8eNGzcAAE5OTnz4bRl4/btAhF6OPYBrSFLfhy2A9AKG6imNDdCws2uVxkdERERERGUcqqdWqzF37lyYm5ujVq1aqFWrFiwsLPDRRx9BrVZXdIwvtbwFIp6mWsFcYQ61IvcryUh9AlEUtRkaERERERH9q0w9TjNnzsQ333yDTz75BC1atAAA/P777wgLC0NGRgbmzZtXoUG+zPJ6nO7daI5zIz+GUl/AzqMfQ63KQVZ6OhRGRhr1H9xMRUZqNmxqmUqr7BERERERUeUq0533+vXrsXbtWrz++utSWYMGDVCzZk2MHTuWiVMpWJsoYGksx8O0LFy9n4ZXappDYWSMzKdpyEhNyZc4/bLyLFIfZaLPewGwc+UKhkREREREVaFMQ/UePnyIunXr5iuvW7cuHj58WO6gqpvatrnD9f65kzuvSfnvM7IKmudkbmsECzsjgKP4iIiIiIiqTJkSJ19fX6xcuTJf+cqVK9GgQYNyB1XdeP07zyny8nIE/RiEe+rHAICMApYk7/GOPwbNaQo7N/Y2ERERERFVlTIN1Vu4cCG6du2KAwcOSM9wOn78OK5fv45du3ZVaIDVgTTP6ek9PBRu4JFeKuygj/QCliQnIiIiIqKqV6YepzZt2uCff/5Bz5498fjxYzx+/Bi9evXCuXPnsHHjxoqO8aXnaZubOKWlWQMA7omPART8LCciIiIiIqp6gliBa16fPXsWr776KlQqVUXtssKlpKTA3NwcycnJMDPTjeFuD1Iz0fDjAzAwOwtlze/QWP4KpruPRw17R9jUctOoe2ZfIi7+kQTv5o7wbeespYiJiIiIiF58pckNuJ61DrAyUcDKWI5HmXYAgDgkwLNxcwiCkK9uemoWHtxMw5OHGVUdJhERERFRtVWmoXpU8TztTKDOsoYAPTzJeoL76fcLrCc3zM11s9JzqjI8IiIiIqJqjYmTjvCyMwVEfZjI7AAROH/lT9y+/A/Uzw17zHvoLRMnIiIiIqKqU6qher169Spy++PHj8sTS7Xm+e+znOQ5rqhvbYWrO/fjoYEZOr45AcYWNaR6CkMZACCTiRMRERERUZUpVeJkbm5e7PahQ4eWK6DqyvPfJclz7ryByJDXEPXoG6hVOVDlZGvU41A9IiIiIqKqV6rEKTw8vLLiqPbynuV041E60jJzEDgktMB6UuKUobsrFxIRERERvWw4x0lHWBrLYW0iBwBcvpuKbHV2gfXyEicO1SMiIiIiqjpMnHRI7oNwVZgUPRCNv22MxxmP89VRcKgeEREREVGVY+KkQ7zsTADIkJ6dAcsHMuz+ahlO79qpUSevx0mVrYYqR62FKImIiIiIqh8mTjokb4EImcoeAPDw/m2kPnqoUUeulEn/zspgrxMRERERUVVg4qRD8haIyEizQqZchafZT5H+5IlGHT2ZHvTluV8bh+sREREREVUNJk46JO9ZTikpVsg0UONp9lNkpD6BKIoa9f5bkpwr6xERERERVYVSLUdOlauGsRzWJgo8zLLNTZxy0qBW5SArPR0KIyOpnl87F6hUahiayrUYLRERERFR9cHEScd42ZngWLwtRD3giZCOHLUKGakpGomTf0cXLUZIRERERFT9aHWo3pEjRxAcHAxHR0cIgoAdO3YUWX/btm3o0KEDbGxsYGZmhmbNmmHv3r1VE2wV8bIzBdSGsDNoAAdrF6hFVb55TkREREREVLW0mjilpaXB19cXX3zxRYnqHzlyBB06dMCuXbvw559/om3btggODsaZM2cqOdKq42mXO8/JKXMi2tcJglwmR8aTFI06T1OycO/6E6Q9ztRGiERERERE1Y5Wh+oFBQUhKCioxPWXLVum8X7+/PnYuXMnfv75Z/j7+1dwdNqRt7LepTupUDrm/js9VbPH6Y+dV3A+OglNXndDQBe3Ko+RiIiIiKi6eaHnOKnVajx58gSWlpaF1snMzERm5n89MykpKYXW1QVetrnJ0s3H6RDlhshSZeUbqmdoJoeRmRx6Mi6KSERERERUFV7oxGnx4sVITU1Fv379Cq2zYMECzJkzpwqjKh9zIwPYmipwP/syPjizHg3u1oBzqo9GnabdPdC0u4eWIiQiIiIiqn5e2C6LyMhIzJkzBz/88ANsbW0LrTdjxgwkJydLr+vXr1dhlGXjZWcKMbsG0vSzkKHKRGrKI22HRERERERUrb2QPU6bN2/GyJEjsWXLFrRv377IugqFAgqFoooiqxiedib4/bIx1HJDACLuP7yt7ZCIiIiIiKq1F67H6bvvvsPw4cPx3XffoWvXrtoOp1J42poCEKAysMElp1Tov+oCURSl7bevJmPb4j+xP/yc9oIkIiIiIqpGtNrjlJqaisuXL0vv4+PjERMTA0tLS7i4uGDGjBm4efMmNmzYACB3eN6wYcPw+eefo0mTJrh9O7cnxtDQEObm5lo5h8rg9e+S5OmZNnhifxm3a2RAEARpe06WCkmXk5GRmq2tEImIiIiIqhWt9jidOnUK/v7+0lLikydPhr+/P2bNmgUASEpKQmJiolT/q6++Qk5ODsaNGwcHBwfpNXHiRK3EX1k8/12SPPWJFQDgavJVje1yw9x8Nys9p2oDIyIiIiKqprTa4xQYGKgxBO15ERERGu+joqIqNyAdYW5oADszBe5n2cEoQ4a7Vy4j1e8hTGrkLrsuJU4ZKm2GSURERERUbbxwc5yqCy87U6gz7dDkQT00irdF0qUL0jbFv4lTdqYKanXhiScREREREVUMJk46ytPWFGKOGezNusHPqxkMlIbSNrnyv45CDtcjIiIiIqp8L+Ry5NVB3gIRcYbueH9YE41tMgM9yPT1oMpRIys9B0pjA22ESERERERUbbDHSUflLRDxz50nSEpNwvUnmg/ulRvKAABZGexxIiIiIiKqbEycdFRt29wep4f6+9Hxx45Yfnq5xnaurEdEREREVHWYOOkoc0MD2JspoZ9uiWaxlpD9elFjBcK8BSIy07myHhERERFRZWPipMM87UyQmW0Po0wZMtOf4mlairSNPU5ERERERFWHiZMO87IzhTrHEtn6AkSoce3OZWkbEyciIiIioqrDxEmH5a6sp4ccAyUA4Orti9K2/x6Cy8SJiIiIiKiycTlyHZa3st5TwRiGSMeNe/HSNhcfSxgaG8DO1Uxb4RERERERVRtMnHSY578r66WqTWGF+7hz/8Z/2wLs4Blgp63QiIiIiIiqFSZOOsxUaQBHcyXS7jrCVpkFT2MvbYdERERERFQtcY6TjvO0M0W6uibM9GvCUWYrledkq5ByPx0p99O1GB0RERERUfXAxEnHedqaIENPibRMFTJS/1uOPCH2ATZ+cBwHIs5rMToiIiIiouqBiZOO87IzRYaeEk8yM3Dz7jXcSr0FAJAr9SEz0IOenqDlCImIiIiIXn6c46TjPO1MkCFTIk28jtM3U6C+uhchDYbDybsGxqwI1HZ4RERERETVAnucdJynnSmyBX1kqRUAgGt3LgEABIE9TUREREREVYWJk44zUeijZg0jZAi5S5PfuBtfTAsiIiIiIqpoHKr3AvC0M8GFB14wdDyLLFUmRFGEWi1iz+pYZKbnoNt4X8iV/CqJiIiIiCoLe5xeAF52pripXxd3LLPwSEzB/fT70NMTkHjuIZIuJyPzaY62QyQiIiIieqkxcXoBeNqaAKI+5GLuc5yuJF+BIAiQG+b2MmWlM3EiIiIiIqpMTJxeAF52ppCrMmFxxxKWyQa48vgKAEBuKAPAxImIiIiIqLJxYswLoLatCayyH8LnkiF8XmmPVjVbAYDU45TJxImIiIiIqFKxx+kFYKzQh2kNSzwSasLBNgAuZi4AAEXeUL0MJk5ERERERJWJPU4viJouTjiUrkBn91eksv/mOKm0FRYRERERUbXAHqcXhJedKQDgfzf/xNZ/tuJJ1hMuDkFEREREVEXY4/SC8Pw3cTqWshyHjz2Am7kb5MrcMiZORERERESViz1OLwgvOxMEPPoTLf80g1WyHFeTr3JVPSIiIiKiKsLESctEUUTO/fvF1qttawIBIpAthzJbD1cfX/1vVT0uDkFEREREVKmYOGlR9p27uD1rNu4uWgQxp+jkx0iuD0NTU4hqBRRZMlx5fOW/VfW4OAQRERERUaVi4qRF+laWUGdmQJWcgvS/Youtb2lVIzdxytb7d6geF4cgIiIiIqoKTJy0SNDXh3Hz5gCA1KNHiq1vb2sJqOVQZOnhztM7UFgCPi0d4eZrXdmhEhERERFVa0yctMykZUtAEJAZdwHZd+8WWdfFwQYQZTDMMgQAPDa9g7aD68KvvUtVhEpEREREVG0xcdIyfaUIpZc7ACDt6O9F1q3tbAcAUKQ645uO36C2Re1Kj4+IiIiIiJg4ade5HcDPE2BSMxsAkHbsGMTs7EKr161lDwiAmG4IV0MfGOobIvNpNp48zIAoilUUNBERERFR9cPESZtq1AJENZTq85CZGUOdlob02L8LrW5qagSFXA4AiIu/g+xMFdZOPooN7x9DTpa6qqImIiIiIqp29LUdQLXm4AdYuEB4nAiLJk7Qq98FCk/PQqsLggBDU1NkZt3Dngs/4R+ZKQTBHXoyPWRl5MBAIau62ImIiIiIqhEmTtokCIB3MHD8CxgJ5wH3sbllRTCvYYHHD+7gZNIm/JqVhf+3d98BctT1/8efM9vb7fXe0ntvJKH3XgQFQYr6lZ9SBPGriF8B/YpiQ1BE+KJf8KuIIqD0HqRDgPRAerm7XK/b+8zvj9mbu83lUii5hLwfuszOzGd3P7s3uZvXfsq8edtb+Nze/VRhIYQQQgghDk3SVW+k1S4CdxHEA7DdmJJ8d+OViosKQLfiSrrR0WmKNe6vmgohhBBCCHHIkuA00ixWmHgaANrqx+l96CFab7wRLZncZfHKsiIA7FE/AFsDW/dPPYUQQgghhDiESXA6EIw5FmxulFg7sbf/Taarm9iyZbssOmPeHJbnz2Sbx7jo7baXQzz9+9U0b+jdnzUWQgghhBDikCLB6UBgc8H4k1AUBW9FHIDwa6/vsmh5dRW2qrGEKAcg2qyzfXUXgc7YfquuEEIIIYQQhxoJTgeK8SeBasVTEoZMjOS2bSSbmnZZdFypDy1pXAy3T+kGoHVz3/6qqRBCCCGEEIccCU4HClcBjD4ai9OCuyQDQPj1oa1OWibDeKWbmp4U6LCscAkA699po21bYL9WWQghhBBCiEOFBKcDycTTAAVPSQDScaJL30WLx4cU8214lam926mPXsGfv3wPEw4zuu299reNaNrwM/IJIYQQQgghPhoJTgeSvEqonouj1InVGkZPJIi+915OEdVioWLMWNqcZbS3VVLmLmPhOWOwOy10NoZY92bLCFVeCCGEEEKIz64RDU6vvfYaZ5xxBpWVlSiKwmOPPbbHx7zyyivMnj0bh8PB2LFj+dOf/vSp13O/mnwWiqLgq4njO3oRzokThxQ5+eJLWV4wh46klc5wAo/fwfwzRgPwzmNbiUdS+7vWQgghhBBCfKaNaHCKRCLMmDGDu+66a6/Kb9u2jdNOO41jjjmGlStXcu211/If//EfPP/8859yTfej4nFQMhHvKDf5E1SsJSVDijhtFmoL3aj2Dn797m/58wd/ZurRVRRWeohHUix9XK7tJIQQQgghxCdpRIPTKaecwi233MI555yzV+XvueceRo0axW233cakSZO46qqrOO+887j99ts/5ZruZ5PONJabX4RkZJdFxpV6sVi7eHrHX3hsy2NYLCpHnj8egLWvN9PZGNpftRVCCCGEEOIz76Aa4/T2229z/PHH52w76aSTePvtt4d9TCKRIBgM5twOeFWzIa8KPRkl/sKf6frDH9AiAwFqy7J3mfDBo0zuMN7L9sB20lqaqgkFjJtbCjq89vcN6DJRhBBCCCGEEJ+Igyo4tbW1UVZWlrOtrKyMYDBILLbrC8Deeuut+P1+81ZTU7M/qvrxKApMOgOAvkcfIfb+MiJL3zV3W+12PDYFZ0pB0W2ktBQ7QjsAWHTuWKwOC21bg2x4t21Eqi+EEEIIIcRnzUEVnD6KG264gUAgYN6ahrmo7AGn/nAUdyGeOjvEegi//hq6brQguXx5eOxWnJkEerIUgK0BY1yTt8DJvFPrAVj/tgQnIYQQQgghPgnWka7AvigvL6e9vT1nW3t7O3l5ebhcrl0+xuFw4HA49kf1PlkWG0w4FU/gLwQ+6CDdWkRy82Yc48bh9HrxOKy4tBCpWDk2RzMPrn+Qo2uORlVUZhxXg8NtZeKiipF+F0IIIYQQQnwmHFQtTgsXLmTJkiU521588UUWLlw4QjX6lI09DtXtxl1lgXiA8GuvA+Dy5qEqkGfVSHUegV11srR1KX/+4M8AWKwqU46owmI5qH68QgghhBBCHLBG9Mw6HA6zcuVKVq5cCRjTja9cuZLGxkbA6GZ3ySWXmOW//vWvs3XrVr773e+yfv16fv/73/OPf/yDb33rWyNR/U+f3QPjTsA71gfhNqIrlpMJh7E6HFhsNjwOK864jyOLvkqZu4wpxVOGPEUmrbFhaZvZzU8IIYQQQgix70Y0OL3//vvMmjWLWbNmAXDdddcxa9YsbrrpJgBaW1vNEAUwatQonn76aV588UVmzJjBbbfdxh//+EdOOumkEan/fjHhVOzFHuyeFESDRN5+G0VRcHnz8DqsOLU4jtgiHjvrMeaVz8t5qKbpPPLz93np/g/ZvKxjhN6AEEIIIYQQB78RHeN09NFH77Yl5E9/+tMuH7NixYpPsVYHGHch1B+OZ+yTaM1hLH4/AE6fD7fDgjMcZ3NHGK/daz6kJ95DobMQVVUYPbOESCCJalFG6h0IIYQQQghx0JNBMAeDSWfgGe2l/AgbnonVALi8PrPFaWN7yAygj21+jFMePYUljcZYsFkn1nLRjw5jzKzSEau+EEIIIYQQBzsJTgcDfzVK1RwUBVj/NABOXx5uuxW3niAYT9MRSgCwtW8r0XSUH771QzqiHVhtFhyug2ryRCGEEEIIIQ44EpwOFpPPBEDb8DLhf7+AQ7WgKlDu0ADY2B4C4OpZVzOpcBJ9iT6+/8b30XRjv67rbHy3jSX/96FMFCGEEEIIIcQ+kuB0sCiZCEVj6X6thd4/3AXbtgFQZs8A8NKHxvWtbBYbPz/y5zgtuVOUh3riLPnzOta/3ca2VV0j8x6EEEIIIYQ4SElwOlgoCkw6E3e9FyIdZFatAWCc3/gR/vmdBpY19AIwyj+K787/LgC/WfEbPuz+kLwiF7OOrwXgjYc3kU5mRuBNCCGEEEIIcXCS4HQwqZ6He/JoVBs42rczY+ocTr/4Is6dXY2uw/WPriaRNgLReePO47ja40hraa5/7XqiqShzTqnHW+Ag1B1n+QuNe3gxIYQQQgghRD8JTgcTVUWZehbueg/WSCe+bdspqqrhxtMnUex1sLkjzO9e3gyAoij8cOEPKXOXcVztcdhUGzaHhcXnjQNg+fMNBLtiI/luhBBCCCGEOGhIcDrYjDoS7+RKyCSJv/c66Z4e8t12fnzWFADufmULH7YEAch35vP42Y9z7ZxrsVlsAIyZXUL1xAIyKY03Ht40Ym9DCCGEEEKIg4kEp4ON1Y5t/tk4ylz0hTpY9/e/Euzq5JRpFZwytZy0pvPdR1eRzhiz6XlsHvOhKS1FMBnkiC+MR1UVtq3qouGD7pF6J0IIIYQQQhw0JDgdjMadiHd8IS3orFv9Lt1NDQD86Kwp+F021jYH+cPr23Ie0hRs4uJnLubbr36b/AoX0481LqT7+kMbyaS0/f4WhBBCCCGEOJhIcDoYOby4jj6Tutn51I314PLlAVDqc3Lj6ZMBuP2ljWzpDJsPSetptga2mlOUzzttFO48O4GOGCuXyEQRQgghhBBC7I4Ep4OUMuUMJo5xsaCyl/ICi7n93NlVHDm+hGRa43uPrkbTjIvdjvKP4rvzBqYo3xzdyKJzxwLw/jPbCffG9/+bEEIIIYQQ4iAhwelg5SmGusUApN/9B+luY6ySoij89JypeOwW3tveywNLG8yHnDvu3Jwpyqtn+agY6yed1Hjj4c0j8jaEEEIIIYQ4GEhwOphNOp3A2j4a736M9lt+SHzDBgCqC9xcf8pEAH7+7Hp29EaBgSnKS12lbA9u51fLfsWRF4xHUSDUHUPPtk4JIYQQQgghcklwOoiFdR//ThSz3ONH276Szl/9gsDTT6NrGl9aUMe8+gIiyQzf/9dadN0IRfnOfH5yxE9QUHhk4yOsyrzLonPHcszFE1FUBYBMSjO7+AkhhBBCCCEkOB3UHG4PelE9alkezho7dG4g+K9H6LzzTvRImJ+dOx27VeW1jZ08urzZfNxhFYdx2ZTLmFI0hbEFY5l5fC3F1T5z/7tPbeWRn71PZ2NoJN6WEEIIIYQQBxwJTgcxq8OB1elFKZ2I6/DJFM7zo/RuIrF6Be23/ISq3ha+dfx4AH781Id0hAYmgLh61tX85dS/UJdXl/OcyXiadW+10tkYItyX2K/vRwghhBBCiAOVBKeDmKIoOL0+sNiIzbocz6zJlB1fgjW1nUxXC+nWVr52xCimVuURiKW4+fEPzMfaLDZsqs1c74x2AmB3WrngxgUc/vlxjJpebO4PdsfM7n5CCCGEEEIcaiQ4HeScPqOLXTicgONuwjbaCE8Fo4N4JpZitaj84twZWBV4dm0bz65pzXl8Rsvwm+W/4cRHT+TOFXcST8dx59mZcVyNWSYaTPKPn7zH079fTbArtl/fnxBCCCGEEAcCCU4HOU9+AQArX3yG9198ieicq1Erp+Ad5UB55afQupqJ+VbuCL1FbbCNGx//gL5o0ny8qqh0RDtIa2nuXX0vZz9+Nq82vZrzGq2b+0glMjSs6eZv/72U5S80kMlo+/V9CiGEEEIIMZIU/RDrfxUMBvH7/QQCAfLy8ka6Oh9bPBxmzcvPs2PdWgBUi4XRM2cxIbMce/daUK30BmcRXLaZd7b38mTpDMpOP5Xbzp9pPoeu67zU+BI/f/fntEfbATi65mi+N/97VHmrAOhpjfDqgxto2dQHQFGVh6Mvmkj5aP9+fb9CCCGEEEJ8UvYlG0hw+ozobW3mg1eX0NmwDQCb3cF4fw9j7NtRdJXejgm0rm7m/YYeNubXcNLN13LUrFE5zxFNRbln1T385cO/kNbTOC1OfrToR5w6+lTACFjr327lrUe3EI+kQIEph1dy2NljcHpsQ+okhBBCCCHEgUyC0258VoMTGMGmY9sWPnh1CYGONgDqvCFmFzSh6xCxH8nbD71Hc2eQtM/Pub+8gYJJ44c8z+bezfxk6U9Y2bGSR858hDH5Y3L2x8JJ3np0M+vfNl7DlWfn8M+PZdzcMhRF+fTfqBBCCCGEEJ8ACU678VkOTv10XafpgzWsf/MVDvvcBeRtexw2v0RG04lUns6Dv3kdZ183VUVeFt/4LdyzZu3yOTb0bmBi4URz2xNbnmBB+QLKPGUANG/o5ZUHN9DXHgWganw+c08bRdX4fAlQQgghhBDigCfBaTcOheDUT9c0FFUFXYflf2bFs48Tjuu4px/Lgw81UBtqZ+Gvf8r8qTV7fK71Pes5/6nzcVqcXDHzCi6cdCE21UYmpbH8hQaWPdtAJm1MGDFpUQXHXjLp0357QgghhBBCfCz7kg1kVr3PMEXN/ngVheTkz7MjVUFXUKO+9zXmnVzKH6aewfXPbSGeyqDrOrE1a4a9VpNNtTGteBrRdJRfvf8rvvDkF3i/7X0sNpV5p43iwh8tYNpRVVisKjWTC83HZVIamszAJ4QQQgghDnLS4nQIiQYDtL70J8bE3yKV0fjF9jE80T2Oc46exdXlKXr+9Cfso0aRf965OMaMGfJ4Tdd4fPPj3L7sdnoTvQCcPvp0vj332xS7irOvkcTptaGqRle9FS82svbVHSw8Zyxj55TuvzcrhBBCCCHEHkhXvd04lIOTaePz8P59NPXE+etyB42Uc9aUUYzathlXtruda9Ys/Oecja10aNgJJAL8ZvlveGTjI+joVHoqefpzT2NVrTnldF3noVveo7s5zDEXT2Ty4sr98vaEEEIIIYTYGxKcdkOCU9bWVwi+/HteWB1ma8hNj72S2VV5eMJh/F29FFnseOx2fEcfTd4pp2LxeoY8xZrONdyy9BbOHns2X5z4RQBSWoqMlsFpdRrriQwb3mll0uJKLFaj6+CGpW0Eu2JMO7papjEXQgghhBAjRoLTbkhwGqThbRKv3c5La3r4MFRMe7qEiRV5FFg00q1t2CJRiq12KidMZsz139vlTHkZLQOARbUA8NTWp/j5uz/n8+M/zwUTL6DUndtipWU0/nrzOwS74tgcFqYeWcWM42vw+B2f/vsVQgghhBBiEAlOuyHBaSfNywi88HM+2NFDY8zFE9H5TC7xM9keRA8GSLW2YquswlNeQeX4iVSNn0hhTd2w041f8/I1vNz0MgBWxcqJ9SfypUlfYlrJNAA0TWfL8g6WPdtAd3MYAItVZdKiCmadWEtesWv/vG8hhBBCCHHIk+C0GxKcdqFzA+k3fsuWbdto6o3yijaT930n8J3DCvEFmmnfsol0KglAsa4yXnWSf9652EeNQtc11GxrE0BaS/Pvpn/zwIcPsLxjubl9RskMvjT5S5xUdxKKoqDrOg1ru1n2bANtWwMAKKpC+eg8Smp9xq3GR0G5G9Uikz8KIYQQQohPngSn3ZDgNIxUHFY+QM/Kp/mwNciOpJf/007mqCOO4ZvH1BNoaqD5w7XYX/o3BSmje15m8kTWxIPUzJjNjBNPHdIK9WH3h/x13V95ZtszpLU088rncd9J9+WU0XWd1s19LHu2gcYPe4ZUy2pTKanzcc51s1GyM/Xpui4X2BVCCCGEEB+bBKfdkOC0B21rSL75ezZt20ZrIM4SbTZri0/l5+fPZ3JlHpm+PgJPPEnk7bdpSkTYnopSMW4iR337e6geD7qus/yZJ/AWFuIvKSOvpJSILcU/Nv6DmSUzWVy1GIDuWDd3r7qbCyddyGj/aAD62qO0bwvQ0RiiszFEV1OYVCJDUbWXC34w36ziP3+5jExa4+iLJlJS6xuRj0kIIYQQQhz8JDjthgSnvZCMwsq/0rHiada3BtmRzuMv+qmcfvyx/L8jR2O1qCR3NNPzyMN0frAGFYV8n5/iK68gU1LM83ffkfN0VoeTvOIS/KXl5JWU4C8p5x+tj/P7D/8HgMVVi7l40sUsqlyU05KkazqBzhjxaIryUX4AMmmNe699FS2t86UfL8RfYoyJWvFiIxvfbaOk1kf91GJqpxRitVsQQgghhBBiOBKcdkOC0z5oWUn8zbvZsG07HaEkL2pz2FZ5Or84fx6jio3WpfgHHxL456Ok2tqp/OlPSNttNKxZSV9TI6FggHBPF1omM+SpA8kgDakWNmlNhNxpmkqjVBfXc/6E8zl99On4Hf5dVknXdYJdcTobQ4yZXWIGrefuXcOW5Z1mOZvDQv30YsbOLpUQJYQQQgghdkmC025IcNpHyQj68j/TtuJZNrSFaM4U8IByGl889Ti+tKAOVVXQMxkSmzbhnDjRfFjHb35DurMT98KFaBPGE0nGCXZ2EOhoJ9jZQSxkTAgRS8dpDjfz+MRNBDBm2auNFXL3MXdROXoCVtveXecp3BunY3uIls19bFnRQbgnYe4zQ9ScbIiySYgSQgghhBASnHZLgtNH1Lyc6Bu/Z/22RrojKZ7X5tFZfya3fn4Olfm5U4hr0SitP/gBWjRmbFBVXNOm4jn8cJyTJ6NYLCTjMYId7QQ6O4gG+xi1eBFPbHmCRzc9yqz1fqbodUw77mTGzl3Aoxsf5YiqIyj1lO6iYkPpuk779iCbl3WwZVkH4V4JUUIIIYQQYigJTrshweljSITRlv2J5uXPs7kzzI5MIX+3nsFXzzyec2ZV5YxP0pJJYsuXE3njDRKbt5jbLfn55J1xOt7Fi3f5EpqmsfLlZ+ncvJnDL7iExkwbX3jqC1R3uZkfH8usGUdx5LzTKSit2KuZ9XQtG6KWDw1Rp3x9GqNnlnyMD0SIQ0+4t4eO7VvwFhRRVF2Dxbp3rcJCCCHEgUiC025IcPoE7Hif0Gt3sX77DvpiGZ7JzCcx8Rx+/LmZFHkdQ4qnWluJvPkmkbffQYtEKLz0EjwLFwKgJ5OgqihWa85j+qccX9mxkl+9/yv0t7dT0mcHwG5xUFFSy+yZRzNpygKKa+pQLXtuOTJD1LIOmtb18Pkb5potTsufb6BrR5jpx1abE1EczHRdJxmLYne5Zep28bFl0mlaN65n++rldDZsM7dbrDZOvfo/sdrtI1i7j65//GX/749UIk6kr49MOoWWyaCl02TSaWOZSaNlMsZ6Jj2wT8swdt5CXN79P8OnrmmEerrpa2slGug16pxzM+qsaRpatq5VE6dQN20mAJG+Xt5+5EEsVhvHXHa5+bzpVGqvu0kLIcTBbl+ygXW3e4XYleq5+M79LbPfu4/G5S9yRtdSGjdu4Su/OpUzjzuKixfWY7cOXLTWVlFB/nnn4T/rLGKrVuGcNs3cF379dYLPPY/nsMPwHL4YW1kZgHmyP7N0Jg+c+gAfTl/FU2/9jY0fvo+rJ05D2yYantvMtmXvUZxXRtnosVSMnUDZ6LHYnM5dVtu4wK6f8tG5wUjXdda91Upfe5T6aUVmcOprj9LTGqFsVB4e/9BAeKBIp1IEOzsIdrQR6GwnkO0CmU7Ecbg9zDntbMpGjx3paoqDULCrk+2rltP0wWqSsaixUVEoqq4l2teL0+vNCU3vPPp3FFVl0hHHkFd8YLfmLnv6cZrXf8DMk06jduoMALqaGnjn0b/v83NNXHSkeX/LsqUEuzqpnTKDouqaT6y+uqYRC4dw5w38/lpy//8Q6urYp+fxl5bnrIe6u7DacoPv0n/+nXgkTOX4SVSOn0ReSal8ASOEEEhwEh+Vw4fl8GsYVXsYBa/djXv7Dq5O/B8tzz/Nj1+fxREnnMMJcyfl/LFVbDbcc+fmPE1s9Rq0UIjQiy8SevFF7GNG4543D/ecOVh8A9/gTq6eweQvzCCZSfLS1hd4bukjhBtbKPaWk4rF2LFuLatXvI7D4sBj96AoKnPPOIfqiVMAaN28gWVPPUZhVQ2LPn+h+bz//tO9JGIxPN4UmUScrcvW0rTWht3porMpQdP6KAp2XHleiqoLKK0roWZyLdUTKrDYVPYnXdeJhYLZsWHZgNTRRri3B4ZpOE5EI7jz8831lo3r6W5upHriFAoqqvZTzT+avvY21r3+byw2G/PPOs/c3rF9K6rFQl5xCXaXewRruPd0XSceDpGIRFCtVqw2GxabDYvVWB5IJ6XpVIrm9R+wfdVyepqbzO0un5+6aTOomz4Ltz8fXddJxWMDj0smadu6GV3LMPWYE8ztnQ3bSEQilNSPwuH27Nf3omkZAu1tdDZup7elmflnnYeiDvy7zaRTZNJpc91qd+D0+rBYragWK6rVYvyMrFZUiwXVYt1pnxW704XNMfBlTfOGdXQ3NVBYWW0Gp0BHG9tXraCgopL88kp8hUU59diZrmmkU0nzeUM9Xbzypz+gWq2cevV/mseLr7CIaKAXf2k5vqJirDY7ikVFVS2oVmt2aTGWFuPmLykzX8fp9XLEFy9FHdTin04m6d7RRCZtfCGz/s1X8RQUUjVhMhXjJlJQUXlAHa9CCLE/SVc98fHFA2SWP0DLqiVs7+gjkdbQUejzjWPGEWcyfu7xYNt1K5CeyRBfu5bwG28QX/vBQABQVVzTp1P0/y4f9o90JBXBbXXT29pM88Z1/OGF21BDSZwWJ35HPnXHH87iBadR66ulZcM63n38YYpr6jjiwsvM53jmzl+RiEZ2+fzB7jjhnjjJeO506hb7NGzusZTU+MgrjhNse4vSUdUc8cUvmnXdtuJ90qmkcYKVPWGxWKwoFgsWS/9JjZpzcuP0eM0goGUyBDs7SKeSFNfUmduevP3WXU7v7nB78JeWkVdahr+kHH9pGZ78AgId7RRWVZv1WvrYw7Rs+JCJhx/NpMVHAcaJUjTYh6+oZL+fECWiEfraWulta6GvtYXKCZPMb/8DHe28fP89WG12Tv/W98y6LbnvboKdHeb79hUV4ysuxVdUhK+oBF9xCU6Pd0RO7tLJJJl0ygwI8UiYtx9+kHBPN+lUctjH9Qeo/pP0WSefTnFtPWAEj20rl1FQWcW4eQvNx4R7e3D58rBYP7nvv9a8/AINq1eQSsQBUFSV8tHjqJ8xm7LRY/d4st/b1kJP8w7GzjvM3P7OPx+iddN6APJKyiitH01p/WiKqms/8S5+uq4T6Gins3EbXQ3b6drRSDr7XgCOufRy8ssrAKOlRdc1fIXFu31f+6p18wa6dzQxauYcPPkFAGx+fylrljxnlrHa7OSXV5BfXklBeSWeggJC3d30tbfQ19ZKoL2N6slTmXXyGYDRVfKpO36GoqqcePk3cXq9ACRjUWwO5ydaf4BkPEbb5o20bFhH+7YtaJmBcOny+amcMJHKcRMpqq79xF9bCCH2N+mqJ/Yvpx/LoiupmXsZJVveYs2bTxJuWkNBaCONz/yK8Bv/Q/3MYyicejyUTYVBf2gViwXXjBm4Zswg09dHdNkyou++R7KhwRj7NOjkN75+PY4xY1Cyfe89NuPktLCyGgrdKNoE3tz+Olomg0IzqaY1aC13U+wq5uy6M/nK167EYsk95Bef/yW0TAZd19E1HdDJpNMko1ESsQjJaJRoMExPSw+97QFC3QEyGR+ppE77tiCtm1pIx3ewY0OEzSveYOpR1cw/fRQb3nmDWDCwTx/jlKOPZ/wCY9KMvvY2Xv3LH/GXlXPsZf8PMMZh+EvLyKTT5JWU4S8tw19Shr+03DyR2tnOXYVqp0zHarNTMWa8ua192xbefewfuHx5xkntqDGU1o/+xFtzkrEofe1t9La20NfWQm9by5DPyOZ0msHJV1zM9ONPMU90wTgx9vgLjLAX6CMRjZCIRuhqash9HocTX3GJEaqKiikfMx5fUTFghJtUIo7VZh+2W+fu6JpGNBgg3NNNfnklDrfxOW1ZtpTVLz1HzZTpzD39HADsTheBzg50LYOiqjjcHmOcTCpFJp0yn9No+RhYH/x9Vrinm+b1H6BrGmSDk67rvHzfPWQyabz5hdnwWIK3sD88FmOz77l76c5jWeLhEKlEHLe/gPoZs6idNnOvx+4oqkphZbXx73GQ/LJyosE+Au1tBDvbCXa2s/m9twGjhcfucmF3uY2l07hfMW4CpfWjjTomkwS7OnG43WYQGfw5BTs76GraTmfDdrqaGnJawcA4Fopr6iiurcc56L30Hw+ftIqxE6gYOyFnW0F5JWPmHkZfWwt97a2kU0m6mhqGHLeDBbsGrktnsVo57qtX4PHn5wSVT6vF1e50UTt1BrVTZ2RbEjcZIWrLJmKhAFveX8qW95fi8HipGDeByvGTKKmrR1VlllIhxGebtDiJT0VnayMvPvMobH+NUnpRFYWqAhf11VU4xh4F9UdAQd2wj0+1d4CWwVZhnDSn2tpo++GPUN0uXLNm454/D8e4cUO+7YykIqzqWMX77e+zrH0Za7rWkNJSXDL5Er4z7zsARFNRrn/9euaUzmFO2RwmFk3Epu79QOj+i/C2bwvQvKmT1o1N9LZFQSlk7mn1LDhjNGtefoFwb5C1rzXhK7BRM7kAXTMGlhvLzE7LNJOPOIZRs4yujN07Gnnnnw9RUFHJwvMuNANk/6QZn6TN773Dh6+9nHPijqJQUF5BUU1dTtjs/3XhLSwyB5gDxuMzaSYcdrh5Mte6aQOdDduIR8L0tbUQ6evd5et7C4soKDe6MBXV1FJQXrlX9U4nk4R6ugh1dRHq7iTU1Umou4tw39Cui3NOO4faqdMB2PHhWt578lGKa+s54ouXmmVeuPdOMqmU0RXLasNqM5YWq9X4DBSFSF8vkd4e87M67HMXUDHOOElu3rCOdx/7B6X1o1l8/sXm83Zs34rT68NbUJgziYmu62aAyqRSpFOp7IQDKfKKS81QF+hop6tpO+68fPO14uEwL/7xrpzWlJ25fP6BVrhsgMwvr8Rqt6PrOqteeIamD1Zz1CVfJa+41HytRDRCSd2oT/w4S0QjdDZso2P7NjobthIN9A1bduqxJ5qtaz0tO3j1L/+LK8/Pyd+41izz7uOP0NmwbWDsVZbV7qCoupaSunqKa+vJLy0/oFpFjAkdugZ9gdBKpLcn599BfnnFHrvzjYRMOkXHtq20bFxP6+YNZki12GycevV3zBC++f2lZFJJ6mfMNltfu3c00d3ciIIC/YdW9hhT+jcoCvll5WYruxBC7A/S4iRGXElFLRd+9VtsaP0q9z/5ItaG15nXs4HWwGZGtbVS/cETWIpGGQGqfjG4cr9JtpXlXrMp3d2Nxe8nEwgYM/S9+SYWvx/3vLm4583DVluLoih4bB4WVS1iUdUiABKZBGu71lLgHHj+VZ2reKXpFV5pegUAl9XFzJKZzCkzgtS0kmk4LMN/W68oCv4SF/4SF+PnlwPTSKcydDWFcfmMrkfTjj2Rbas6Wf7iGjTFw+IvLDAf//ZjW7A7LZSP9lNal4fNMfRb2sKqmpyxDINf+5M2dt5hjJo1h+4dTbRv20zHtq0EO9vpbW2ht7Vll48pGz02Jzhtfv8dMqkUo2fNM4NT144GtixbmvM4T0Eh+WUV5liP/NLyj9TqA2C12ynIdnUaLJNOEe7pGQhTPd3klw8MiNc0DUW1DOniFg+HyKRS7A3VYsGTX4iua+a2stFjOe2b3xnSCtDfcrIzRVGw2u177K7mLzVaFwdzer2cfs13iUfCZmAMdXcR7uki1NVJPBImFgoQCwXo2L7VfNyRX/oKRVU1KIpCIhohnUrSsmGdGZx2fp1PksPtoXrSVKonTTXHRyViUZKxGKlY9n7cuD+41UrXNFw+Py5f7h+zvvZWkrEoFpvNCEq12aBUXnFAt3woqkpecSl5xaU5/4YOBharjYpxE6gYNwEtk6GzcTstG9ehoOS0XG58+3US0QgVYyeYwamjYSvr33hlj68xdt5CCU5CiAPWAdHidNddd/HLX/6StrY2ZsyYwZ133sn8+fOHLX/HHXdw991309jYSHFxMeeddx633norzr04AZMWp5Hx+qZOfvb0B9jbV7JQ/YAFjgYmlLgoy3OgKCpUzIBRR0LVbLC5dvkcuqaR2LSZ6HvvEVu+bOACu0DxlVfimjZ1r+rSGm7l+e3Ps6x9Gcs6lhFKhnL23zD/Bi6cZEwgEU6GSWmpnOC1t+LhFDs29KLrOuPmGiekmYzGH699jXTKOOFWVIXiai/lo/Ioy874l1fsHPHB17FwiI5tWwi0t+W2cinGf3xFxYyaOccs/+FrL6NlMow/bLEZHNq3bqZ7RyNWh4P8sgryyyuwO3f9sx0JO7fehXq6yKTSZiuQlk6TTqfMaad1TcPtz8dbWITb7z+gT86T8ZjREtfT3xpnBKtjL7vcDKp97W2kkwljnMpBONi/e0cTKEY3uL25HIHYf1YveZ50MsGkw482A2/LxvXmWDfztEPXMU9AstvKRo8zW4eFEGJ/OKiu4/TQQw9xySWXcM8997BgwQLuuOMOHn74YTZs2EBpaemQ8g8++CBf+cpXuO+++1i0aBEbN27ksssu44ILLuDXv/71Hl9PgtPIyWg6/1rRzK+e30Ao2Ms8dT1n+rdwTFEfBe7st+6KBYrGQPk0YzxU8TiwDO1Gp6dSxD/8kOh775HYtJmKH/83Svab+8BTT5Nub8cxdgz2MWOxVQ0/C5Sma2zq3cTyjuUsa1/G+23vc/fxdzOpaBIAj2x8hB+9/SPq8+qZVTqLWaWzmFk6k/q8+o90splKZvjgtWbatgZo2xok0pcYUsblsxmtUfV5lNb6KKn1mS1ZQgghhBDik3NQBacFCxYwb948fve73wFGN5qamhquvvpqvve97w0pf9VVV7Fu3TqWLFlibvv2t7/N0qVLeeONN/b4ehKcRl4smeF/39jK3a9sIZLMUEovl9fs4AsljeSlu3MLW2xQMgnKpxpBqmBUzuQSYMzMpwz6xrntx7eQam4211W3C/uo0dkgNcYYGzVM6On/59C///Zlt3Pf2vuGlCtwFDCjdAbXz7ueal/1kP17K9QTp21rgPatQVq3BuhqCqFlhv6TPO/6uZSNMo7XcG8cRVUO6GtLCSGEEEIcDA6a4JRMJnG73TzyyCOcffbZ5vZLL72Uvr4+Hn/88SGPefDBB7niiit44YUXmD9/Plu3buW0007j4osv5vvf//6Q8olEgkRi4Fv9YDBITU2NBKcDQGcowW+WbORv7zaR0XQsqsJFU1x8aVSIcdo2lPa1kAjmPsjugdLJAy1SeZXmAON+8Q0bSGzeTGLzZpJbt6EP+vlbiouovOUWcz2xdSvW0lIsw8xKB9AX72NV5ypWdKxgRccK1natJakZU0u/ccEb+B3GBSkf3fgoDaEGZpUYLVP5zvx9/kzSqQydDSHatgXpbAjS2RQm2BnjP+44EpvdCIev/W0Da15tNiei6H9cPJzGk28/KLtdCSGEEEKMhINmcoiuri4ymQxlZbkDksvKyli/fv0uH3PhhRfS1dXF4Ycfjq7rpNNpvv71r+8yNAHceuut/OhHP/rE6y4+vhKfg1vOnsZli+r52bPreWldB39eE+XPayxMLJ/FRQvO4pzRGt7e9dC+Fto/gGQEdrxn3ABchVA2JdsiNQ08RTgnTMA5wZh9TM9kSDU3k9i8hcSWzVgLBsYq6ZpG1+9+hxaNYS0vwzF6DI5xY7GPHoO1dOCaRvnOfI6qOYqjaozrHiUzST7s/pAtfVvM0ATw5NYnWda+jPu5H4Cx+WPNCSdml86mzLPngfdWm4WKsflUjM03t6USGTM0AcSjaWNsR9nAJARtW4M8fvsKXHl2s3tfcY0Xl9eGxWbBalOx2lUsVgtWu4rVpmKxqRKyhBBCCCH20oi2OLW0tFBVVcVbb73FwoUDF3b87ne/y6uvvsrSpUuHPOaVV17hggsu4JZbbmHBggVs3ryZa665hq997WvceOONQ8pLi9PBY2VTHw+808CTq1pIpI3JEzx2C2fNquKiBbVMKfdCz1ZoW2MEqc4NoKVzn8RXYYSo8ulGy5Rj+JakTF8fnb/9LamW1iH7VI8H79FH4T/jjL2u/zNbn+HdtndZ3rGcbYFtOfvy7Hm8fsHrqIrRzbA33ku+I/8jB5dkPI2iKmag+vDNFl7564bstaj2jt1l5Wu3H2muL/m/D+loCLHoc2Opm1oEQF9HlHVvtVJY7qagwkN+mRu7UybjFEIIIcRnw0HT4lRcXIzFYqG9vT1ne3t7O+WDpg8e7MYbb+Tiiy/mP/7jPwCYNm0akUiEyy+/nP/6r/9C3Wn8i8PhwOGQsSAHg5k1+cysyefG0ybzyPId/HVpA1s7Izy4tJEHlzYysyafixbUcvr0s3BN/Rykk9CZbY1qW2uEqlCrcdv0IqAYE02UTTW69hWPB+vAJAuW/HzKb7qJTDhCcttWo1Vq8yaSDQ1okUhO3TKhEJ233469fhT20aNxjKrHWlGRc52VU0efyqmjTwWgJ97DivYVLOtYxrL2ZZS7y83QBHD+U+eT1tJGa1TZbOaUzWFs/ticMruzc3iZvLiScfPK6N4RprMxRGdjiO7mMMl4hnQqQyalkU5qpFOaGa4sttzXCnTG6GmJkEpkzG3t24Isfy73Ip3eAgcF5W4Kyj0DywoPLp9NWrCEEEII8Zl1QEwOMX/+fO68807AmByitraWq666apeTQ8yZM4fjjz+en//85+a2v/3tb3z1q18lFAph2cO0tDI5xMFD13Xe2drDX5c28PwHbaSykybkOa2cN6eGCxfUMrZ0UItSMgLtH0L7GqNVKrjTNYgsNiiZaISo8mnGRBO7ONHXUymSO3Zg8fmwFhcDEFu9mq7f351TTnE6sdfX4Rg1Ctecudirq4Z9L5qumaGoK9bFiY+cSErLvWZQnj2P2aWzObH+RM4Ys/ctXfsqk9HIJDUyGQ2XdyBIdu0IEQulKKry4s4ztrdtDbD+nTZ6WyP0tkeJBZPDPq/DbaWg3E1RtY+jL5xgbv80LtorhBBCCPFJOGgmhwBjOvJLL72U//mf/2H+/Pnccccd/OMf/2D9+vWUlZVxySWXUFVVxa233grAD3/4Q379619z7733ml31vvGNbzBnzhweeuihPb6eBKeDU2cowcPLmnhwaSM7egeu33TY6EIuWlDHSVPKsVt3aq2JdGdD1FojSMX7cvfbvdnxUdON7n3esl0GKQAtEjEmnNi2jeS27SS3b8+ZdKLw0kvwZLubptrbia1ejbW4GGtJCdaiIlRX7vWL4uk4a7rWsKx9Gcvbl7OycyWxtPG+Lpx4ITcsuAEwuvTd8PoN1OXVUZdXR31ePbV5tVR4KrCMwHWE4pEUvW1RetsiA8vWCMHuOP0XZCmo8HDhzQMX/H30F8uIhZIc/5XJlI8yxoQFu2JEAknyipy48+woqgQrIYQQQux/B01XPYDzzz+fzs5ObrrpJtra2pg5cybPPfecOWFEY2NjTve7H/zgByiKwg9+8AOam5spKSnhjDPO4Cc/+clIvQWxH5T4HFxx9Fj+35FjeG1TJ399p5GX17fzztYe3tnaQ7HXzufn1nDh/FpqCrOTJniKYPTRxk3XIbAj261vTXaiiTA0LTVuAJ7igbFR+bWQVwUW45+I6vHgmjED14wZgDGxRKqlleS2rSS3bcM+ZoxZ1/jatQQe/WdO/VWPB2txMZbiIvJOOQVndTXzyucxp3AGypT/IK3qrO9ez7L2ZcwonWE+bntwO2+2vMmbLW/mPJ9NtVHrq+XiyRdz7vhzAUhlUgSSAYqcRZ9aC4/TY6NijJ+KMf6c7elkhr6OKL1t0Zztuq7T1Rwmnchgdwz8utn4bjtLn9gKgGpV8BU6ySty4ity4SsauC/BSgghhBAHihFvcdrfpMXps6OlL8bf32vi7+820hEyWn8UBebVFXLa9ApOmVZOqc+56wdn0tCzxQhRbWuge/PQiSYUFXzl4K/J3qohvwa85Wag2pXo8hXEli8j3dVNuqsLLRzO2V/63e/iGD0KgNDL/6bv4Yex5OcbLVTFRViKi7EWFWMtLSVY5OD1jnfYHtxOQ6CBhmADjaFGs5vf9xd8ny9O/CIAazrXcOEzF+KxecwWqlpfLXV5ddT4ahiTPwaf3fdRPuqPTNd1Qj1xwj1xyur95riq5S80sPbVZsK9iT1OaKFaFTx5DirH5XP8lyeb21f/eweqRWHs7FKcXuMiyelUBlVVUC17N1ZMCCGEEIe2g6qr3v4mwemzJ5XRWLKunb8ubeT1TV3mdkWBBaMKOW16JadMLafYu5tJQlJx6FxnhKiujUbrVCq267KqNRuoqnNDla8cdtF9TovHSXd1k+nuIt3VhWfhQlS30SrW9+ijhF58adhqlX7nP3FkW7PiGzeSbGjAUlpCT55CkyVEfeFoKr2VALzU8BLffvXbaLq2y+f63vzvcdGkiwBoDDby+JbHzXBVm1dLgaNgv49F0jIa4b4Eoe44oe44we44oe6YeX9wsKqdXMgZ35xpPvYP175KMp7hwh8uoKDcA8DSJ7by/jPbcbitOL02XF4bTq8dl9dGUZWX8jF+imu8WCRYCSGEEAIJTrslwemzrbkvxrNrWnlqdSsrm/rM7aoCC8cUcdq0Sk6eWk6hxz78k4DRtS/aA4FGI0SZtyZIJ3b9GNVqXJDXX2108/MUg7t4YLmLVipd19FCoWzrVCeZ7m7SnUbASnd0UPaDH2DxGqGg9+GHCS95eeDBVgvWkhJsZWVYy8rxHXcsGY+THaEdRgtVtnWqMdhIY6iRmxfezOFVhwPG1OnXv359Tl18Nh81eTXU+eq4cNKFzCydCUBaS6Mq6l7P+PdJ0jIa4d4E0VASi0WlpNZoMdN1nX8/sJ54OMVxl07C4TZanF59cANrX2ve7XNa7Splo/KoGJNPxRg/ZaP9OFwj3mtZCCGEECNAgtNuSHA6dDT1RHlmTStPr2ll9Y6Aud2iKiwaU8Tp0ys4aUo5+e49hKjBdB0iXUaACjTlBqpMajcPVMCVD+4iI0h5Soxbf7DyFIPds9uXjix9l/ia1aTa2km3t6Oncl+v8hc/x5I9poPPPkts7VosvjxUtwvF5UJ1uVHdLlSXi021Nh5vfJqmYBOt3dtoj7STsGFOjnHnsXdydM3RADy77VlufPNGKjwVVPmqqPJUGUuvcRvtH43b5uZAoGk6iWiKWChFPGzcYuEk0WCS9u1B2rYESERzu2TWTinkjKtnmuvh3gTeArmEgRBCCHEokOC0GxKcDk2N3VGeXtPK02taWNscNLdbVYXDxxVz2rQKTpxcjj/bcrHPdB3CHQMhKtQG0S4jZEW79hCqsmyubJAqMSa2MFursvddBWarla7rZHp7Sbe1GUGqu4v8884zu9p13X03sVWrh32pql/fZnYX7PnrXwm+9hrxTJyoJU3IkqK2dBweXxGq18tTU+PctvkPwz7Xb4/5LcfUHgPA8vblvNDwApWeSqp8VVR7q6nwVuCz+Q6IKcl1Tae3LUrrlj5atwRo3RJg0sJy5p5qjDmLBBL86fo38RU6uei/D8Oy80yNQgghhPhMkeC0GxKcxLauCM9ku/Otax0IUTaLwpHjSjhlWgVHjiumNG+YiSX2la5DImiEqEgXRDqzoarTmDI90mnM8LdHg1qt+m/93QDdReAuNMKVopBqaSHV0oIWiaDFYmixOFo0gh6LoUVjFF99lRlkuv/3PqLvvTfsq5b+6md06EFawi2EH3+S9LqNtOdpNHjibHYG+K+zf8O4ulkoisIf1/yR3yz/zZDncFvdlHnK+MninzCtZBoADUFjsosydxll7jL8Dv+IhCtd081Z+5rW9fDUnasoqPRwwQ/mm2WevHMlmbSG02PDarNgtatY7RastuzSPmiZ3V9U5cVXaBxD6VSGeDiF3WnFLt0ChRBCiAOGBKfdkOAkBtvSGebp1a08vbqVDe2hnH3jy7wsGlPM4WOLWTC6EJ/zI7ZG7Y1UfKCFqr+VKtIF0W7jfrRn6Kx/u6JajfDU31Jl9xotWTZ39uYatD6w1LGiJVNo0ShaNGoErGzg8h6+2Hz6jtvvILFhw9CX9XiwVVbScN4CXu9aSnOomebgDlqirfQmes1yj575KOMLxgPwv2v+lzuW32Huc1qclHnKzCB1+fTLqffXA8b1rOLpOIWuQhyWT7cbXSqRIdKXIL/MaJFLpzL84VuvoaX37VflUV8cz9SjqgHYsaGXx29fgb/ExZd+vNAs89pDG0nF0rh8duOWZ8Pls+P22XH5jPvS6iWEEEJ8eiQ47YYEJzGcTe0hnlrdysvrO1jbEmDwvwyLqjCzJp/FY4pYPLaYWbUFQy+4+2nSdYgHjCBlBqruQQGrB2K9mFeh/SisDiNIWZ3GeKv+kGV1Gjebi3QkRao7QrIzRKo7RKqzj3R3ABQF1ZdH5U9+hJJ9TOc995BubUUvKiBq1QipSaqLR+Pw5qH6fDxT2sojGx+hPdqO1tUNQMIKCTtoqpITsu5dfS93rrgTAK/NS6GzkCJXkbF0FnHZ1Muo8dUA0BXrIpwMU+gq/ES6COqaTndLmK6mMKlEhnRSI53KkE5m7yczpFPaoO3Gtjmn1DN6ZgkAjR9089Rdqymrz+Pc784xn/v/bniTcO8wk41kOdzWbLAygtSkRRXUTysGjAsSt24J4PHbKa2T32dCCCHEvpLgtBsSnMTe6I0keXtrN29u7uLNzV1s7869sKvLZmHB6EIWjylm8dhiJpb7UEf6Iq2ZtBGezFDVDalo9haDZBTSsez9iLFMx/Zu/NVu6BmNVDBFJp7BVTEwSUTLk81kopoxRbvFBqrNXFry/VT+1zVG65gzn5bf3k140wYSmQSJTIK4kqamZCx2tw+L389Dx9q4b+19pLU0M7ZqeGOQsBm3pE3hJ8f/ivrSCahuN/e3P26GLLtqp9BVSKGzkDJ3GeWeci6ZfAnVPqMlKJFJYFWsWHYxjfynIZPRcqZC37C0jUifMWtgLJQkFkoRDRr346EU2i6ucXXkBeOZdrRR/+aNvTz26xXkl7m56EeHmWX+ddtyIn0JnF4bTs+gm9eK02PDV+SioNyNr9ApFxcW4uPSdeN3b6gNwu3GLdRm/O5bdPVI104IsQf7kg2ks70Qu1DgsXPqtApOnVYBGDP0vbWlizc3G2GqO5LklQ2dvLKhE4Aij52FY4o4fKwRpGoKR2CWOYsVvCXGbV9kUkaI6g9Y5v2o0YUwHTOmYE9ll+lYdnsc0gmUdAy7t389DtnrSJWdWE6qL0kmkkZLaWgpHT2VQEvFUKwheOVnZhWsm9px92VwaYNCVssW0hYruj+fqyu/zVX1ZxFSoe23/0OycxtJLUkykyKlJbE3PEqHakWx28l8dSIem4dIKsJJb8ep6GkmYW0mbl9DxKEQmeslUDoK1ePloeLN3LXy95S6S6m1lFDqK6e0oJoKbyXlnnJml87Ga/d+cj+ina4fNWFB+bBldU0nEUtnA1WSaNAIVZXj8s0yqqpQWufDV5Q7Hi/QGSPSlyDQOcy1yLKsdpWCcg8F5W4mLqygZlLhvr8pIUaarhu/r5JRY7xoJpVtQXeZreVYPmZXay1jjEcNt0OoHcJtA8tw+66/gLI6jLodABPjCCE+GdLiJMQ+0jSdDe0hszVq6bYeoslMTpnqAhdz6wqYU1/I3LoCxpf5sBwK3+zrunECkQ1VxslMxOhmGOuFeB/E+nKX8SD9XQx1TUdPGyFLS2noSQ1d13GWucyXCG0IkIqArlnRNBtaRkXPqGhpBcXhpOLqi8DuJW510HzvgyQamknqGRJakkQmQY23GqtqQbFauf/CYv6x+V8AnPuGxthWnYwKMTvE7XDyhNMoLqxEdTt5Za6TJ5tfJs9ZQF0H5GccOD1+PJ58PN585tYswucrQnE6SVsVbKptxGYS7G2LGFOyR7K3cJJ4MEY8FCceShDoydDXlUTLDPz6P/qiCUw5ogqAtq0BXv7zOqomFHDUFyeYZXZuMROHIF03/n3Hg8akN4ngoPvZcaKqNXuzDLpvy1237LTeX16xGM+fDBu/O/rD0OBg1P97JRk2tqVi7LGbsmrNhijnQJfkwcGqf2lzgdUFmWQ2FHUYrUeRLtAzwz+/ohpjS73l4CsDbxn4KqByNqjyb0aIA5l01dsNCU7ik5ZMa6xs6uONzV28tbmLFU19ZHbqYuVzWJlVV8Cc2gLm1hcwsyYfj0MafAHjm9x4YPhwFes1TsgSIeNkaR/GcaVCKbR4Bi2pZW8ZtIRxX9d1/HOL6CRNm54i/nIHWkeCODoJNBLozFBcWFFQLAr3n+vgH5ox0cV5r2uMacutxzxnGW6LAxQLj19SzR8738FndXLCaoW6DgXV6cDucOG1upnsH4fH6gJFoejyS7HYjMcFXniZxIZN2XeYDV065jfWJddcg2pTIREmumwpyW3bsDhUVKuOatNQbRksljSqJYWiRVFSEUhkT0B3OunTdIVgupyeTDW9iVJGj9UpqPSDu4gP17n49xNBaicVcMY1s8zH3H/9G1isKgVlblSLgpbR0TTdWGa0ndaNbUddOIHayUUAbHq/nZf/sp6q8fmcfuUM83m3rerEW+CksNJz4E6GoetGa6qWMSZq0bNLTYNMItsam8i9v/P6cPu0dPbE3gEWB1jt2WX2ZrEbt/77Q8rZjWBiVHTXdd9535A//bpRl0Ro4N9jIjQ0GMUDezdRzUiw2MDmMZb9reMfsyvykOf3lhnhyFtqBCNvKfjKh73IuRDiwCdd9YTYj+xWlfmjCpk/qpDrThhPOJFmeUMv7zf0sryhlxWNvYQSaV7b2MlrG42ufRZVYVKFj7l1hcyuK2BuXQGV+a49vNJnlGoxplJ3FwKjdl9W141vmROhbCAIDYSqRDi7L2iu21zZsrs50SvHRrlig+Pr0dIaWlI3bgnNDFy6Bp+32pmXcRPUMzgKQqhainRKI5PW0NI69ozxLbiiKgS6Q2TQ6EtH0Xo0LJ3GSWoK6AWSSgNWjIDwh4p/8wC9VGLj5KUZRjVmcKDiVBQcKHixYEaJihVgN9biS7uIbA0NeT9m0TNrsHqMX/HhzSHi7TEsThuqx42ipFHIYLUGKbNsor7ajdqpQiekI2mqozZOGV2ONZMh82AExVdCwlFKNGCEqFB3fE8/VVNy3SsQjxiBY4uTdKKMdGcjvPU6qBY0rLzwwCjSaRVV1SkqylBSkqakVKekTKGoVMFqtxnf2ve3TCiWgZPUTNpoHdBSxn0tZaxnUsbPvf9+JpXdt9P9/iDUf9Mz2W2ZoesfZ/KVzxqLDRx5xs2ZXTp8RsuL+Xnu9NlqGeNz33l//8+qf93mMmYEtWdnAx1y35Nd9+Tet+7iYuZaJtvNOJ677B/j2d8dORU3WrL696uWgWDkLTfCUfZyD0KIQ5e0OAnxKUtnNNa3hVjW0GvemvuGjj2p9DvNrn1z6gqYWO7DKt2iPj49+026rhkndWAsFQVQjKW5fQ8nRZo2MMGGOSYsap506ckoxEOkMjECiT4CiT6Cbe1EAgEi8SihZIxuLcn59jIcKKBr/Ly8i39qxqyCFd06vuyhoWNU75fWKiqxgwIvlSV4iyj5qo3aZoWiHhVv2oorbcWZsuLL2CGho2eg6uZrUH0FYPfS88gzRN5fOfA+YeCENZOk8ptfwGKJQ6SL3heWEl613QgcO/15SFi92A+fTFgpBF0h2R4m2RnFomioqo6qGkuLqqFadLxj3BQXhHHaEiQ644Q7dRK4sVnTuO0xVKtCAjf/bjuV7kQpiczQa6cpaBR6einxdlLi7aLE20Wxtxub5eO1eui6nm3N42N0qVSyk5/YB7UOOXZ9f3f7VKvx8zBboZI7LRPGz2OXy4T5czRbKXOqqOTWd5dvI7vdYgenfyAEOQcHIx84/APbrA4JEUKIzwTpqrcbEpzEgaA1EOP97QNB6sPW4JDufW67henVfmbVFjC7toBZtfkUez/daxiJ/S+SitASbqE10kpruJWWyMD91kgrT535L5wWO+gaN7/zY/659clhn+vZzz1Lta8aLZnk/g1/4Zltz5DvyKe+S6U8qOJP2fClLHh0O2O8ddg1FT2VouhrX8PiNiY06XvsMaJvv42eTKEnouiJWLbVxmi5qbhkMVar0eLU9/Y2QqubGQig2TCaXS+/7HhsJYWgWgi8+SHBtz7IDay6Duig65RcdBxJdyGdnRZ2rAnT3qISsJSRVIdOtKKgc97R71KaHyLa0MeODzIkdA8+pQeXHkPXlexTKxSetghHbQWoVsJrttH3wlJjn5ZNTaqK6nSiuJwUnHMarknjQbWS3NFG+P2VqC43qtOF4nGjujyoLjeKx4utqgZL9m+InkyixWLomgaZDHomA5pmLDMZLEXFWLweADKhEMmGRtAGyqHrKC4XFo8HS3GJWVYIIcSnT7rqCXGAq/C7OGOGizNmVAIQSaRZ1dTHsv4ufo29hOJp3tnawztbe8zH1RS6jBBVk8/sugImluft3+tJiU+cx+ZhXME4xhWM22PZk8ecQX3BOPoSfQQSAfoSfTn38x35AKh2O02hJjb2bgTgXYCd8sezn3uWkuy07L9Z/hse3vgwRc7stbFOLaLQWZxdL+CEymPwKW70VBK8HnSrMfGFZ3oHzq4u9FRqF7c06uGHQzYE2PQVuD3js/uSxjKZQk8m0RMJLHO+QF55OXlAsedpgk8+hQ7EcdFHAQHyCVBAHwUkcJF/9nfAaSXz8stsWrGZ7YxlHB8yiQ8AiOFkHdMpaptMYX4NeUVOLP5iMvZNqDt1udN0IKpDfh0UGz+H1IY2Iu+uHvZnUfTVr+CeNw+A6MqV9Nx3/7BlCy+7DM9hCwBIbt1K1933DFs2/wtfwHfsMUbZ7dvp+fOfUT1eVK8X1eMxbl4PFo8H+5gx2MrKACO8ZUIh9HQa0mn0TAY9nUFPpyCTwVpairXIGGuWCQSIrV1rlEunB8plv7xxTpyAY5zxOWT6+gi/+qrxGv3fsw76+Bzjx+GaMsUoGwoRev55o5ymG+FQ04zymoZz0kTzM8uEw/T+7W9GOV0zymlGiFZdThwTJ5kX39Z1ndiKlageN6p74KY4nZ/YBCy6pg05hhWbDWtBgVmHxPr1xueVSpufa/+6pSAf96yB8YB9jz4KgGK3o9jsxtJhR7XbUf1+nOPHm2VTHR0oVmNWUKP8yE0sIw4Nejo7PnMwqxUlO5FJ/5c+wxpU9lAjwUmIA4DHYWXR2GIWjTUubKppOls6wyxv7GVFYx/LG3vZ1BGmqSdGU0+Mx1e2AOCwqkyr8jO7zghTs2oLKPcP7e4kPhsWVi5kYeXCvSr7lalf4YS6E4aEq75EH73xXgqdA1OPd8e6CSQCBBIBtga2DnmuRecuJt9bAni4fdnt/HXdX3FandhUW+7NYuO3x/yWCq8xjf/jmx/npcaXBvaPM8rYVBt21c6XJl9MuceYkn1bYBuNTa/itrnxzKvFPe9a3JqNfM1CnWaBZDZwJRJoZbXYncafL+fkyfhn2sjfnqF81lyKJx+FYrHQ0pJmxyNd7HgvAu+tN9+LopyHx2/DV+DAV+jE4VSMcTDpDE0fWlgwScNiVbFVVxOcdya9PWnK3BEKbCG0WJRYOM2OPi/d2y3Yky0oikKyIUOYuuyscCqoCoqiomeX3Vs0Js9MY3daUd1ugmWTCKa9+J0xit3GBZAzkSjBkI7f4zPrmgkESLW0Dvszzj//C2Zwim/cRNfvfjd82S98Ht+xxwKQ7uyk9y8PDFtWsVoGglMoRPDZ54YvqypmcNKiUUIvLRm+rMtpBic9lSK2bPluyrqgPzhFo3Tfe+/QQqqK6nLhnj+fgvO/YJTVdXof+Gs2EA6EINJp9GQK55TJ+M8806hvMknLd75rnETu4iTRNXs2xZd/zVzv/M1vh62vc8qUnOAUfu119MSuL27tGDsG53/+58Dz3nYbmUAw9/3bbCh2O/b6ekquvsrcHnzuOeNLif4Q7fEYQdLjweI11j8uXdfNllM9lQZ0LN6ByzIkGxrQolHjS4/+oJm9r9hseI86yiwbeOpp0m2t6LqOYrWhWCxgUY37Djv5Z59tlo0uX0GmtwfFagWLFcVqyZa3otisuKZNG6jD9u1kgoM+s506TzmnTzfDZ3L7djJ9fdlAr6GnM9kWXw0yaTyLFxuvCcRWrSLZ0GDs0zIDZbPL/C98AdVljEcOv/YasdVr0DNpI/Rn0gOPy2gUX3mFGbyDzz5L+JVXjS8IFFAdThSnE9VhR3E4jX/LpaUAJDZvJrF5M4rdgep0GF8Q9N93OLCWlqI6jN4nqfYOUs3N6Ik4WixuLrV4DD0Wx3/WmViLjfOK0L//TfCZZ9HjsezPNVfJtdfgnDgRgMibb9L74N+GPUaKr/gGrunTjbJL36Xnz39GsVhQrBZQ+39uxjL/8+eZZeMbNxJ88kmzTMEXL8Baso+XUBlhEpyEOACpqsK4Mh/jynycP68WgGA8xeqmQDZM9bKiqY++aIr3s61U/Sr9TmZlu/ZNq/IzuTIPn/NjXsNEHHRq82qpzavdq7LfnvttLp58MT3xHnriPXTHuo1lvJueWE9OyOqJ95gXKt4VjYFvMTf3beaVpleGfd2zxp5lBqfntj3H71f9fpflFBT+cupfmFFizMT3zNZnePT5R/E7/FR7q6k6uoo6XxV53nIs3krsFjvFpTEWZvwEu+OEumOEuuMEu+NkUhrhvhThvhSt28I7vVKA+Z8zWgLsNTW0qEE2bmln0bkzGHeC8Vm2bQ2w8hfLYEkf0DfosfMx3/rO5+CvxxhzihGcHOPG0TsVVi1pYvZJtUw+ZywA4d44/7zhLbg/iPufb5BX5MKXb8U9/8t4HWk81iQuJYpLC0M0ghaJmKEJsifaNhuKrf+k0zjxNE5erKjugRNq1efDOX0aSv/JafZE1Qh8CraageNG9XrxHnPM4B9GdmncsY8ePVDW48F34omgKMaFlVUVFNW4ryjY6+sHyrrd5J//BeNb62w5cyLJeBxbZaVZVs9ksI8ZbZysR6PGMmV8Y65FIkbrT3/ZaJTIm28yHGvpwEmaYrHsOtxYLdnPZuAUSVEU7HV12c960GdsM5a26pqcp/CdeAJ6PGGE/aRx07LLwe8NMIPB4JNZM5AkcidiCf/7FTKBwK7fW0U5FTffbK53/+//kgmFQNONk/u00QKop1PYSksp/sY3zLJtP/0p6bb2XbY0WMvKqPjRD831nj//hVRz8y7rYPH7c4JTfN2HJLcM/TIGQHW7coJT+PXXSKxbv8uyWC3UDPpiIPjss8RWDd8iXP27OyH78wstWUL0vfeHLeueP39QcFpN5K23hi3rP+ssyAanVGsb8bVrhy2rpwaOSy2eyPm5aew0sc+gzzy+fgPBp54a9nlLv/sdHNl/d7Fl7xN4Yvju296jjjSDEzpooeEnFPrIMumBoJ0cujvncwiFSGzaPLAvuYsHHOAkOAlxkMhz2jh8XDGHjzN+Ceq6zrauiNkitaKxj/VtQVoCcVrWtPL0moFvquuK3EytNELUlMo8plT6KfHJeClh8Dv8+B3+vSp7w/wb+H/T/x9JLUkqkyKlZW/Z+0XOIrPsiXUnUpdXl7O//5bMJCl2FZtli1xFTCmaQiQVIZqKEkkbSz37P5d1YNbJhlAD77a9u8v6KSjcd9J9zC2fy+yT6ljXvY5AbwMTfNVUuuvwZfIJ9yQJZsNUMp4xrh+m6ei68aVFv6pxBagWlaLKgdDhcFsZPavEfMzg3i5m7yolZwGKgtU20K2lsNLDqBnFFFQMPG80mMTqsJBOZIgGkkQDSdqGvDsniuLEW1CNr8hJ3ntwWFUCj9+Bc8J4Km6/A9Wi7LGbl62sjJIrrthtmX7WggKzNWdPLF4v+Z87Z6/Kqg4HvsGBbHfPm5dH2Xe+k7NNTybRsiFKcQz6Xaaq+M860+hK1B8mrQOh0pJtAQAjOJX/949Q7Xaw2lDsNiMMDdMFqeyG7+1VfQH8p52212Urf/oT4z31dxfMdl/VE4kh14DyHHEEmWAALRLJ3qJoUWNp2am1KbFx07Aha2f9r7vLfTttt5Ybgd38fPu7F9psqINapgB8Rx9NZs4cQDHCW7YLKZn0kOnbnePHY/F6ja6j/UEvY5TdeTi+tbQU+6jdzMI66N+AtbTUDPhmi5fFOrAc9Bk7JkzIBuPcVhPFkm1JcQ706HDPm4e9tsb4csBsaVHNpcU/8DvVe/RRuOfOQVFV4+ecTKLF4+bP2ZKfb5a111TjWbQILRE3wncygRZPZMvGzRYvAEtxMfYxo41xmE4HqtOF6nKiZJeWoqJB9Z2Lc+KEbEuXY8ixpdgHZqX0LFqEe8GC4T/eQV8quObOpWLSpIHxnTstrYO+4LGPHk3R1/5jYPznoH+PBwuZHEKIz5BIIs3qHQFWNBlB6sOW4C5n8AMoy3MwpdJvBqkplXlUF7ikb704YGi6RjwdJ5KKkO/Mx5a9VtGWvi1s6NlAd7yb5nAzzaFmdoR30BxuJpaO8cznnqHGZ7QA3LniTu5dPdDNy6baqPRWUuWtotpbzTdnf9MMjUsalvB269tk9AyarpHRssvs+rfnfttsIXtq61M8tfUpdF3HY/NQ6CykwFlAgaOAQmchCyoWUOAcGB+zN/+udF0nHkkR7IobLWRdMbPFrH9bJp07LuErvzocl9c44XnjkU2se7OVeafVM/N4o9UolczQ1xbFX+oyuzeKzyZd03JCX2zNWrRIxDiZtwxqgbRaUZ1OswUNIN1tzOyJqhrh0WIZGMdiscjfBfGZJpNDCHGI8jisLBxTxMIxA98y9UaSfNAS5IOWAGuzy21dEdqDCdqDHby8vsMs63fZmFyRx9QqI0xNrcpjVLEXiyp/NMX+pyoqbpsbty13Zosx+WMYkz9mSHld1+mJ95iTZABUeatYULGA5lAzbZE2UlqKhmADDcEGAC6bepkZnFZ1reKhDQ8NW5+vTf+aGZyaQk282Tx8l7AHTn3ADE4PrHuAu1fdTaGzkHxHPgVOI1wVOAoocBZwUv1JlHvKURSFhDVKojBIYbmXOlslNstAN1td04mGkgS7jFAV7o3j9AzsD7RHScbSWO0Wc1v3jjCP/mIZAG6/nfxSN/ll7uzSRX6Zm7xi124vPNzXHiUSSFBQ7sGdZ4S0zqYQG95uIxFLkYimScbSJGJpbA4L7jw7br8Dj9+OOy+7zK47vTLxwadl55Yy17Spe/1Y66CWCSHE8CQ4CfEZV+Cx53TxA6Nlal1rcCBQNQfZ1BEiEEvx9tZu3t7abZZ12SxMrsxjamUeU6r8TK30M67Mi02uMSUOMIqiUOTKPQH83LjP8blxnwMgraVpj7bTHGqmOWy0UnltA12LDqs4DIfFgaqoWBSLeVMVFYtqocQ1MD7m2JpjqfRUoigKoWSInngPffE+ehO99MR7KHWVmmV74j2EkiFCyRANNAyp96zSWWYge2zzY9y27DZzn12147V78dq8eO1ebjrsJqaMmULFGD8rO1Zy54on8Nl95NnzKDqtmMOOLaWo2Ga2csUjKVw+G7FQyuwC2LKpL/dzUxXyipzYnBaSsTSKovClHw9MQvLKg+tp3tDHiV+dwrh5RrebUFecVS837euPiK/feTQWmxGcVi1porctwoQF5VSMzd/n5xJCiP1NgpMQhyCPw8rc+kLm1g8M+k+kM2xqD/NBSyAbqIJ82BIklsqY15vqZ7eoTKzwma1SUyv9TCj34bRZdvVyQhwQrKqVKm8VVd6qXe5fVLmIRZWL9uq5JhROYELhhL0q+9WpX+WM0WcY4SrRR0+8h954r3m/PzSBMbmGy+oilja62Ca1pDlpB0BGHxhEvqpzFX9Y84ddvqZdtfO7437HwmkL+covj2D1jg9YtnE13lgR9pAXvc9Golsn0BEjlcgQ6Bzo0quqSk73wrwiF5GyJKp1oKWooMLN7JNqcbht2F1WHG4rdqeVVCJDJJDIhrQEkWB2GTDGyVgGjfVqWNtF07peysf4JTgJIQ4KMsZJCDGsjKazrSvM2uYga5sDrG0J8EFzkFBi6FSmVlVhbKmXqVV+plbmMbXKz6SKPDwO+X5GiH2V0TJE0hHCyTDhVNhcziqdhc9uTFn+Tus7vNz4MpFUhN54Lx3RDjqiHfQmjC85Hjr9ISYXTQbg/rX38+tlvx7yOoWOQqot9Xy97pvUuutxuK282/s2z3Q/RkpPkdbSpLW0OalHWkvzsyN/xpQiYwryh9Y/xG3LbjP3uawufDYfPrtx+9acbzG7bDYA67s28HbbW+a+9GY3ereN+llFVNYWkWfPw6rK7wshxP4lY5yEEJ8Ii6owttTH2FIfZ88yvqXXNJ2m3qgRploCRqBqDtAbTbG+LcT6thCPGEMqUBQYVexhfKmPcWVeY4r1Ui+jSzw4rNI6JcRwLKqFPHseefbh/4gfVnEYh1UcNmR7MpOkI9pBqXugu2BdXh0n159MR7SD9mg7HdEOUlqKnkQPPfRQPMZNXXacS9faFt5sHX78VjQVNe/r6GbrGEAsHSOWjtERM8ZODp62fk3P6l2GN942brcddRsn1p8IwLut73LfB/eZ48B2Xo7JH7PXM0EKIcQnRYKTEGKfqKpCXZGHuiIPp003LnSq6zqtgXi2VSrIB9nWqfZggq2dEbZ2Rnjug4HnsKgKdUVuxpV6GV/mY2x2KYFKiI/PbrFT7avO2XZs7bEcW3usua7rOn2JPjNE1eUNzLB2RNURFLuKsSpWbBbbwFK1YlNtjCsYZ5Y9dfSpLK5ajE019sfTcXM8VygZyunOWOOr4YzRZxBKhggmg4RSA+UiqYjZkgbGlPO7m3zjl0f9kpPrTwbgtR2v8ev3f20EK2eB0ZqVbSVLa2m+POXLTCsxLp76ZvOb3LXyrpxWtMFT5d+08CZOqDsBgNWdq/nV+7+iyFlEkatoyLI+r558Z/5H+AkJIQ5WEpyEEB+boihU5ruozHdx4pSB8RodoTgb2kJsbA+zqT3Epo4wG9tDhOJpM1A9/0G7WV5VoL7IY7ROZVupJFAJ8clTFMUMGhMLJ+bsG1cwLicc7c6eWsUGG66FDIyJO5SBK18xv3w+P178Y/riffQkjDFhvfFeehPGcvBEHW2RNrYEtsAwlyw6ZdQpTMMITqFkiDVda4at4+DWtOZwMys6Vgxb9qaFN/H58Z8HjPFmv3jvFznhymf34bA4cFgczC6bbYbTYDJIQ6ABu8WO0+rEYXHgtDjNdVWRiXeEOFBJcBJCfGpKfU5KfU6OGDdwkqPrOh2hBBvbjUC1ucNYmoGqK8LWrtxAZVEV6ovcTCj3Mb7Mx4QyH+PLfdQVurHK7H5CHPR2HttUl1eX0wq2O8fWHkttXi29cWNGw0gqYraOWVUrEwoGWr1mlc7izmPvxKbajJvFZpazqbac7o2zS2dz21G30R3vpjvWPWRZ5h64sGdzqJnVnauHreN/L/pv8/2s6ljFFUuGvwDxDfNv4MJJFwJGq9cNr99g1tWu2o26Zut97rhzOb7ueKMO4WbuX3u/+d6sqhWHxUGBs4AiZxHjC8ZTk1ezV5+pEGLXJDgJIfYrRVEoy3NSljd8oNrUHmZTh7Hc2B4iGE+zpTPCls4Iz6xpMx9jt6qMK/WaQap/Wel3yrVihDhEFLuKKXYV77kgUOYpo8xTtueC2bInek7cq7JzyuZw+9G35wSrSDpCMpMkno5T6a00y1pUC5WeSuKZuLE/EyetDUy4Y7fYzfvhVJjGUOOwr7uwYmDa+M5o526vQ/b1GV/nyplXAtAQbOBrL3yNQmchRa4iY+k0loWuQiYXTmZ0/mgAUlqKvngf4VSYSCpiLJPGMpwKM714utkVsiHYwK/e+1Vu2VQEi2KhwFnA58Z9josmXQQYrXuPb3ncHLuW78g3r3U2+PplQhxIJDgJIQ4IuwtU7cEEG9pDbGwLGcvsLZ7SzKnTB/M6rIwv8+a0UI0t9VLic0igEkJ84vYlkC2qXMTz5z2fsy2jZUhkEiQyCZxWp7l9avFU/nzKn3PGYaW0FMlMkpSWYmrRwEVuy9xlXDHjCpJa0iwfz8TN6ewHt+B1xbpojbTSGmndZR2/MeMbXDHTaBVb27WWS569ZNj3c+XMK83glMwkeWXHK7ss1xnrJJAY6E/ZFmnjp0t/usuyPpuPL03+klmHrlgXv1/5exQU83d4/30Fhfnl8zmu7jjA6Ap576p7zX3G/xVURcVusTOlaApHVh8JGF1E32x+E4fV6C7psrrM7pMuqwuX1ZUTZHdF13XSWhod3Syr6zo7wjtyZqXsXzosDio8FUOuOScODhKchBAHNEVRKPc7Kfc7OWr8QKDqn93PGEMVYkN7mI1tIbZ0hgkn0ixv7GN5Y1/Oc3kdVkYVexhd4mF0sTG7X/99l13GUAkhRoZFteBW3bht7pztefY8ZpXO2qvnqPBW8I2Z39irspMKJ/HgqQ/SHe+mJ95Ddyx32d/aBOCxeVAVFY/Ng9fmxWPz5Nyv99ebZcs95fxw4Q/x2D14rB68di9uqxtN1+iN9+a0vFlVKyfUnZAzfq0v0Yema4RSoZwxb8FkkIc3Pjzs+7GoFjM4RZIR/u/D/xu27HnjzzODUyQV4aqXrxq27KmjTuXnR/4cMFreTn7kZNJ6mlQmlbMEOKX+FH5x1C8A43prp/7z1GGfd27ZXO4/+X5z/ZZ3bsFj81DuKafcXW4sPeXkO/Lly74DjAQnIcRBafDsfoMnpEimNbZ1RYa0UDX1RAkn0qxpDrCmeego8kq/k9El2TBV7GFUiZfRxR6q8l2oqvzhEkJ8drhtbrOVaE/G5Y9j5cUr9+oE3mf3ce74c/fqeWvzavn10bnT02u6RigZoifekzPLYr4j32h90o0p8HV0dF1H0zUAZpbONMu6bW6+POXLZpnB5ROZhHldsf7Xm1o0lXgmTjwdz1n2X5esXzwdN6fZ35WUljLvWxQLLqsrZ6xd/9izaDqaEyBTmRT/2PAPdIZeVtVpcXJ83fHcesSt5rYntjyBXbVjUS1YFAtW1YpFsWBRLRQ6CxlfMN4su6FnA6qiYlWtWBWr+RiLasGm2nKm9G8ON5PRMmi6hoZmfr6ablyUuzav1iz7QdcHpLSU2SrntDrN+5/1a7HJBXCFEIeERDpDY3eULZ0RtnaFs7P6hdnaFaEvmhr2cQ6rarZS1Rdlb8Ue6ovc0vVPCCE+o1JaCk3XcFgcgNGtb1PvpiFhqH+yjv4ZFPeGruvm3454Os7f1v+NtkibcYsay554DwBnjD6Dnx5hdGlMZVLMeWDOLkMWwLE1x/KbY39jrs/880wyemaXZRdXLeae4+8x1+f/dX7ONdkGm106m/87ZaAV76iHjjLrt7NJhZP4xxn/MNev/fe19MR7zGA1OGxdMvkSyj3lu3ye/UkugCuEEDtxWC3GBXjLfEP29USSZogaHKgauiMk0pp5Yd+due0W6oqMENUfpuqKPIwq9lAqoUoIIQ5aNjV3ggqramVS0aRP5LkH/21wWp18eeqXh5RJZpK0R9pzykbTUY6sPpJYOkZaS5PRM2S0DBk9Q1pP57Rk6bpOobPQ2DeobFpPk9Ey7Jy9+rtkqqgoijEmrP+288Wmq33VuK1u4pm4edHr/ta/nSf2WNO1ho7orlvqzh579gERnPaFtDgJIcQw0hmNHb0xs4WqoTvK9u4I27sjNPfG0Hbz29Nls1BX5Ka+yENdsZtR2W6FdUVuyvOc0v1PCCHEZ4Ku6yQ1YwbJjJ6h0Flo7nun9R1CyRCxdIx4eiBoxdIxLp1yaU7ZkbIv2UCCkxBCfATJtEZTb5SG7gjbu/oDlbG+ozdGZjepym5VqSlwmUGqrtBoqaotclNd4JKL/QohhBD7iXTVE0KIT5ndqjKmxMuYEu+Qfcm0RnNfzAhTXUZL1bZs178dvTGSac28LtXOFAUq/S4jUBW5qS30mPfrijx4HfJrWwghhBgJ0uIkhBD7UTqj0RqIm93+GnuMVqqG7iiNPVGiyV0P5O1X6LFTU+CiutBNbaGbmgI3NYUuagrcVOa7sFvV/fROhBBCiIOfdNXbDQlOQogDla7rdIYTNHZHaeiO0rBTqOqJJHf7eFWB8jwnNYVu49YfqrL3S30OGVslhBBCDCLBaTckOAkhDlbBeIqmnihNPTFj2RvNLo31RFrb7ePtVpXqAqN1qrrARbW5NO4Xe+0yE6AQQohDioxxEkKIz6A8p40plX6mVPqH7NN1nc5QIhumBoJVYzZotQaMsVXGdOtDx1aBcc2qql0Eqv77JV6ZYl0IIcShS4KTEEJ8BiiKQmmek9I8J3Pqhu5PZTRa++I09UbZ0RtlR28sezPutwXjJPYhWFX6nVT4XVT4nZT7nVTmOyn3u2TyCiGEEJ9Z8hdOCCEOATaLSm2Rm9oi9y73J9MabYH4oFCVG672JlgB+JxWKgaFKnOZ78yGLAlXQgghDk7y10sIIQR26+6DVSpjBKum/haqQJzWQIzWQJzWPuN+MJ4mFE8TiofZ2B4e9rX6w1W530VFntFiVeF3UpZdVuS5yHNZpVugEEKIA4oEJyGEEHtks6jmbH3DCSfSQwJVWzBGS1+ctkCclkAsG6z2HK5cNgvlfifleU6zO+DAuotyv5Mij11mCRRCCLHfSHASQgjxifA6rIwt9TK2dOhFgfsZ4SobpoJx2gNxWoPxbOCK0xaI0RtNEUtl2NYVYVvX8N0CbRaFsjwnlX5Xtitgf/dAJ5X5xv1Cj8wUKIQQ4pMhwUkIIcR+Y4QrH2NLfcOWiacytAf7g5SxNNZj5npnOEEqo5vjsIZjt6oDYSrbUlWR76JyUAtWgVtaroQQQuzZARGc7rrrLn75y1/S1tbGjBkzuPPOO5k/f/6w5fv6+viv//ov/vnPf9LT00NdXR133HEHp5566n6stRBCiE+D02ahrshDXZFn2DKpjEZHKEFrX7ZbYLYVqz9ctQTidIUTJNOacTHh7uiwz2VVFYq9Dkp82dvg+z4HpYPuu+0HxJ9NIYQQI2DE/wI89NBDXHfdddxzzz0sWLCAO+64g5NOOokNGzZQWlo6pHwymeSEE06gtLSURx55hKqqKhoaGsjPz9//lRdCCDEibBaVqnwXVfmuYcsk05rZcjUw7ipGS/96X5zuSJK0ptMWNLoO7onHbhkUqJy7DFulPgeFHjtWi/pJvmUhhBAjTNF1XR/JCixYsIB58+bxu9/9DgBN06ipqeHqq6/me9/73pDy99xzD7/85S9Zv349Npttn19vX64OLIQQ4rMtldHoDifpDCXoDMfpDCXoCCboDCeMbSHjfkcwQSyV2evnVRQo8tgp9joozXPuthXL55AZBIUQYqTsSzYY0eCUTCZxu9088sgjnH322eb2Sy+9lL6+Ph5//PEhjzn11FMpLCzE7Xbz+OOPU1JSwoUXXsj111+PxWIZUj6RSJBIJMz1YDBITU2NBCchhBB7Tdd1IsnMQJgKJegIxekIJegKDQStjlCC7nACbR/+sjqsKsVeB8VeI2gVmcuBbf3bC9x2LDIeSwghPjH7EpxGtKteV1cXmUyGsrKynO1lZWWsX79+l4/ZunUrL7/8MhdddBHPPPMMmzdv5oorriCVSnHzzTcPKX/rrbfyox/96FOpvxBCiEODoih4HVa8DiujiocfewWQ0XR6IslBrVXx3Bas/qAVTBBKpEmkNZr7YjT3DT/JRT9VgULPQMAq8jgGhS1jvdBrp9hjbHPbLdKaJYQQn5ARH+O0rzRNo7S0lHvvvReLxcKcOXNobm7ml7/85S6D0w033MB1111nrve3OAkhhBCfBouqmN3w9iSWzNAVTmRvSboH3e8KJ+juX0aS9EaTaDrZfcm9qovTplLk6Q9Zdgo9RitWkde4X5QNWYXZ/U7b0J4bQgghDCManIqLi7FYLLS3t+dsb29vp7y8fJePqaiowGaz5XTLmzRpEm1tbSSTSex2e055h8OBw7HnP15CCCHE/uayW/Z4YeF+6YxGTzRJVyhJdyQxKFgZ4aon0h+8jP3xlEY8tfetWQA+h5ViX24XwWKvg2LfwHpJdl1mGBRCHGpG9Lee3W5nzpw5LFmyxBzjpGkaS5Ys4aqrrtrlYxYvXsyDDz6IpmmoqjFj0caNG6moqBgSmoQQQojPCqtFpdTnpNTn3Kvy0WSa7nCS7myg6g4n6Yok6MluGwhbRtBKZXRCiTShRHq3Fx7u57ZbcsZmFfscFHvsFHrsFHod2RaubOuWW2YZFEIc/Eb866LrrruOSy+9lLlz5zJ//nzuuOMOIpEIX/7ylwG45JJLqKqq4tZbbwXgG9/4Br/73e+45ppruPrqq9m0aRM//elP+eY3vzmSb0MIIYQ4oLjtVtyF1r1qzdJ1nWAsTVfEmOyivxWr/9YZyl2PpzSiyQyNPVEae4a/RtZgfpeNov4gle02OHi9yOPIbreT77ZJt0EhxAFnxIPT+eefT2dnJzfddBNtbW3MnDmT5557zpwworGx0WxZAqipqeH555/nW9/6FtOnT6eqqoprrrmG66+/fqTeghBCCHFQUxQFv9uG321jTIl3t2X7Zxg0AlY2WIWTdIWMFqyeQa1ZPYPGZgViKQKxFFv3ojULwGWzUOC2UeAxZhPMd9socNuH2WanwGPDK1O7CyE+RSN+Haf9Ta7jJIQQQuw/GU0nEEsZ3QWzYaq/+2D//Z5w//YEfdEU6X2Zz30Qq6qQ77ZT6DECldF6lbveH7oKJWwJITiIpiMXQgghxGebRVXMLnjj9qK8rhtjrfoiKXqjSXqiSfqiSXqz68YtRV80SU/EWPZGk8RTGmlNN1vB9pbNouS0WhVmg5WxvlPoym7zyDTvQhySJDgJIYQQ4oChKAp5Tht5Thu1RXsen9UvlsyYwaovmjK7CfZEkvRGjLA1eL0nG7ZSGZ2O7MWL95bdolIwJFDZsq1YA9uOHF/yUT4CIcQBSoKTEEIIIQ56LrsFl91FZb5rrx/TH7b6Q1ZvNEVvtvtgX3b7ziEskdZIZjTagwnag8OHLZ/TypofnvRJvDUhxAFCgpMQQgghDkkfNWz1RLOtVv2BK5KkJxu6+lu9HFaZFVCIzxoJTkIIIYQQe8llt1Bld1G1D2FLCPHZIFejE0IIIYQQQog9kOAkhBBCCCGEEHsgwUkIIYQQQggh9kCCkxBCCCGEEELsgQQnIYQQQgghhNgDCU5CCCGEEEIIsQcSnIQQQgghhBBiDyQ4CSGEEEIIIcQeSHASQgghhBBCiD2Q4CSEEEIIIYQQeyDBSQghhBBCCCH2QIKTEEIIIYQQQuyBBCchhBBCCCGE2AMJTkIIIYQQQgixBxKchBBCCCGEEGIPJDgJIYQQQgghxB5IcBJCCCGEEEKIPZDgJIQQQgghhBB7YB3pCuxvuq4DEAwGR7gmQgghhBBCiJHUnwn6M8LuHHLBKRQKAVBTUzPCNRFCCCGEEEIcCEKhEH6/f7dlFH1v4tVniKZptLS04PP5UBRlpKtDMBikpqaGpqYm8vLyRro6Qpjk2BQHMjk+xYFMjk9xIJPjM5eu64RCISorK1HV3Y9iOuRanFRVpbq6eqSrMUReXp4cvOKAJMemOJDJ8SkOZHJ8igOZHJ8D9tTS1E8mhxBCCCGEEEKIPZDgJIQQQgghhBB7IMFphDkcDm6++WYcDsdIV0WIHHJsigOZHJ/iQCbHpziQyfH50R1yk0MIIYQQQgghxL6SFichhBBCCCGE2AMJTkIIIYQQQgixBxKchBBCCCGEEGIPJDgJIYQQQgghxB5IcBpBd911F/X19TidThYsWMC777470lUSh6DXXnuNM844g8rKShRF4bHHHsvZr+s6N910ExUVFbhcLo4//ng2bdo0MpUVh5Rbb72VefPm4fP5KC0t5eyzz2bDhg05ZeLxOFdeeSVFRUV4vV7OPfdc2tvbR6jG4lBy9913M336dPMiogsXLuTZZ58198uxKQ4kP/vZz1AUhWuvvdbcJsfovpPgNEIeeughrrvuOm6++WaWL1/OjBkzOOmkk+jo6BjpqolDTCQSYcaMGdx111273P+LX/yC3/72t9xzzz0sXboUj8fDSSedRDwe3881FYeaV199lSuvvJJ33nmHF198kVQqxYknnkgkEjHLfOtb3+LJJ5/k4Ycf5tVXX6WlpYXPfe5zI1hrcaiorq7mZz/7GcuWLeP999/n2GOP5ayzzuKDDz4A5NgUB4733nuP//mf/2H69Ok52+UY/Qh0MSLmz5+vX3nlleZ6JpPRKysr9VtvvXUEayUOdYD+r3/9y1zXNE0vLy/Xf/nLX5rb+vr6dIfDof/tb38bgRqKQ1lHR4cO6K+++qqu68axaLPZ9Icfftgss27dOh3Q33777ZGqpjiEFRQU6H/84x/l2BQHjFAopI8bN05/8cUX9aOOOkq/5pprdF2X358flbQ4jYBkMsmyZcs4/vjjzW2qqnL88cfz9ttvj2DNhMi1bds22traco5Vv9/PggUL5FgV+10gEACgsLAQgGXLlpFKpXKOz4kTJ1JbWyvHp9ivMpkMf//734lEIixcuFCOTXHAuPLKKznttNNyjkWQ358flXWkK3Ao6urqIpPJUFZWlrO9rKyM9evXj1CthBiqra0NYJfHav8+IfYHTdO49tprWbx4MVOnTgWM49Nut5Ofn59TVo5Psb+sWbOGhQsXEo/H8Xq9/Otf/2Ly5MmsXLlSjk0x4v7+97+zfPly3nvvvSH75PfnRyPBSQghxAHvyiuvZO3atbzxxhsjXRUhTBMmTGDlypUEAgEeeeQRLr30Ul599dWRrpYQNDU1cc011/Diiy/idDpHujqfGdJVbwQUFxdjsViGzFzS3t5OeXn5CNVKiKH6j0c5VsVIuuqqq3jqqaf497//TXV1tbm9vLycZDJJX19fTnk5PsX+YrfbGTt2LHPmzOHWW29lxowZ/OY3v5FjU4y4ZcuW0dHRwezZs7FarVitVl599VV++9vfYrVaKSsrk2P0I5DgNALsdjtz5sxhyZIl5jZN01iyZAkLFy4cwZoJkWvUqFGUl5fnHKvBYJClS5fKsSo+dbquc9VVV/Gvf/2Ll19+mVGjRuXsnzNnDjabLef43LBhA42NjXJ8ihGhaRqJREKOTTHijjvuONasWcPKlSvN29y5c7nooovM+3KM7jvpqjdCrrvuOi699FLmzp3L/PnzueOOO4hEInz5y18e6aqJQ0w4HGbz5s3m+rZt21i5ciWFhYXU1tZy7bXXcssttzBu3DhGjRrFjTfeSGVlJWefffbIVVocEq688koefPBBHn/8cXw+n9nv3u/343K58Pv9fPWrX+W6666jsLCQvLw8rr76ahYuXMhhhx02wrUXn3U33HADp5xyCrW1tYRCIR588EFeeeUVnn/+eTk2xYjz+XzmeNB+Ho+HoqIic7sco/tOgtMIOf/88+ns7OSmm26ira2NmTNn8txzzw0ZhC/Ep+3999/nmGOOMdevu+46AC699FL+9Kc/8d3vfpdIJMLll19OX18fhx9+OM8995z0mRafurvvvhuAo48+Omf7/fffz2WXXQbA7bffjqqqnHvuuSQSCU466SR+//vf7+eaikNRR0cHl1xyCa2trfj9fqZPn87zzz/PCSecAMixKQ58cozuO0XXdX2kKyGEEEIIIYQQBzIZ4ySEEEIIIYQQeyDBSQghhBBCCCH2QIKTEEIIIYQQQuyBBCchhBBCCCGE2AMJTkIIIYQQQgixBxKchBBCCCGEEGIPJDgJIYQQQgghxB5IcBJCCCGEEEKIPZDgJIQQQuyGoig89thjI10NIYQQI0yCkxBCiAPWZZddhqIoQ24nn3zySFdNCCHEIcY60hUQQgghdufkk0/m/vvvz9nmcDhGqDZCCCEOVdLiJIQQ4oDmcDgoLy/PuRUUFABGN7q7776bU045BZfLxejRo3nkkUdyHr9mzRqOPfZYXC4XRUVFXH755YTD4Zwy9913H1OmTMHhcFBRUcFVV12Vs7+rq4tzzjkHt9vNuHHjeOKJJ8x9vb29XHTRRZSUlOByuRg3btyQoCeEEOLgJ8FJCCHEQe3GG2/k3HPPZdWqVVx00UVccMEFrFu3DoBIJMJJJ51EQUEB7733Hg8//DAvvfRSTjC6++67ufLKK7n88stZs2YNTzzxBGPHjs15jR/96Ed84QtfYPXq1Zx66qlcdNFF9PT0mK//4Ycf8uyzz7Ju3TruvvtuiouL998HIIQQYr9QdF3XR7oSQgghxK5cdtllPPDAAzidzpzt3//+9/n+97+Poih8/etf5+677zb3HXbYYcyePZvf//73/OEPf+D666+nqakJj8cDwDPPPMMZZ5xBS0sLZWVlVFVV8eUvf5lbbrlll3VQFIUf/OAH/PjHPwaMMOb1enn22Wc5+eSTOfPMMykuLua+++77lD4FIYQQBwIZ4ySEEOKAdswxx+QEI4DCwkLz/sKFC3P2LVy4kJUrVwKwbt06ZsyYYYYmgMWLF6NpGhs2bEBRFFpaWjjuuON2W4fp06eb9z0eD3l5eXR0dADwjW98g3PPPZfly5dz4okncvbZZ7No0aKP9F6FEEIcuCQ4CSGEOKB5PJ4hXec+KS6Xa6/K2Wy2nHVFUdA0DYBTTjmFhoYGnnnmGV588UWOO+44rrzySn71q1994vUVQggxcmSMkxBCiIPaO++8M2R90qRJAEyaNIlVq1YRiUTM/W+++SaqqjJhwgR8Ph/19fUsWbLkY9WhpKSESy+9lAceeIA77riDe++992M9nxBCiAOPtDgJIYQ4oCUSCdra2nK2Wa1WcwKGhx9+mLlz53L44Yfz17/+lXfffZf//d//BeCiiy7i5ptv5tJLL+WHP/whnZ2dXH311Vx88cWUlZUB8MMf/pCvf/3rlJaWcsoppxAKhXjzzTe5+uqr96p+N910E3PmzGHKlCkkEgmeeuopM7gJIYT47JDgJIQQ4oD23HPPUVFRkbNtwoQJrF+/HjBmvPv73//OFVdcQUVFBX/729+YPHkyAG63m+eff55rrrmGefPm4Xa7Offcc/n1r39tPtell15KPB7n9ttv5z//8z8pLi7mvPPO2+v62e12brjhBrZv347L5eKII47g73//+yfwzoUQQhxIZFY9IYQQBy1FUfjXv/7F2WefPdJVEUII8RknY5yEEEIIIYQQYg8kOAkhhBBCCCHEHsgYJyGEEAct6W0uhBBif5EWJyGEEEIIIYTYAwlOQgghhBBCCLEHEpyEEEIIIYQQYg8kOAkhhBBCCCHEHkhwEkIIIYQQQog9kOAkhBBCCCGEEHsgwUkIIYQQQggh9kCCkxBCCCGEEELswf8H7Tvs/L5IiQoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_comparison(histories=[lstm_history, lstm_dropout_history, gru_history],\n",
    "                        model_names=[\"LSTM\", \"LSTM with Dropout\", \"GRU\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the **LSTM** model learns quickly, achieving a lower training loss over time compared to the other models. Based on its validation loss curve, the model seems to generalize more or less well (but maybe is enough for our case ?), as the validation loss does not diverge significantly from the training loss. However, the direction of training and validation loss curves suggests mild underfitting, meaning the model might still benefit from additional capacity or a longer training duration to capture more complex patterns.\n",
    "\n",
    "The **LSTM with Dropout** model learns at a similar rate initially but stabilizes earlier than the standard LSTM. Its validation loss is close to the training loss, indicating better generalization and reduced overfitting, which is expected due to dropout regularization. However, this stability comes at the cost of a slightly higher error than the standard LSTM model. Is a high generalization what we need in this study case ? We will see it later.\n",
    "\n",
    "Finally, **GRU** shows decent performance, similar to the LSTM with Dropout in terms of generalization. Its training and validation loss curves are also close, which indicates good generalization and stability. However, like the LSTM with Dropout, it seems to converge to a slightly higher loss than the standard LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Generation Tools (Deeplearning version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is the equivalent of `choose_top_k` implemented for `n_gram` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_top_k(predictions, k):\n",
    "    \"\"\"\n",
    "    Samples an index from the top k predictions, weighted by probabilities.\n",
    "    \n",
    "    Parameters:\n",
    "        predictions (np.array): Array of probabilities for the next character.\n",
    "        k (int): Number of top predictions to consider.\n",
    "    \n",
    "    Returns:\n",
    "        int: The index of the chosen character.\n",
    "    \"\"\"\n",
    "    # Sort the probabilities and get the top k indices\n",
    "    top_k_indices = np.argsort(predictions)[-k:]\n",
    "    top_k_probs = predictions[top_k_indices]\n",
    "    \n",
    "    # Normalize probabilities to sum to 1\n",
    "    top_k_probs = top_k_probs / np.sum(top_k_probs)\n",
    "    \n",
    "    # Sample from the top k indices based on their probabilities\n",
    "    chosen_index = np.random.choice(top_k_indices, p=top_k_probs)\n",
    "    \n",
    "    return chosen_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like it was done before, there is a function to generate one name with one of the implemented model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(model, vocab: dict, reverse_vocab: dict, max_length: int, sequence_length: int, top_k: int) -> str:\n",
    "    \"\"\"\n",
    "    Generates a new name using the trained model, starting with the <0> token, with added randomness through top_k sampling.\n",
    "    \n",
    "    Parameters:\n",
    "        model (Model): Trained Keras model for name generation.\n",
    "        vocab (dict): Dictionary mapping characters to integer IDs.\n",
    "        reverse_vocab (dict): Dictionary mapping integer IDs back to characters.\n",
    "        max_length (int): Maximum length of the generated name.\n",
    "        sequence_length (int): Length of each input sequence for the model.\n",
    "        top_k (int): Number of top probable characters to sample from.\n",
    "    \n",
    "    Returns:\n",
    "        str: Generated name.\n",
    "    \"\"\"\n",
    "    # Start with the <0> token repeated to form the initial sequence\n",
    "    start_token = [vocab[\"0\"]] * sequence_length\n",
    "    name = []\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        input_seq = np.array([start_token])  # Shape (1, sequence_length)\n",
    "        predictions = model.predict(input_seq, verbose=0)[0]  # Predict next character probabilities\n",
    "        \n",
    "        # Sample the next character index from the top k probable choices\n",
    "        next_char_index = sample_from_top_k(predictions, top_k)\n",
    "        next_char = reverse_vocab[next_char_index]\n",
    "        \n",
    "        # Stop if the end token <1> is generated\n",
    "        if next_char == \"1\":\n",
    "            break\n",
    "        \n",
    "        # Append the predicted character to the name\n",
    "        name.append(next_char)\n",
    "        \n",
    "        # Update the input sequence by shifting and adding the new character\n",
    "        start_token = start_token[1:] + [next_char_index]\n",
    "\n",
    "    # Join the list of characters to form the generated name\n",
    "    return ''.join(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purpose, another function to generate multiple names at one will be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_names(model, vocab: dict, reverse_vocab: dict, num_names: int, max_length: int, sequence_length: int, top_k: int) -> list:\n",
    "    \"\"\"\n",
    "    Generates multiple names using the trained model, each starting with the <0> token and using top_k sampling.\n",
    "    \n",
    "    Parameters:\n",
    "        model (Model): Trained Keras model for name generation.\n",
    "        vocab (dict): Dictionary mapping characters to integer IDs.\n",
    "        reverse_vocab (dict): Dictionary mapping integer IDs back to characters.\n",
    "        num_names (int): Number of names to generate.\n",
    "        max_length (int): Maximum length of each generated name.\n",
    "        sequence_length (int): Length of each input sequence for the model.\n",
    "        top_k (int): Number of top probable characters to sample from.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of generated names.\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    \n",
    "    for _ in range(num_names):\n",
    "        name = generate_name(model=model, vocab=vocab, reverse_vocab=reverse_vocab, max_length=max_length, sequence_length=sequence_length, top_k=top_k)\n",
    "        names.append(name)\n",
    "    \n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of Dino Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k (one of k most probable letters) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated LSTM Names: ['raptor', 'raptor', 'raptor', 'raptor', 'raptor', 'raptor', 'raptor', 'raptor', 'raptor', 'raptor']\n",
      "Generated LSTM with Dropout Names: ['uanosaurus', 'uanosaurus', 'uanosaurus', 'uanosaurus', 'uanosaurus', 'uanosaurus', 'uanosaurus', 'uanosaurus', 'uanosaurus', 'uanosaurus']\n",
      "Generated GRU Names: ['nchisaurus', 'nchisaurus', 'nchisaurus', 'nchisaurus', 'nchisaurus', 'nchisaurus', 'nchisaurus', 'nchisaurus', 'nchisaurus', 'nchisaurus']\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 names from each model\n",
    "num_names = 10\n",
    "\n",
    "lstm_names = generate_multiple_names(model=lstm_model, vocab=vocab, reverse_vocab=reverse_vocab, num_names=num_names, max_length=max_word_length, sequence_length=sequence_length, top_k=1)\n",
    "lstm_dropout_names = generate_multiple_names(model=lstm_dropout, vocab=vocab, reverse_vocab=reverse_vocab, num_names=num_names, max_length=max_word_length, sequence_length=sequence_length,top_k=1)\n",
    "gru_names = generate_multiple_names(model=gru_model, vocab=vocab, reverse_vocab=reverse_vocab, num_names=num_names, max_length=max_word_length, sequence_length=sequence_length,top_k=1)\n",
    "\n",
    "# Print the generated names\n",
    "print(\"Generated LSTM Names:\", lstm_names)\n",
    "print(\"Generated LSTM with Dropout Names:\", lstm_dropout_names)\n",
    "print(\"Generated GRU Names:\", gru_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated LSTM Names: ['raptor', 'ryodon', 'ryphosaurus', 'trosaurus', 'raptor', 'raptoraptor', 'ryphus', 'rahale', 'raptor', 'ryptor']\n",
      "Generated LSTM with Dropout Names: ['inosaurus', 'ulasaurus', 'ulanosaurus', 'inosaurus', 'iaraptor', 'inganosaurus', 'iangosaurus', 'uanosaurus', 'uanosaurus', 'ianganosaurus']\n",
      "Generated GRU Names: ['rchaeosaura', 'rgong', 'ndosaurus', 'ncondylus', 'ncheirus', 'ndromerus', 'nchenius', 'rgongosaurus', 'rgosaurus', 'ndosauraptor']\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 names from each model\n",
    "num_names = 10\n",
    "\n",
    "lstm_names = generate_multiple_names(model=lstm_model, vocab=vocab, reverse_vocab=reverse_vocab, num_names=num_names, max_length=max_word_length, sequence_length=sequence_length, top_k=2)\n",
    "lstm_dropout_names = generate_multiple_names(model=lstm_dropout, vocab=vocab, reverse_vocab=reverse_vocab, num_names=num_names, max_length=max_word_length, sequence_length=sequence_length,top_k=2)\n",
    "gru_names = generate_multiple_names(model=gru_model, vocab=vocab, reverse_vocab=reverse_vocab, num_names=num_names, max_length=max_word_length, sequence_length=sequence_length,top_k=2)\n",
    "\n",
    "# Print the generated names\n",
    "print(\"Generated LSTM Names:\", lstm_names)\n",
    "print(\"Generated LSTM with Dropout Names:\", lstm_dropout_names)\n",
    "print(\"Generated GRU Names:\", gru_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated LSTM Names: ['ropelta', 'nichasaurus', 'ratothodesteondypsaurus', 'nedmoresaurus', 'ititan', 'iriasaurus', 'rahoes', 'ryosaurasaurus', 'bias', 'tamosaurus']\n",
      "Generated LSTM with Dropout Names: ['errus', 'indoraptor', 'ungshiceratitangosaurus', 'uanshanosaurus', 'unasaurus', 'iravur', 'ulicondrachinosaurus', 'yplus', 'yplosaurus', 'uangatops']\n",
      "Generated GRU Names: ['criscapauceratus', 'rator', 'ntiragosaurus', 'lomomaeus', 'nocerator', 'rchanosaurus', 'nchistoceratops', 'rcisaurus', 'ratops', 'rguraptor']\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 names from each model\n",
    "num_names = 10\n",
    "\n",
    "lstm_names = generate_multiple_names(model=lstm_model, vocab=vocab, reverse_vocab=reverse_vocab, num_names=num_names, max_length=max_word_length, sequence_length=sequence_length, top_k=5)\n",
    "lstm_dropout_names = generate_multiple_names(model=lstm_dropout, vocab=vocab, reverse_vocab=reverse_vocab, num_names=num_names, max_length=max_word_length, sequence_length=sequence_length,top_k=5)\n",
    "gru_names = generate_multiple_names(model=gru_model, vocab=vocab, reverse_vocab=reverse_vocab, num_names=num_names, max_length=max_word_length, sequence_length=sequence_length,top_k=5)\n",
    "\n",
    "# Print the generated names\n",
    "print(\"Generated LSTM Names:\", lstm_names)\n",
    "print(\"Generated LSTM with Dropout Names:\", lstm_dropout_names)\n",
    "print(\"Generated GRU Names:\", gru_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "ChatGPT : For giving advice, logs and commenting my code. <br>\n",
    "Copilot : Auto-completion. Sometime, it auto-completed functions. *Note* : Functions were then modified to adapt my context, my vision or my logic.<br> \n",
    "Medium : [Using RNN Model For Text Generation](https://medium.com/analytics-vidhya/using-rnn-model-for-text-generation-c5a37017d142)<br>\n",
    "Professor Riveilli courses<br>\n",
    "Medium : [Generation de texte par n-gram](https://beranger.medium.com/nlp-g%C3%A9n%C3%A9ration-de-texte-par-n-grams-3894187f6cd4). Not the code this time but the idea and path to implement the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino_name_generator-CGxwSDO1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
