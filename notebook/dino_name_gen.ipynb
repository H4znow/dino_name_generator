{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Generator for Dinosaurs\n",
    "\n",
    "### @Author : HADDOU Amine\n",
    "\n",
    "The goal of this project is to developp different neural network models to generates new dinosaur names.<br>\n",
    "The objective is to developp the following two models : \n",
    "- n-grams model language\n",
    "- a pre-trained model (from hugginface) finetuned to the project goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data from `data/dinos.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/dinos.txt\", names=[\"dino_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachenosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aardonyx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abdallahsaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abelisaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abrictosaurus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dino_name\n",
       "0   Aachenosaurus\n",
       "1        Aardonyx\n",
       "2  Abdallahsaurus\n",
       "3     Abelisaurus\n",
       "4   Abrictosaurus"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an overview of the imported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1536 entries, 0 to 1535\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   dino_name  1536 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 12.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring 20 random rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Dystylosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>Panphagia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Eucercosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>Xenoceratops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>Lufengosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>Nurosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>Tambatitanis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Camelotia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Oryctodromeus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Aurornis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Judiceratops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>Parksosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Acristavus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Jaklapallisaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Alnashetri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Crataeomus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>Stegosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Indosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Jianchangosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>Yamaceratops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dino_name\n",
       "430      Dystylosaurus\n",
       "1021         Panphagia\n",
       "481      Eucercosaurus\n",
       "1470      Xenoceratops\n",
       "807      Lufengosaurus\n",
       "950         Nurosaurus\n",
       "1318      Tambatitanis\n",
       "249          Camelotia\n",
       "980      Oryctodromeus\n",
       "151           Aurornis\n",
       "688       Judiceratops\n",
       "1029      Parksosaurus\n",
       "12          Acristavus\n",
       "668   Jaklapallisaurus\n",
       "56          Alnashetri\n",
       "336         Crataeomus\n",
       "1283       Stegosaurus\n",
       "653         Indosaurus\n",
       "675   Jianchangosaurus\n",
       "1487      Yamaceratops"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there punctuation (composed names, etc) ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No non-alphabetical characters found in the dataset\n"
     ]
    }
   ],
   "source": [
    "def print_non_alphabetical_chars(word):\n",
    "    non_alphabetical = [char for char in word if char.lower() not in \"abcdefghijklmnopqrstuvwxyz\"]\n",
    "    if non_alphabetical:\n",
    "        print(\"Non-alphabetical characters in '{}': {}\".format(word, ''.join(non_alphabetical)))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def print_non_alphabetical(data):\n",
    "    presence = False # flag to check if there are any non-alphabetical characters\n",
    "    for name in data[\"dino_name\"]:\n",
    "        if print_non_alphabetical_chars(name):\n",
    "            presence = True\n",
    "    if not presence:\n",
    "        print(\"No non-alphabetical characters found in the dataset\")\n",
    "\n",
    "print_non_alphabetical(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the data contains recurrent names ? If so, we should get rid of them later in the pre-processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in the dataset: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicates in the dataset: {}\".format(data.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore words length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average length of dino names\n",
    "avg_word_length = data[\"dino_name\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max length of dino names\n",
    "max_word_length = data[\"dino_name\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min length of dino names\n",
    "min_word_length = data[\"dino_name\"].str.len().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile of dino names\n",
    "quantile = data[\"dino_name\"].str.len().quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique dino names\n",
    "unique_dino_names = data[\"dino_name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 11.962239583333334\n",
      "Max word length: 26\n",
      "Min word length: 3\n",
      "Quantiles : {25% : 10.0, 50% : 12.0, 75% : 13.0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average word length: {avg_word_length}\")\n",
    "print(f\"Max word length: {max_word_length}\")\n",
    "print(f\"Min word length: {min_word_length}\")\n",
    "print(f\"Quantiles : {{25% : {quantile[0.25]}, 50% : {quantile[0.5]}, 75% : {quantile[0.75]}}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are interesting. Dinosaur names are, in average, very long. So, if I want to generate a name, model has to take in account enough context from previous letters to generate remaining part.\n",
    "\n",
    "My first idea for the __n_gram model__ is to select `n_gram=3`. Because, I want to catch syllables in name. In my opinion, last syllables is enough context. It corresponds to the last 3 words before the word we want to predict.<br>\n",
    "In this context, a *syllable* is defined as a sequence of three characters, usually at least the middle one is a vowel.<br>\n",
    "It seems that using trigrams (3-grams) is a good choice since many words have lengths that are multiples of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Case Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should start with lower case all letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aachenosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardonyx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dino_name\n",
       "0  aachenosaurus\n",
       "1       aardonyx"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"dino_name\"] = data[\"dino_name\"].str.lower()\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Recurrent values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to delete previous identified dublicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in dino names: 0\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset='dino_name')\n",
    "num_duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicates in dino names: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add padding at the end of worlds to regularize names' length. We will try the `n-gram` model without padding.<br>\n",
    "Maybe by adding a padding, the model will be able to learn __how__ dino names finish usally (\"aurus\", \"tor\", etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(names: list[str], max_length: int) -> list[str]:\n",
    "    padded_names = []\n",
    "    for name in names :\n",
    "        if len(name) < max_length:\n",
    "            padded_names.append(name + \"1\" * (max_length - len(name)))\n",
    "        else:\n",
    "            padded_names.append(name[:max_length])\n",
    "    return padded_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"paddded_dino_name\"] = add_padding(data[\"dino_name\"].values, max_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "      <th>paddded_dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aachenosaurus</td>\n",
       "      <td>aachenosaurus1111111111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardonyx</td>\n",
       "      <td>aardonyx111111111111111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dino_name           paddded_dino_name\n",
       "0  aachenosaurus  aachenosaurus1111111111111\n",
       "1       aardonyx  aardonyx111111111111111111"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start and End Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add `0` at the start and `1` at the end of names. The `0` will be usefull at the begenning of the generation to generate a first letter. For `k-gram`model, we will generate `k` `0` at the begenning to generate the first letter.\n",
    "\n",
    "For the `1`, it will help us determine when the generation is finished. And it may help the model in *learning* how dino names end (\"tor\", \"saurus\",etc).. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_end_tokens(names: list[str], n: int) -> list[str]:\n",
    "    \"\"\"Adds start '0' and end '1' tokens to each name.\"\"\"\n",
    "    return [\"0\" * n + name + \"1\" for name in names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a first function to generates a list of n-grams from a list of names at a **character** level.\n",
    "\n",
    "When building the vocabulary and tokens, we will add an `<UNK>` token that will be used for any unseen tokens or characters during generation. it is important because if the model produce a token which was not in the initial dataset, it won't be able to complete the generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_tokens(names: list[str], n: int) -> list[str]:\n",
    "    \"\"\"Generates and returns all unique n-grams from the names.\"\"\"\n",
    "    tokens = [\"<UNK>\"]  # Add the <UNK> token at the beginning\n",
    "    for name in names:\n",
    "        for i in range(len(name) - n + 1):\n",
    "            token = name[i:i+n]\n",
    "            if token not in tokens:\n",
    "                tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<UNK>', 'dino', 'inos', 'noso', 'osou', 'sour', 'ouru', 'urus']\n"
     ]
    }
   ],
   "source": [
    "print(list_all_tokens([\"dino\", \"dinosour\", \"dinosourus\"], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) N-gram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some usefull functions usefull for this model __only__. Each models needs his own tool functions. Some times the difference is only a line or a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dertermining tokens of language, it is also necessary to determine our vocabulary. In our case, it is all the characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(names: list[str]) -> list[str]:\n",
    "    \"\"\"Builds and returns a list of all unique characters (vocabulary) from the names.\"\"\"\n",
    "    vocab = [\"<UNK>\"]  # Add the <UNK> token at the beginning\n",
    "    for name in names:\n",
    "        for letter in name:\n",
    "            if letter not in vocab:\n",
    "                vocab.append(letter)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute probability of a letter appearing after a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_probabilities(probabilities: np.ndarray, tokens: list[str], vocab: list[str]) -> None:\n",
    "    \"\"\"Prints the probabilities of generating each letter for each token.\"\"\"\n",
    "    for i, token in enumerate(tokens):\n",
    "        print(f\"Token: {token}\")\n",
    "        for j, letter in enumerate(vocab):\n",
    "            prob = probabilities[i][j]\n",
    "            if prob > 0:\n",
    "                print(f\"    {letter}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilities(names: list[str], tokens: list[str], vocab: list[str], n: int) -> np.ndarray:\n",
    "    \"\"\"Computes the conditional probabilities of each token generating a letter from the vocabulary.\"\"\"\n",
    "    probabilities_array = np.zeros((len(tokens), len(vocab)))\n",
    "\n",
    "    # Count occurrences of letters following each token\n",
    "    for name in names:\n",
    "        for i in range(len(name) - n):\n",
    "            token = name[i:i+n]\n",
    "            next_letter = name[i+n]  # The letter after the token\n",
    "            if next_letter in vocab:\n",
    "                token_index = tokens.index(token) if token in tokens else tokens.index(\"<UNK>\")\n",
    "                letter_index = vocab.index(next_letter)\n",
    "                probabilities_array[token_index][letter_index] += 1\n",
    "            else:\n",
    "                print(f\"Letter {next_letter} not in vocabulary\")\n",
    "                probabilities_array[tokens.index(\"<UNK>\")][vocab.index(\"<UNK>\")] += 1\n",
    "\n",
    "    # Normalize the probabilities by dividing by row sums\n",
    "    row_sums = probabilities_array.sum(axis=1, keepdims=True)\n",
    "    probabilities_array = np.divide(probabilities_array, row_sums, where=row_sums != 0, out=probabilities_array)\n",
    "\n",
    "    # print_probabilities(probabilities_array, tokens, vocab)\n",
    "    \n",
    "    return probabilities_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add some randomness and not generating alwas the same name, we will not retrieve the most predicted letter but one of the first k letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_top_k_letters(probabilities: np.array, token_index: int, vocab: list[str], k: int = 5, verbose: bool = False) -> str:\n",
    "    \"\"\"Chooses one of the top k letters based on probabilities. Only selects letters with probability > 0.\"\"\"\n",
    "    \n",
    "    # Sort the probabilities and get indices sorted by highest probability\n",
    "    sorted_indices = np.argsort(probabilities[token_index])[::-1]  # Sort descending\n",
    "    \n",
    "    # Filter out indices where the probability is > 0\n",
    "    valid_indices = [idx for idx in sorted_indices if probabilities[token_index][idx] > 0]\n",
    "\n",
    "    # Adjust k if there are fewer than k valid options\n",
    "    k = min(k, len(valid_indices))\n",
    "    \n",
    "    if k == 0:\n",
    "        # Handle the case where no valid options with prob > 0 exist, fallback to <UNK> or any default behavior\n",
    "        if verbose:\n",
    "            print(\"No valid letters with probability > 0. Falling back to <UNK>.\")\n",
    "        return \"<UNK>\"  # or any other fallback behavior you'd like\n",
    "\n",
    "    # Select the top k valid indices\n",
    "    best_k_indices = valid_indices[:k]\n",
    "    \n",
    "    # Log top k predicted letters\n",
    "    if verbose:\n",
    "        print(f\"\\nTop {k} predicted letters for token index {token_index}:\")\n",
    "        for idx in best_k_indices:\n",
    "            print(f\"Letter: {vocab[idx]}, Probability: {probabilities[token_index][idx]}\")\n",
    "\n",
    "    # Choose one of the top k at random (or return the best if k=1)\n",
    "    if k > 1:\n",
    "        chosen_index = np.random.choice(best_k_indices)\n",
    "    else:\n",
    "        chosen_index = best_k_indices[-1]\n",
    "    \n",
    "    chosen_letter = vocab[chosen_index]\n",
    "    if verbose:\n",
    "        print(f\"Chosen letter: {chosen_letter}\")\n",
    "    \n",
    "    return chosen_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have all the tools to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_predict_new_name(tokens: list[str], vocab: list[str], probabilities: np.array, n: int, max_inter_count : int = 10, k: int = 5, verbose: bool = False) -> str:\n",
    "    \"\"\"Generates a new name using the n-gram model with <UNK> token handling.\"\"\"\n",
    "    generated_name = \"\"  # Start with an empty string\n",
    "    token = \"0\" * n  # Initial token is the start token\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nStarting name generation:\")\n",
    "    \n",
    "    inter_count = 0\n",
    "    while inter_count < max_inter_count:\n",
    "        # Handle unknown token by using <UNK> token\n",
    "        token_index = tokens.index(token) if token in tokens else tokens.index(\"<UNK>\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nCurrent token: {token}\")\n",
    "            print(f\"Name under construction: {generated_name}\")\n",
    "        \n",
    "        if token == \"0\" * n:  # Start token: choose any letter\n",
    "            next_letter = choose_top_k_letters(probabilities, token_index, vocab, k=len(vocab)-1, verbose=verbose)\n",
    "        else:\n",
    "            # Find the next letter using one of the top k probabilities\n",
    "            next_letter = choose_top_k_letters(probabilities, token_index, vocab, k=k, verbose=verbose)\n",
    "        \n",
    "        if next_letter == \"1\":  # End of name (using '1')\n",
    "            if verbose:\n",
    "                print(f\"End of name reached with letter: 1\\n\")\n",
    "            break\n",
    "        \n",
    "        generated_name += next_letter\n",
    "        token = (token + next_letter)[-n:]  # Shift the token by one letter, keeping it at length n\n",
    "        inter_count += 1\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Final generated name: {generated_name}\\n\")\n",
    "    return generated_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_model(names: list[str], n: int = 4, num_predictions: int = 5, max_length_output : int = 10, k: int = 5, verbose: bool = False) -> list[str]:\n",
    "    \"\"\"Trains an n-gram model and generates new names.\"\"\"\n",
    "    # Add start/end tokens to names and build model components\n",
    "    n = n - 1 # n-gram model uses n-1 letters to predict the new one. So I'll adjust n here. \n",
    "    names = add_start_end_tokens(names, n)\n",
    "    tokens = list_all_tokens(names, n)\n",
    "    vocab = build_vocabulary(names)\n",
    "    probabilities = compute_probabilities(names, tokens, vocab, n)\n",
    "    \n",
    "    # Generate new names based on the model\n",
    "    generated_names = []\n",
    "    for _ in range(num_predictions):\n",
    "        name = ngram_predict_new_name(tokens, vocab, probabilities, n, max_inter_count=max_length_output, k=k, verbose=verbose)\n",
    "        generated_names.append(name)\n",
    "    \n",
    "    return generated_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Names with n-gramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 0\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.1089238845144357\n",
      "Letter: s, Probability: 0.09448818897637795\n",
      "Letter: p, Probability: 0.07939632545931759\n",
      "Letter: c, Probability: 0.07086614173228346\n",
      "Letter: t, Probability: 0.06430446194225722\n",
      "Letter: m, Probability: 0.05971128608923885\n",
      "Letter: l, Probability: 0.05380577427821522\n",
      "Letter: d, Probability: 0.0531496062992126\n",
      "Letter: b, Probability: 0.04921259842519685\n",
      "Letter: e, Probability: 0.04265091863517061\n",
      "Letter: h, Probability: 0.04199475065616798\n",
      "Letter: g, Probability: 0.03937007874015748\n",
      "Letter: n, Probability: 0.031496062992125984\n",
      "Letter: o, Probability: 0.02690288713910761\n",
      "Letter: r, Probability: 0.026246719160104987\n",
      "Letter: k, Probability: 0.025590551181102362\n",
      "Letter: j, Probability: 0.01706036745406824\n",
      "Letter: z, Probability: 0.01706036745406824\n",
      "Letter: i, Probability: 0.015748031496062992\n",
      "Letter: y, Probability: 0.015748031496062992\n",
      "Letter: f, Probability: 0.013779527559055118\n",
      "Letter: v, Probability: 0.013123359580052493\n",
      "Letter: w, Probability: 0.01115485564304462\n",
      "Letter: u, Probability: 0.01115485564304462\n",
      "Letter: x, Probability: 0.010498687664041995\n",
      "Letter: q, Probability: 0.006561679790026247\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: i\n",
      "Name under construction: i\n",
      "\n",
      "Top 3 predicted letters for token index 17:\n",
      "Letter: a, Probability: 0.18809776833156217\n",
      "Letter: n, Probability: 0.14558979808714134\n",
      "Letter: s, Probability: 0.1434643995749203\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: a\n",
      "Name under construction: ia\n",
      "\n",
      "Top 3 predicted letters for token index 2:\n",
      "Letter: u, Probability: 0.3172609400324149\n",
      "Letter: n, Probability: 0.1393841166936791\n",
      "Letter: t, Probability: 0.08265802269043761\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: n\n",
      "Name under construction: ian\n",
      "\n",
      "Top 3 predicted letters for token index 6:\n",
      "Letter: o, Probability: 0.17488372093023255\n",
      "Letter: g, Probability: 0.1469767441860465\n",
      "Letter: 1, Probability: 0.11348837209302326\n",
      "Chosen letter: 1\n",
      "End of name reached with letter: 1\n",
      "\n",
      "Final generated name: ian\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 0\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.1089238845144357\n",
      "Letter: s, Probability: 0.09448818897637795\n",
      "Letter: p, Probability: 0.07939632545931759\n",
      "Letter: c, Probability: 0.07086614173228346\n",
      "Letter: t, Probability: 0.06430446194225722\n",
      "Letter: m, Probability: 0.05971128608923885\n",
      "Letter: l, Probability: 0.05380577427821522\n",
      "Letter: d, Probability: 0.0531496062992126\n",
      "Letter: b, Probability: 0.04921259842519685\n",
      "Letter: e, Probability: 0.04265091863517061\n",
      "Letter: h, Probability: 0.04199475065616798\n",
      "Letter: g, Probability: 0.03937007874015748\n",
      "Letter: n, Probability: 0.031496062992125984\n",
      "Letter: o, Probability: 0.02690288713910761\n",
      "Letter: r, Probability: 0.026246719160104987\n",
      "Letter: k, Probability: 0.025590551181102362\n",
      "Letter: j, Probability: 0.01706036745406824\n",
      "Letter: z, Probability: 0.01706036745406824\n",
      "Letter: i, Probability: 0.015748031496062992\n",
      "Letter: y, Probability: 0.015748031496062992\n",
      "Letter: f, Probability: 0.013779527559055118\n",
      "Letter: v, Probability: 0.013123359580052493\n",
      "Letter: w, Probability: 0.01115485564304462\n",
      "Letter: u, Probability: 0.01115485564304462\n",
      "Letter: x, Probability: 0.010498687664041995\n",
      "Letter: q, Probability: 0.006561679790026247\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: s\n",
      "Name under construction: s\n",
      "\n",
      "Top 3 predicted letters for token index 8:\n",
      "Letter: 1, Probability: 0.4706401766004415\n",
      "Letter: a, Probability: 0.34613686534216337\n",
      "Letter: t, Probability: 0.037527593818984545\n",
      "Chosen letter: 1\n",
      "End of name reached with letter: 1\n",
      "\n",
      "Final generated name: s\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 0\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.1089238845144357\n",
      "Letter: s, Probability: 0.09448818897637795\n",
      "Letter: p, Probability: 0.07939632545931759\n",
      "Letter: c, Probability: 0.07086614173228346\n",
      "Letter: t, Probability: 0.06430446194225722\n",
      "Letter: m, Probability: 0.05971128608923885\n",
      "Letter: l, Probability: 0.05380577427821522\n",
      "Letter: d, Probability: 0.0531496062992126\n",
      "Letter: b, Probability: 0.04921259842519685\n",
      "Letter: e, Probability: 0.04265091863517061\n",
      "Letter: h, Probability: 0.04199475065616798\n",
      "Letter: g, Probability: 0.03937007874015748\n",
      "Letter: n, Probability: 0.031496062992125984\n",
      "Letter: o, Probability: 0.02690288713910761\n",
      "Letter: r, Probability: 0.026246719160104987\n",
      "Letter: k, Probability: 0.025590551181102362\n",
      "Letter: j, Probability: 0.01706036745406824\n",
      "Letter: z, Probability: 0.01706036745406824\n",
      "Letter: i, Probability: 0.015748031496062992\n",
      "Letter: y, Probability: 0.015748031496062992\n",
      "Letter: f, Probability: 0.013779527559055118\n",
      "Letter: v, Probability: 0.013123359580052493\n",
      "Letter: w, Probability: 0.01115485564304462\n",
      "Letter: u, Probability: 0.01115485564304462\n",
      "Letter: x, Probability: 0.010498687664041995\n",
      "Letter: q, Probability: 0.006561679790026247\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: a\n",
      "Name under construction: a\n",
      "\n",
      "Top 3 predicted letters for token index 2:\n",
      "Letter: u, Probability: 0.3172609400324149\n",
      "Letter: n, Probability: 0.1393841166936791\n",
      "Letter: t, Probability: 0.08265802269043761\n",
      "Chosen letter: t\n",
      "\n",
      "Current token: t\n",
      "Name under construction: at\n",
      "\n",
      "Top 3 predicted letters for token index 18:\n",
      "Letter: o, Probability: 0.3447867298578199\n",
      "Letter: a, Probability: 0.18601895734597157\n",
      "Letter: e, Probability: 0.12677725118483413\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: a\n",
      "Name under construction: ata\n",
      "\n",
      "Top 3 predicted letters for token index 2:\n",
      "Letter: u, Probability: 0.3172609400324149\n",
      "Letter: n, Probability: 0.1393841166936791\n",
      "Letter: t, Probability: 0.08265802269043761\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: n\n",
      "Name under construction: atan\n",
      "\n",
      "Top 3 predicted letters for token index 6:\n",
      "Letter: o, Probability: 0.17488372093023255\n",
      "Letter: g, Probability: 0.1469767441860465\n",
      "Letter: 1, Probability: 0.11348837209302326\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: o\n",
      "Name under construction: atano\n",
      "\n",
      "Top 3 predicted letters for token index 7:\n",
      "Letter: s, Probability: 0.30260047281323876\n",
      "Letter: n, Probability: 0.15780141843971632\n",
      "Letter: r, Probability: 0.12174940898345153\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: n\n",
      "Name under construction: atanon\n",
      "\n",
      "Top 3 predicted letters for token index 6:\n",
      "Letter: o, Probability: 0.17488372093023255\n",
      "Letter: g, Probability: 0.1469767441860465\n",
      "Letter: 1, Probability: 0.11348837209302326\n",
      "Chosen letter: 1\n",
      "End of name reached with letter: 1\n",
      "\n",
      "Final generated name: atanon\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 0\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.1089238845144357\n",
      "Letter: s, Probability: 0.09448818897637795\n",
      "Letter: p, Probability: 0.07939632545931759\n",
      "Letter: c, Probability: 0.07086614173228346\n",
      "Letter: t, Probability: 0.06430446194225722\n",
      "Letter: m, Probability: 0.05971128608923885\n",
      "Letter: l, Probability: 0.05380577427821522\n",
      "Letter: d, Probability: 0.0531496062992126\n",
      "Letter: b, Probability: 0.04921259842519685\n",
      "Letter: e, Probability: 0.04265091863517061\n",
      "Letter: h, Probability: 0.04199475065616798\n",
      "Letter: g, Probability: 0.03937007874015748\n",
      "Letter: n, Probability: 0.031496062992125984\n",
      "Letter: o, Probability: 0.02690288713910761\n",
      "Letter: r, Probability: 0.026246719160104987\n",
      "Letter: k, Probability: 0.025590551181102362\n",
      "Letter: j, Probability: 0.01706036745406824\n",
      "Letter: z, Probability: 0.01706036745406824\n",
      "Letter: i, Probability: 0.015748031496062992\n",
      "Letter: y, Probability: 0.015748031496062992\n",
      "Letter: f, Probability: 0.013779527559055118\n",
      "Letter: v, Probability: 0.013123359580052493\n",
      "Letter: w, Probability: 0.01115485564304462\n",
      "Letter: u, Probability: 0.01115485564304462\n",
      "Letter: x, Probability: 0.010498687664041995\n",
      "Letter: q, Probability: 0.006561679790026247\n",
      "Chosen letter: z\n",
      "\n",
      "Current token: z\n",
      "Name under construction: z\n",
      "\n",
      "Top 3 predicted letters for token index 27:\n",
      "Letter: h, Probability: 0.3333333333333333\n",
      "Letter: a, Probability: 0.2\n",
      "Letter: u, Probability: 0.11666666666666667\n",
      "Chosen letter: u\n",
      "\n",
      "Current token: u\n",
      "Name under construction: zu\n",
      "\n",
      "Top 3 predicted letters for token index 9:\n",
      "Letter: s, Probability: 0.465083135391924\n",
      "Letter: r, Probability: 0.38764845605700715\n",
      "Letter: a, Probability: 0.023752969121140142\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: r\n",
      "Name under construction: zur\n",
      "\n",
      "Top 3 predicted letters for token index 10:\n",
      "Letter: u, Probability: 0.4457617071724956\n",
      "Letter: a, Probability: 0.15826911677534083\n",
      "Letter: o, Probability: 0.13218731475992887\n",
      "Chosen letter: u\n",
      "\n",
      "Current token: u\n",
      "Name under construction: zuru\n",
      "\n",
      "Top 3 predicted letters for token index 9:\n",
      "Letter: s, Probability: 0.465083135391924\n",
      "Letter: r, Probability: 0.38764845605700715\n",
      "Letter: a, Probability: 0.023752969121140142\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: r\n",
      "Name under construction: zurur\n",
      "\n",
      "Top 3 predicted letters for token index 10:\n",
      "Letter: u, Probability: 0.4457617071724956\n",
      "Letter: a, Probability: 0.15826911677534083\n",
      "Letter: o, Probability: 0.13218731475992887\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: a\n",
      "Name under construction: zurura\n",
      "\n",
      "Top 3 predicted letters for token index 2:\n",
      "Letter: u, Probability: 0.3172609400324149\n",
      "Letter: n, Probability: 0.1393841166936791\n",
      "Letter: t, Probability: 0.08265802269043761\n",
      "Chosen letter: t\n",
      "\n",
      "Current token: t\n",
      "Name under construction: zururat\n",
      "\n",
      "Top 3 predicted letters for token index 18:\n",
      "Letter: o, Probability: 0.3447867298578199\n",
      "Letter: a, Probability: 0.18601895734597157\n",
      "Letter: e, Probability: 0.12677725118483413\n",
      "Chosen letter: e\n",
      "\n",
      "Current token: e\n",
      "Name under construction: zururate\n",
      "\n",
      "Top 3 predicted letters for token index 5:\n",
      "Letter: r, Probability: 0.19889502762430938\n",
      "Letter: n, Probability: 0.15248618784530388\n",
      "Letter: l, Probability: 0.12044198895027625\n",
      "Chosen letter: l\n",
      "\n",
      "Current token: l\n",
      "Name under construction: zururatel\n",
      "\n",
      "Top 3 predicted letters for token index 16:\n",
      "Letter: o, Probability: 0.2791461412151067\n",
      "Letter: a, Probability: 0.15599343185550082\n",
      "Letter: i, Probability: 0.13793103448275862\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: a\n",
      "Name under construction: zururatela\n",
      "\n",
      "Top 3 predicted letters for token index 2:\n",
      "Letter: u, Probability: 0.3172609400324149\n",
      "Letter: n, Probability: 0.1393841166936791\n",
      "Letter: t, Probability: 0.08265802269043761\n",
      "Chosen letter: t\n",
      "\n",
      "Current token: t\n",
      "Name under construction: zururatelat\n",
      "\n",
      "Top 3 predicted letters for token index 18:\n",
      "Letter: o, Probability: 0.3447867298578199\n",
      "Letter: a, Probability: 0.18601895734597157\n",
      "Letter: e, Probability: 0.12677725118483413\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: o\n",
      "Name under construction: zururatelato\n",
      "\n",
      "Top 3 predicted letters for token index 7:\n",
      "Letter: s, Probability: 0.30260047281323876\n",
      "Letter: n, Probability: 0.15780141843971632\n",
      "Letter: r, Probability: 0.12174940898345153\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: n\n",
      "Name under construction: zururatelaton\n",
      "\n",
      "Top 3 predicted letters for token index 6:\n",
      "Letter: o, Probability: 0.17488372093023255\n",
      "Letter: g, Probability: 0.1469767441860465\n",
      "Letter: 1, Probability: 0.11348837209302326\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: o\n",
      "Name under construction: zururatelatono\n",
      "\n",
      "Top 3 predicted letters for token index 7:\n",
      "Letter: s, Probability: 0.30260047281323876\n",
      "Letter: n, Probability: 0.15780141843971632\n",
      "Letter: r, Probability: 0.12174940898345153\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: s\n",
      "Name under construction: zururatelatonos\n",
      "\n",
      "Top 3 predicted letters for token index 8:\n",
      "Letter: 1, Probability: 0.4706401766004415\n",
      "Letter: a, Probability: 0.34613686534216337\n",
      "Letter: t, Probability: 0.037527593818984545\n",
      "Chosen letter: 1\n",
      "End of name reached with letter: 1\n",
      "\n",
      "Final generated name: zururatelatonos\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 0\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.1089238845144357\n",
      "Letter: s, Probability: 0.09448818897637795\n",
      "Letter: p, Probability: 0.07939632545931759\n",
      "Letter: c, Probability: 0.07086614173228346\n",
      "Letter: t, Probability: 0.06430446194225722\n",
      "Letter: m, Probability: 0.05971128608923885\n",
      "Letter: l, Probability: 0.05380577427821522\n",
      "Letter: d, Probability: 0.0531496062992126\n",
      "Letter: b, Probability: 0.04921259842519685\n",
      "Letter: e, Probability: 0.04265091863517061\n",
      "Letter: h, Probability: 0.04199475065616798\n",
      "Letter: g, Probability: 0.03937007874015748\n",
      "Letter: n, Probability: 0.031496062992125984\n",
      "Letter: o, Probability: 0.02690288713910761\n",
      "Letter: r, Probability: 0.026246719160104987\n",
      "Letter: k, Probability: 0.025590551181102362\n",
      "Letter: j, Probability: 0.01706036745406824\n",
      "Letter: z, Probability: 0.01706036745406824\n",
      "Letter: i, Probability: 0.015748031496062992\n",
      "Letter: y, Probability: 0.015748031496062992\n",
      "Letter: f, Probability: 0.013779527559055118\n",
      "Letter: v, Probability: 0.013123359580052493\n",
      "Letter: w, Probability: 0.01115485564304462\n",
      "Letter: u, Probability: 0.01115485564304462\n",
      "Letter: x, Probability: 0.010498687664041995\n",
      "Letter: q, Probability: 0.006561679790026247\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: o\n",
      "Name under construction: o\n",
      "\n",
      "Top 3 predicted letters for token index 7:\n",
      "Letter: s, Probability: 0.30260047281323876\n",
      "Letter: n, Probability: 0.15780141843971632\n",
      "Letter: r, Probability: 0.12174940898345153\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: r\n",
      "Name under construction: or\n",
      "\n",
      "Top 3 predicted letters for token index 10:\n",
      "Letter: u, Probability: 0.4457617071724956\n",
      "Letter: a, Probability: 0.15826911677534083\n",
      "Letter: o, Probability: 0.13218731475992887\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: a\n",
      "Name under construction: ora\n",
      "\n",
      "Top 3 predicted letters for token index 2:\n",
      "Letter: u, Probability: 0.3172609400324149\n",
      "Letter: n, Probability: 0.1393841166936791\n",
      "Letter: t, Probability: 0.08265802269043761\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: n\n",
      "Name under construction: oran\n",
      "\n",
      "Top 3 predicted letters for token index 6:\n",
      "Letter: o, Probability: 0.17488372093023255\n",
      "Letter: g, Probability: 0.1469767441860465\n",
      "Letter: 1, Probability: 0.11348837209302326\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: o\n",
      "Name under construction: orano\n",
      "\n",
      "Top 3 predicted letters for token index 7:\n",
      "Letter: s, Probability: 0.30260047281323876\n",
      "Letter: n, Probability: 0.15780141843971632\n",
      "Letter: r, Probability: 0.12174940898345153\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: s\n",
      "Name under construction: oranos\n",
      "\n",
      "Top 3 predicted letters for token index 8:\n",
      "Letter: 1, Probability: 0.4706401766004415\n",
      "Letter: a, Probability: 0.34613686534216337\n",
      "Letter: t, Probability: 0.037527593818984545\n",
      "Chosen letter: 1\n",
      "End of name reached with letter: 1\n",
      "\n",
      "Final generated name: oranos\n",
      "\n",
      "['ian', 's', 'atanon', 'zururatelatonos', 'oranos']\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 names with n=4, top 5 letters considered, and verbose logging enabled\n",
    "names = data[\"dino_name\"].values\n",
    "generated_names = ngram_model(names, n=2, max_length_output=max_word_length, num_predictions=5, k=3, verbose=True)\n",
    "\n",
    "print(generated_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rathusausaus', 'lanosuchinodrosucanodrathu', 'zhuale', 'yingon', 'xing']\n"
     ]
    }
   ],
   "source": [
    "names = data[\"dino_name\"].values\n",
    "generated_names = ngram_model(names, n=3, max_length_output=max_word_length, num_predictions=5, k=2, verbose=False)\n",
    "\n",
    "print(generated_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crang', 'mostelusanserotydolodzigar', 'ventos', 'ilodzistreocoekufengovecol', 'qansariocelinaxa']\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 names with n=4, top 5 letters considered, and verbose logging enabled\n",
    "names = data[\"dino_name\"].values\n",
    "generated_names = ngram_model(names, n=3, max_length_output=max_word_length, num_predictions=5, k=5, verbose=False)\n",
    "\n",
    "print(generated_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qinlonius', 'monosasparapelosauros', 'gong', 'barrhinuropeltongosaspleur', 'unenlagongongosucciniosucc']\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 names with n=4, top 5 letters considered, and verbose logging enabled\n",
    "names = data[\"dino_name\"].values\n",
    "generated_names = ngram_model(names, n=4, max_length_output=max_word_length, num_predictions=5, k=2, verbose=False)\n",
    "\n",
    "print(generated_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jingosuchunosuccinchunsaur', 'nomimucrocolamosphanoptery', 'hallasazisangsaurolopterot', 'zhongolosponodosaichthos', 'zhuchopsilonis']\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 names with n=4, top 5 letters considered, and verbose logging enabled\n",
    "names = data[\"dino_name\"].values\n",
    "generated_names = ngram_model(names, n=4, max_length_output=max_word_length, num_predictions=5, k=4, verbose=False)\n",
    "\n",
    "print(generated_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elrhazosauropteryx', 'nemegtomaia', 'marmarospondylosoma', 'sinraptorsaurushypacrosaur', 'wiehenvenatrix']\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 names with n=4, top 5 letters considered, and verbose logging enabled\n",
    "names = data[\"dino_name\"].values\n",
    "generated_names = ngram_model(names, n=6, max_length_output=max_word_length, num_predictions=5, k=3, verbose=False)\n",
    "\n",
    "print(generated_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of my generator with different parameters' values : \n",
    "-  `n = 3` and `k = 2`<br>\n",
    "['neoversosuccingshadros', 'bator', 'quilmayisaurutichodosuccin', 'dasylossus', 'inosphagros']\n",
    "-  `n = 3` and `k = 3`<br>\n",
    "['yungonius', 'elaplossuesiohadromaia', 'venescelusothostospinax', 'xingsauros', 'euskelyx']\n",
    "-  `n = 2` and `k = 3`<br>\n",
    "['heisaudasilis', 'kan', 'ale', 'xiasaustesaudiangobistrops', 'raptastriong']\n",
    "- `n = 4` and `k=3`<br>\n",
    "['unicerosaurophale', 'yurgovuchia', 'ischyrophus', 'ovirapterovenatosaurus', 'magnapartenykus']\n",
    "- `n = 4` and `k=5`<br>\n",
    "['cristatus', 'vouivria', 'yongjianosaurutitanius', 'mojoceratusauravusaurornit', 'epachthosuchomimoides']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like with a 4-gram model, we generate name that looks like real dino names. Even with a high randomness (k=5), results are still good.\n",
    "\n",
    "Even with the 3-gram model, the results are good (with low randomness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **n-gram model** is a type of probabilistic model used for generating sequences (in this case, names) by predicting the next element in a sequence based on the previous **n-1** elements. The model learns the probability distribution of letters following specific **n-grams** (substrings of length `n`) from a training dataset.\n",
    "\n",
    "This implementation generates new names one letter at a time using the learned probability distribution from the training data. The generated name is built step by step by predicting the next letter based on the preceding **n-1** letters.\n",
    "\n",
    "---\n",
    "\n",
    "### How the Model Works:\n",
    "1. **Training Phase**:\n",
    "   - The model processes the list of names to build the vocabulary and n-gram tokens.\n",
    "   - It calculates the probability of each letter occurring after each token based on the training data.\n",
    "   \n",
    "2. **Generation Phase**:\n",
    "   - The model generates new names by starting with a special start token (e.g., `\"000\"` for `n=4`).\n",
    "   - For each step, it uses the previous n-1 letters to predict the next letter.\n",
    "   - The next letter is chosen based on the learned probabilities, and the process continues until an end token (`\"1\"`) is generated or the name reaches the maximum length (`max_length_output`).\n",
    "\n",
    "---\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "```python\n",
    "# Example test data (dinosaur names)\n",
    "dino_names = [\"Tyrannosaurus\", \"Stegosaurus\", \"Triceratops\"]\n",
    "\n",
    "# Generate 5 names with n=4, maximum name length of 10, and top 3 letters considered\n",
    "generated_names = ngram_model(dino_names, n=4, num_predictions=5, max_length_output=10, k=3, verbose=True)\n",
    "\n",
    "print(generated_names)\n",
    "```\n",
    "\n",
    "This example generates 5 names with a trigram model, considers the top 3 letters at each step, and limits the names to 10 characters max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) LSTM model - Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM It is a type of RNN model usuall used for sequence prediction tasks. It is capable of learning long-term dependencies in data. This is the reason why it is used for text generation tasks.\n",
    "\n",
    "I'll try to implement the model in a way that the prediction take in account the position of the futur predicted letter __with__ it context. I'll come back on this point later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did before, we have to firstly define the vocabulary of our language again. It will be different as before because I decided here to define each char as an element of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary_classique_LSTM(names : list[str]) :\n",
    "    chars = sorted(list(set(''.join(names))))\n",
    "    vocab = list(dict.fromkeys(chars)) # make sure there are no duplicates\n",
    "    char_to_index = {char: idx for idx, char in enumerate(vocab)}\n",
    "    index_to_char = {idx: char for idx, char in enumerate(vocab)}\n",
    "    vocab_size = len(vocab)\n",
    "    return vocab, char_to_index, index_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_to_seq(seq: list[int], max_length: int) -> list[int]:\n",
    "    return [0] * (max_length - len(seq)) + seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this definition, we may encode the data. Otherwise, the model won't be able to learn from dino names.\n",
    "\n",
    "And as we can see in the following code, `seq_in` is a sequence that grow with one letter from `name` at each iteration of `i`. When `seq_in`is too small, a padding of `0`is added at the beginning of the word. `0` is here the starter marker. So, this may help the model to take in account the position of the word indirectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(names: list[str], char_to_index: dict, sequence_length: int = 15) -> tuple[np.array, np.array]: \n",
    "    data_X, data_y = [], []\n",
    "    for name in names:\n",
    "        encoded_name = [char_to_index[char] for char in name]\n",
    "        for i in range(1, len(encoded_name)):\n",
    "            seq_in = encoded_name[:i]\n",
    "            seq_out = encoded_name[i]\n",
    "            seq_in = pad_sequences([seq_in], maxlen=sequence_length, padding='pre')[0]\n",
    "            data_X.append(seq_in)\n",
    "            data_y.append(seq_out)\n",
    "    return np.array(data_X), np.array(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that use previous functions to make last adjustement on dino names (last processing) and then returnin training data, vocabulary and other important informations for the generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data: pd.DataFrame, max_length: int) -> tuple[np.array, np.array, list[str], dict, dict, int]:\n",
    "    names = data[\"dino_name\"].values\n",
    "    names = add_start_end_tokens(names, 1)\n",
    "    vocab, char_to_index, index_to_char, vocab_size = build_vocabulary_classique_LSTM(names)\n",
    "    names = add_padding(names, max_length=max_word_length)\n",
    "    data_X, data_y = encoding(names, char_to_index, sequence_length=max_word_length)\n",
    "    return data_X, data_y, vocab, char_to_index, index_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we are using to generate dinosaur names is based on an LSTM neural network. Here is the configuration of the layers:\n",
    "\n",
    "- **Input Layer**: Accepts input sequences of length `sequence_length`.\n",
    "- **Embedding Layer**: Converts each character (represented by an integer index) into an 13-dimensional vector, helping the model learn relationships between characters. The embedding has `input_dim=vocab_size`, `output_dim=13`, and `input_length=sequence_length`.\n",
    "- **LSTM Layer**: Contains 128 units, allowing the model to learn the temporal dependencies between characters in the sequence, crucial for generating plausible names.\n",
    "- **Dense Layer**: Outputs a probability distribution over the `vocab_size` possible characters using the `softmax` activation function. This allows the model to predict the next character in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_model(vocab_size: int, sequence_length: int, embedding_size: int = 13, hidden_units: int = 128, show_summary: bool = False) -> Model:\n",
    "    inputs = Input(shape=(sequence_length,))\n",
    "    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_size)(inputs)\n",
    "    lstm = LSTM(hidden_units)(embedding)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(lstm)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to train. It will be used later for other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model: Model, data_X: np.array, data_y: np.array, epochs: int = 100, batch_size: int = 32) -> Model:\n",
    "    # Train the model\n",
    "    mycallback = EarlyStopping(monitor='loss', patience=5)\n",
    "    model.fit(data_X, data_y, epochs=epochs, batch_size=batch_size, callbacks=[mycallback])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "firstly, let's excute the preporcess on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X, data_y, vocab, char_to_index, index_to_char, vocab_size = prepare_training_data(data, max_word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model initiallisation and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 1.5065\n",
      "Epoch 2/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - loss: 1.0493\n",
      "Epoch 3/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - loss: 0.9786\n",
      "Epoch 4/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - loss: 0.9283\n",
      "Epoch 5/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.8851\n",
      "Epoch 6/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.8532\n",
      "Epoch 7/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.8238\n",
      "Epoch 8/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 0.7845\n",
      "Epoch 9/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.7703\n",
      "Epoch 10/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.7491\n",
      "Epoch 11/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.7219\n",
      "Epoch 12/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.7133\n",
      "Epoch 13/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.6822\n",
      "Epoch 14/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.6558\n",
      "Epoch 15/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.6434\n",
      "Epoch 16/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.6234\n",
      "Epoch 17/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.5889\n",
      "Epoch 18/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - loss: 0.5788\n",
      "Epoch 19/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.5542\n",
      "Epoch 20/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.5422\n",
      "Epoch 21/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.5274\n",
      "Epoch 22/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.5077\n",
      "Epoch 23/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.4933\n",
      "Epoch 24/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.4922\n",
      "Epoch 25/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.4706\n",
      "Epoch 26/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.4499\n",
      "Epoch 27/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.4494\n",
      "Epoch 28/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.4406\n",
      "Epoch 29/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.4286\n",
      "Epoch 30/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.4267\n",
      "Epoch 31/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.4186\n",
      "Epoch 32/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.4150\n",
      "Epoch 33/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.4083\n",
      "Epoch 34/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.3942\n",
      "Epoch 35/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3949\n",
      "Epoch 36/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3858\n",
      "Epoch 37/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3792\n",
      "Epoch 38/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.3845\n",
      "Epoch 39/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.3791\n",
      "Epoch 40/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.3740\n",
      "Epoch 41/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3695\n",
      "Epoch 42/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3627\n",
      "Epoch 43/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.3677\n",
      "Epoch 44/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.3656\n",
      "Epoch 45/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3683\n",
      "Epoch 46/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3591\n",
      "Epoch 47/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3574\n",
      "Epoch 48/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3615\n",
      "Epoch 49/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3470\n",
      "Epoch 50/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3553\n",
      "Epoch 51/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3520\n",
      "Epoch 52/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.3469\n",
      "Epoch 53/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - loss: 0.3423\n",
      "Epoch 54/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - loss: 0.3513\n",
      "Epoch 55/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 22ms/step - loss: 0.3452\n",
      "Epoch 56/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 20ms/step - loss: 0.3416\n",
      "Epoch 57/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - loss: 0.3422\n",
      "Epoch 58/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - loss: 0.3492\n",
      "Epoch 59/100\n",
      "\u001b[1m 405/1191\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - loss: 0.3431"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m create_LSTM_model(vocab_size, max_word_length)\n\u001b[1;32m----> 2\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 4\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, data_X, data_y, epochs, batch_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining\u001b[39m(model: Model, data_X: np\u001b[38;5;241m.\u001b[39marray, data_y: np\u001b[38;5;241m.\u001b[39marray, epochs: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, batch_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Model:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     mycallback \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmycallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_model = create_LSTM_model(vocab_size, max_word_length)\n",
    "lstm_model = training(lstm_model, data_X, data_y, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a trained LSTM. We can implement new functions to generates the new dino names with the LSTM generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate a new name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the goal of the following function is to introduce some kind of randomness in the generator. Not alway predicting the most probable letter but one the k-most probable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_top_k_letters_from_model(predictions: np.array, k: int = 5) -> int:\n",
    "    \"\"\"Chooses one of the top k letters based on probabilities. Only selects letters with probability > 0.\"\"\"\n",
    "    sorted_indices = np.argsort(predictions)[::-1]  # Sort descending\n",
    "    # Filter out indices where the probability is > 0\n",
    "    valid_indices = [idx for idx in sorted_indices if predictions[idx] > 0]\n",
    "    # Adjust k if there are fewer than k valid options\n",
    "    k = min(k, len(valid_indices))\n",
    "    if k == 0:\n",
    "        print(\"No valid letters with probability > 0.\")\n",
    "        # Return random letter if no valid letter found (except 0)\n",
    "        letter = 0\n",
    "        while letter == 0:\n",
    "            letter = np.random.choice(len(predictions))\n",
    "        return letter\n",
    "\n",
    "    # Select the top k valid indices\n",
    "    best_k_indices = valid_indices[:k]\n",
    "    \n",
    "    # Choose one of the top k at random (or return the best if k=1)\n",
    "    if k > 1:\n",
    "        chosen_index = np.random.choice(best_k_indices)\n",
    "    else:\n",
    "        chosen_index = best_k_indices[-1]\n",
    "    \n",
    "    return chosen_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function to generate one new name only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(model: \"Model\", char_to_index: dict, index_to_char: dict, sequence_length: int, max_length: int = 20, k: int = 5) -> str:\n",
    "    name = [0]  # start token ('0')\n",
    "    while len(name) < max_length:\n",
    "        seq_in = add_padding_to_seq(name, sequence_length)\n",
    "        prediction = model.predict(np.array([seq_in]), verbose=0)\n",
    "        next_index = choose_top_k_letters_from_model(prediction[0], k)\n",
    "        if next_index == 1:  # end token ('1')\n",
    "            break\n",
    "        name.append(next_index)\n",
    "    return ''.join([index_to_char[idx] for idx in name[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to generates multiple names at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_names(model: \"Model\", char_to_index: dict, index_to_char: dict, sequence_length: int, n: int, k: int = 5) -> list[str]:\n",
    "    names = []\n",
    "    for _ in range(n):\n",
    "        name = generate_name(model, char_to_index=char_to_index, index_to_char=index_to_char, sequence_length=sequence_length, k=k)\n",
    "        names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`k`(temperature) = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['siarontentongadisus', 'sauiclaloscoidolove', 'albisprostyiamisabh', 'panplicomumiora', 'pangongonykur']\n"
     ]
    }
   ],
   "source": [
    "names = generate_n_names(lstm_model, char_to_index=char_to_index, index_to_char=index_to_char, sequence_length=max_word_length, n=5, k=3)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`k`= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['siamodrator', 'saltrisomimoigery', 'antaltacidaxauropst', 'sanjunx', 'saltrisapra']\n"
     ]
    }
   ],
   "source": [
    "names = generate_n_names(lstm_model, char_to_index=char_to_index, index_to_char=index_to_char, sequence_length=max_word_length, n=5, k=2)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`k`= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saldsplrrug', 'ariyopithnunikr', 'pideiragongevantoli', 'anopslumemovenaturu', 'crupzognig']\n"
     ]
    }
   ],
   "source": [
    "names = generate_n_names(lstm_model, char_to_index=char_to_index, index_to_char=index_to_char, sequence_length=max_word_length, n=5, k=6)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple of an output for `k=6`: `['conguionniodavithya', 'chesallientapatotho', 'priantaleor', 'stocusudhaleus', 'ausarodynnimiegitol']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) *N-gram* based LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results on previous model were acceptable, even good sometimes. But let's try another approach.\n",
    "\n",
    "The vocabulary will contains usuall letters, and in addition, the *n-gram token*. tokens may help to identify patterns and enhance the prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did for previous models, we define in this subsection usefull functions to train, and generate dino names with the new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we bring the modification in teh vocabulary I talked about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_tokens(names: list[str], n: int) -> list[str]:\n",
    "    tokens = [\"<UNK>\", \"0\", \"1\"]  # Add the <UNK> token and padding character '1' at the beginning\n",
    "\n",
    "    def get_letters_in_name(names: list[str]) -> list[str]:\n",
    "        letters = []\n",
    "        for name in names :\n",
    "            for l in name :\n",
    "                if l not in letters:\n",
    "                    letters.append(l)\n",
    "        return letters\n",
    "    \n",
    "    tokens += get_letters_in_name(names)\n",
    "    for name in names:\n",
    "        for i in range(len(name) - n + 1):\n",
    "            token = name[i:i+n]\n",
    "            if token not in tokens:\n",
    "                tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds vocabulary and mappings for LSTM with specified n-gram tokens.\n",
    "def build_n_vocabulary_for_lstm(names: list[str], n: int = 1):\n",
    "    names = add_start_end_tokens(names, n)\n",
    "    tokens = list_all_tokens(names, n)\n",
    "    char_to_index = {char: idx for idx, char in enumerate(tokens)}\n",
    "    index_to_char = {idx: char for idx, char in enumerate(tokens)}\n",
    "    vocab_size = len(tokens)\n",
    "    return tokens, char_to_index, index_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds padding to make sequences of equal length.\n",
    "def add_padding(names: list[str], max_length: int) -> list[str]:\n",
    "    return [name.rjust(max_length, '1') for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(names: list[str], char_to_index: dict, sequence_length: int, ngram: int):\n",
    "    data_X, data_y = [], []\n",
    "    for name in names:\n",
    "        encoded_name = [char_to_index[char] for char in name]\n",
    "        for i in range(0, len(encoded_name) - ngram):\n",
    "            data_X.append(encoded_name[i:i+ngram])\n",
    "            data_y.append(encoded_name[i+ngram])  # Use only the next single token\n",
    "    data_X = np.array(data_X)\n",
    "    data_y = np.array(data_y)\n",
    "    print(f\"data_X shape: {data_X.shape}, data_y shape: {data_y.shape}\")\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a last function to that will call back the previous ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares training data for the LSTM.\n",
    "def prepare_n_training_data(names: list[str], ngram=4, max_length: int = 15):\n",
    "    names = add_start_end_tokens(names, n=ngram)\n",
    "    names = add_padding(names, max_length=max_length)\n",
    "    vocab, char_to_index, index_to_char, vocab_size = build_n_vocabulary_for_lstm(names, ngram)\n",
    "    data_X, data_y = encoding(names, char_to_index, sequence_length=max_length, ngram=ngram)\n",
    "    return data_X, data_y, vocab, char_to_index, index_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an LSTM model.\n",
    "def create_LSTM_model(vocab_size: int, sequence_length: int, embedding_size: int = 13, hidden_units: int = 128, dropout_rate: float = 0.2, show_summary: bool = False) -> Model:\n",
    "    inputs = Input(shape=(sequence_length,))\n",
    "    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_size)(inputs)\n",
    "    lstm = LSTM(hidden_units, return_sequences=False)(embedding)\n",
    "    dropout = Dropout(dropout_rate)(lstm)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(dropout)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the LSTM model.\n",
    "def training(model: Model, data_X: np.array, data_y: np.array, epochs: int = 100, batch_size: int = 32) -> Model:\n",
    "    data_X_train, data_X_val, data_y_train, data_y_val = train_test_split(data_X, data_y, test_size=0.2, random_state=42)\n",
    "    mycallback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(data_X_train, data_y_train, validation_data=(data_X_val, data_y_val), epochs=epochs, batch_size=batch_size, callbacks=[mycallback])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to generate new names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chooses one of the top k letters based on probabilities.\n",
    "def choose_top_k_letters_from_model(predictions: np.array, k: int = 5) -> int:\n",
    "    sorted_indices = np.argsort(predictions)[::-1]\n",
    "    valid_indices = [idx for idx in sorted_indices if predictions[idx] > 0]\n",
    "    k = min(k, len(valid_indices))\n",
    "    if k == 0:\n",
    "        return np.random.randint(1, len(predictions))\n",
    "    best_k_indices = valid_indices[:k]\n",
    "    return np.random.choice(best_k_indices) if k > 1 else best_k_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a single name using the trained LSTM model.\n",
    "def generate_name(model: \"Model\", char_to_index: dict, index_to_char: dict, max_length: int, ngram : int, k: int = 5) -> str:\n",
    "    # Start with the start token and a random letter\n",
    "    name = [0] + [np.random.randint(3, len(char_to_index))] # Exclude start token and markers tokens \"0\" and \"1\"\n",
    "    while len(name) < max_length:\n",
    "        seq_in = pad_sequences([name[-ngram:]], maxlen=ngram, padding='pre')  # Generate based on the last n tokens\n",
    "        prediction = model.predict(seq_in, verbose=0)\n",
    "        next_index = choose_top_k_letters_from_model(prediction[0], k)\n",
    "        next_letter = index_to_char[next_index]\n",
    "        if next_letter == '1':\n",
    "            break\n",
    "        name.append(next_index)\n",
    "    return ''.join([index_to_char[idx] for idx in name[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates multiple names using the trained LSTM model.\n",
    "def generate_names(model: \"Model\", char_to_index: dict, index_to_char: dict, max_length: int, ngram : int, n: int, k: int = 5) -> list[str]:\n",
    "    names = []\n",
    "    for _ in range(n):\n",
    "        name = generate_name(model, char_to_index=char_to_index, index_to_char=index_to_char, max_length=max_length, ngram=ngram, k=k)\n",
    "        names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of New Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create multiple *n-gram* based LSTM model. We will vary the parameter `ngram`for each model. So main difference between models will be their vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 1 - 2\n",
    "> ngram = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X shape: (36581, 2), data_y shape: (36581,)\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "data_X, data_y, vocab, char_to_index, index_to_char, vocab_size = prepare_n_training_data(data[\"dino_name\"], ngram=n, max_length=max_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">6,461</span> \n",
       "\n",
       " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">72,704</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">497</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">64,113</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " embedding (\u001b[38;5;33mEmbedding\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m13\u001b[0m)                   \u001b[38;5;34m6,461\u001b[0m \n",
       "\n",
       " lstm (\u001b[38;5;33mLSTM\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m72,704\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m497\u001b[0m)                    \u001b[38;5;34m64,113\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,278</span> (559.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m143,278\u001b[0m (559.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,278</span> (559.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m143,278\u001b[0m (559.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4461 - loss: 2.6560 - val_accuracy: 0.5591 - val_loss: 1.4846\n",
      "Epoch 2/5\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5882 - loss: 1.4409 - val_accuracy: 0.6104 - val_loss: 1.3594\n",
      "Epoch 3/5\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6194 - loss: 1.3266 - val_accuracy: 0.6233 - val_loss: 1.2823\n",
      "Epoch 4/5\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6306 - loss: 1.2735 - val_accuracy: 0.6344 - val_loss: 1.2376\n",
      "Epoch 5/5\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6309 - loss: 1.2477 - val_accuracy: 0.6477 - val_loss: 1.2070\n"
     ]
    }
   ],
   "source": [
    "lstm_model_2 = create_LSTM_model(vocab_size, sequence_length=n, show_summary=True)\n",
    "lstm_model_2 = training(lstm_model_2, data_X, data_y, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['suatar', 'ocantanonstrapanos', 'onataraptoraton', 'amonsanon', 'janton']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = generate_names(lstm_model_2, char_to_index=char_to_index, index_to_char=index_to_char, max_length=max_word_length, n=5, ngram=n, k=2)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jaianalis',\n",
       " 'ryonaltepstonstilelon',\n",
       " 'leetophosistelisolinuasaog',\n",
       " 'lntirastenodopthenachaltas',\n",
       " 'awortiatelongurantirothons']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = generate_names(lstm_model_2, char_to_index=char_to_index, index_to_char=index_to_char, max_length=max_word_length, n=5, ngram=n, k=5)\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 3-4\n",
    "> ngram = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X shape: (35061, 3), data_y shape: (35061,)\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "data_X, data_y, vocab, char_to_index, index_to_char, vocab_size = prepare_n_training_data(data[\"dino_name\"], ngram=n, max_length=max_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m877/877\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.3867 - loss: 3.0788 - val_accuracy: 0.5637 - val_loss: 1.5692\n",
      "Epoch 2/100\n",
      "\u001b[1m877/877\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.5528 - loss: 1.5491 - val_accuracy: 0.5851 - val_loss: 1.4285\n",
      "Epoch 3/100\n",
      "\u001b[1m877/877\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.5882 - loss: 1.4267 - val_accuracy: 0.6077 - val_loss: 1.3255\n",
      "Epoch 4/100\n",
      "\u001b[1m877/877\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.6084 - loss: 1.3222 - val_accuracy: 0.6150 - val_loss: 1.2914\n",
      "Epoch 5/100\n",
      "\u001b[1m877/877\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.6209 - loss: 1.2788 - val_accuracy: 0.6308 - val_loss: 1.2524\n",
      "Epoch 6/100\n",
      "\u001b[1m877/877\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.6286 - loss: 1.2529 - val_accuracy: 0.6355 - val_loss: 1.2299\n",
      "Epoch 7/100\n",
      "\u001b[1m877/877\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.6364 - loss: 1.2233 - val_accuracy: 0.6441 - val_loss: 1.2058\n",
      "Epoch 8/100\n",
      "\u001b[1m773/877\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6356 - loss: 1.2022"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lstm_model_3 \u001b[38;5;241m=\u001b[39m create_LSTM_model(vocab_size, sequence_length\u001b[38;5;241m=\u001b[39mn)\n\u001b[1;32m----> 2\u001b[0m lstm_model_3 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_model_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 5\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, data_X, data_y, epochs, batch_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m data_X_train, data_X_val, data_y_train, data_y_val \u001b[38;5;241m=\u001b[39m train_test_split(data_X, data_y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m mycallback \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_X_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_y_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmycallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\haddo\\.virtualenvs\\dino_name_generator-CGxwSDO1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_model_3 = create_LSTM_model(vocab_size, sequence_length=n)\n",
    "lstm_model_3 = training(lstm_model_3, data_X, data_y, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ustyctonychangjospedmeryp',\n",
       " 'uamon',\n",
       " 'onglospeng',\n",
       " 'onyclanathangarinodassusi',\n",
       " 'racericetegnestrintospeno']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = generate_names(lstm_model_3, char_to_index=char_to_index, index_to_char=index_to_char, max_length=max_word_length, n=5, ngram=n, k=3)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unategraspidilosplonycost',\n",
       " 'alangleirururson',\n",
       " 'ulodeiamperyaspleosuteste',\n",
       " 'shustassibonistonisarssib',\n",
       " 'ropsodreadociantodranosar']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = generate_names(lstm_model_3, char_to_index=char_to_index, index_to_char=index_to_char, max_length=max_word_length, n=5, ngram=n, k=5)\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 4\n",
    "> ngram = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n = 4\n",
    "data_X, data_y, vocab, char_to_index, index_to_char, vocab_size = prepare_n_training_data(data[\"dino_name\"], ngram=n, max_length=max_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_4 = create_LSTM_model(vocab_size, sequence_length=n)\n",
    "lstm_model_4 = training(lstm_model_3, data_X, data_y, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = generate_names(lstm_model_4, char_to_index=char_to_index, index_to_char=index_to_char, max_length=max_word_length, n=5, ngram=n, k=3)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = generate_names(lstm_model_4, char_to_index=char_to_index, index_to_char=index_to_char, max_length=max_word_length, n=5, ngram=n, k=5)\n",
    "names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino_name_generator-CGxwSDO1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
