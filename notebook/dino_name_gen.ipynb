{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Generator for Dinosaurs\n",
    "\n",
    "### @Author : HADDOU Amine\n",
    "\n",
    "The goal of this project is to developp different neural network models to generates new dinosaur names.<br>\n",
    "The objective is to developp the following two models : \n",
    "- n-grams model language\n",
    "- a pre-trained model (from hugginface) finetuned to the project goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data from `data/dinos.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/dinos.txt\", names=[\"dino_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachenosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aardonyx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abdallahsaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abelisaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abrictosaurus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dino_name\n",
       "0   Aachenosaurus\n",
       "1        Aardonyx\n",
       "2  Abdallahsaurus\n",
       "3     Abelisaurus\n",
       "4   Abrictosaurus"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an overview of the imported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1536 entries, 0 to 1535\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   dino_name  1536 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 12.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring 20 random rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>Indosuchus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Lametasaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>Rhabdodon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>Texacephale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>Siamodon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Alamosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abelisaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Anabisetia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Alocodon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>Triceratops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>Ingenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Loricatosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Chindesaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Leptorhynchos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>Pellegrinisaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>Scolosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>Krzyzanowskisaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Calamospondylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>Rugocaudia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Cryptodraco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dino_name\n",
       "654           Indosuchus\n",
       "742         Lametasaurus\n",
       "1146           Rhabdodon\n",
       "1357         Texacephale\n",
       "1235            Siamodon\n",
       "38           Alamosaurus\n",
       "3            Abelisaurus\n",
       "76            Anabisetia\n",
       "57              Alocodon\n",
       "1396         Triceratops\n",
       "655              Ingenia\n",
       "798       Loricatosaurus\n",
       "293         Chindesaurus\n",
       "763        Leptorhynchos\n",
       "1043    Pellegrinisaurus\n",
       "1206         Scolosaurus\n",
       "724   Krzyzanowskisaurus\n",
       "245      Calamospondylus\n",
       "1166          Rugocaudia\n",
       "345          Cryptodraco"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there punctuation (composed names, etc) ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No non-alphabetical characters found in the dataset\n"
     ]
    }
   ],
   "source": [
    "def print_non_alphabetical_chars(word):\n",
    "    non_alphabetical = [char for char in word if char.lower() not in \"abcdefghijklmnopqrstuvwxyz\"]\n",
    "    if non_alphabetical:\n",
    "        print(\"Non-alphabetical characters in '{}': {}\".format(word, ''.join(non_alphabetical)))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def print_non_alphabetical(data):\n",
    "    presence = False # flag to check if there are any non-alphabetical characters\n",
    "    for name in data[\"dino_name\"]:\n",
    "        if print_non_alphabetical_chars(name):\n",
    "            presence = True\n",
    "    if not presence:\n",
    "        print(\"No non-alphabetical characters found in the dataset\")\n",
    "\n",
    "print_non_alphabetical(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore words length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average length of dino names\n",
    "avg_word_length = data[\"dino_name\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max length of dino names\n",
    "max_word_length = data[\"dino_name\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min length of dino names\n",
    "min_word_length = data[\"dino_name\"].str.len().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile of dino names\n",
    "quantile = data[\"dino_name\"].str.len().quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique dino names\n",
    "unique_dino_names = data[\"dino_name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 11.962239583333334\n",
      "Max word length: 26\n",
      "Min word length: 3\n",
      "Quantiles : {25% : 10.0, 50% : 12.0, 75% : 13.0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average word length: {avg_word_length}\")\n",
    "print(f\"Max word length: {max_word_length}\")\n",
    "print(f\"Min word length: {min_word_length}\")\n",
    "print(f\"Quantiles : {{25% : {quantile[0.25]}, 50% : {quantile[0.5]}, 75% : {quantile[0.75]}}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are interesting. Dinosaur names are, in average, very long. So, if I want to generate a name, model has to take in account enough context from previous letters to generate remaining part.\n",
    "\n",
    "My first idea for the __n_gram model__ is to select `n_gram=3`. Because, I want to catch syllables in name. In my opinion, last syllables is enough context. It corresponds to the last 3 words before the word we want to predict.<br>\n",
    "In this context, a *syllable* is defined as a sequence of three characters, usually at least the middle one is a vowel.<br>\n",
    "It seems that using trigrams (3-grams) is a good choice since many words have lengths that are multiples of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Case Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should start with lower case all letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aachenosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardonyx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dino_name\n",
       "0  aachenosaurus\n",
       "1       aardonyx"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"dino_name\"] = data[\"dino_name\"].str.lower()\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding - Not needed for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add padding at the end of worlds to regularize names' length. We will try the `n-gram` model without padding.<br>\n",
    "Maybe by adding a padding, the model will be able to learn __how__ dino names finish usally (\"aurus\", \"tor\", etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(names: list[str], max_length: int) -> list[str]:\n",
    "    padded_names = []\n",
    "    for name in names :\n",
    "        if len(name) < max_length:\n",
    "            padded_names.append(name + \"0\" * (max_length - len(name)))\n",
    "        else:\n",
    "            padded_names.append(name)\n",
    "    return padded_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"paddded_dino_name\"] = add_padding(data[\"dino_name\"].values, max_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dino_name</th>\n",
       "      <th>paddded_dino_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aachenosaurus</td>\n",
       "      <td>aachenosaurus0000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardonyx</td>\n",
       "      <td>aardonyx000000000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dino_name           paddded_dino_name\n",
       "0  aachenosaurus  aachenosaurus0000000000000\n",
       "1       aardonyx  aardonyx000000000000000000"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start and End Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add `0` at the start and `1` at the end of names. The `0` will be usefull at the begenning of the generation to generate a first letter. For `k-gram`model, we will generate `k` `0` at the begenning to generate the first letter.\n",
    "\n",
    "For the `1`, it will help us determine when the generation is finished. And it may help the model in *learning* how dino names end (\"tor\", \"saurus\",etc).. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_end_tokens(names: list[str], n: int) -> list[str]:\n",
    "    \"\"\"Adds start '0' and end '1' tokens to each name.\"\"\"\n",
    "    return [\"0\" * n + name + \"1\" for name in names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a first function to generates a list of n-grams from a list of names at a **character** level.\n",
    "\n",
    "When building the vocabulary and tokens, we will add an `<UNK>` token that will be used for any unseen tokens or characters during generation. it is important because if the model produce a token which was not in the initial dataset, it won't be able to complete the generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_tokens(names: list[str], n: int) -> list[str]:\n",
    "    \"\"\"Generates and returns all unique n-grams from the names.\"\"\"\n",
    "    tokens = [\"<UNK>\"]  # Add the <UNK> token at the beginning\n",
    "    for name in names:\n",
    "        for i in range(len(name) - n + 1):\n",
    "            token = name[i:i+n]\n",
    "            if token not in tokens:\n",
    "                tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<UNK>', 'dino', 'inos', 'noso', 'osou', 'sour', 'ouru', 'urus']\n"
     ]
    }
   ],
   "source": [
    "print(list_all_tokens([\"dino\", \"dinosour\", \"dinosourus\"], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dertermining tokens of language, it is also necessary to determine our vocabulary. In our case, it is all the characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(names: list[str]) -> list[str]:\n",
    "    \"\"\"Builds and returns a list of all unique characters (vocabulary) from the names.\"\"\"\n",
    "    vocab = [\"<UNK>\"]  # Add the <UNK> token at the beginning\n",
    "    for name in names:\n",
    "        for letter in name:\n",
    "            if letter not in vocab:\n",
    "                vocab.append(letter)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute probability of a letter appearing after a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_probabilities(probabilities: np.ndarray, tokens: list[str], vocab: list[str]) -> None:\n",
    "    \"\"\"Prints the probabilities of generating each letter for each token.\"\"\"\n",
    "    for i, token in enumerate(tokens):\n",
    "        print(f\"Token: {token}\")\n",
    "        for j, letter in enumerate(vocab):\n",
    "            prob = probabilities[i][j]\n",
    "            if prob > 0:\n",
    "                print(f\"    {letter}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilities(names: list[str], tokens: list[str], vocab: list[str], n: int) -> np.ndarray:\n",
    "    \"\"\"Computes the conditional probabilities of each token generating a letter from the vocabulary.\"\"\"\n",
    "    probabilities_array = np.zeros((len(tokens), len(vocab)))\n",
    "\n",
    "    # Count occurrences of letters following each token\n",
    "    for name in names:\n",
    "        for i in range(len(name) - n):\n",
    "            token = name[i:i+n]\n",
    "            next_letter = name[i+n]  # The letter after the token\n",
    "            if next_letter in vocab:\n",
    "                token_index = tokens.index(token) if token in tokens else tokens.index(\"<UNK>\")\n",
    "                letter_index = vocab.index(next_letter)\n",
    "                probabilities_array[token_index][letter_index] += 1\n",
    "            else:\n",
    "                print(f\"Letter {next_letter} not in vocabulary\")\n",
    "                probabilities_array[tokens.index(\"<UNK>\")][vocab.index(\"<UNK>\")] += 1\n",
    "\n",
    "    # Normalize the probabilities by dividing by row sums\n",
    "    row_sums = probabilities_array.sum(axis=1, keepdims=True)\n",
    "    probabilities_array = np.divide(probabilities_array, row_sums, where=row_sums != 0, out=probabilities_array)\n",
    "\n",
    "    # print_probabilities(probabilities_array, tokens, vocab)\n",
    "    \n",
    "    return probabilities_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add some randomness and not generating alwas the same name, we will not retrieve the most predicted letter but one of the first k letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_top_k_letters(probabilities: np.array, token_index: int, vocab: list[str], k: int = 5, verbose: bool = False) -> str:\n",
    "    \"\"\"Chooses one of the top k letters based on probabilities. Only selects letters with probability > 0.\"\"\"\n",
    "    \n",
    "    # Sort the probabilities and get indices sorted by highest probability\n",
    "    sorted_indices = np.argsort(probabilities[token_index])[::-1]  # Sort descending\n",
    "    \n",
    "    # Filter out indices where the probability is > 0\n",
    "    valid_indices = [idx for idx in sorted_indices if probabilities[token_index][idx] > 0]\n",
    "\n",
    "    # Adjust k if there are fewer than k valid options\n",
    "    k = min(k, len(valid_indices))\n",
    "    \n",
    "    if k == 0:\n",
    "        # Handle the case where no valid options with prob > 0 exist, fallback to <UNK> or any default behavior\n",
    "        if verbose:\n",
    "            print(\"No valid letters with probability > 0. Falling back to <UNK>.\")\n",
    "        return \"<UNK>\"  # or any other fallback behavior you'd like\n",
    "\n",
    "    # Select the top k valid indices\n",
    "    best_k_indices = valid_indices[:k]\n",
    "    \n",
    "    # Log top k predicted letters\n",
    "    if verbose:\n",
    "        print(f\"\\nTop {k} predicted letters for token index {token_index}:\")\n",
    "        for idx in best_k_indices:\n",
    "            print(f\"Letter: {vocab[idx]}, Probability: {probabilities[token_index][idx]}\")\n",
    "\n",
    "    # Choose one of the top k at random (or return the best if k=1)\n",
    "    if k > 1:\n",
    "        chosen_index = np.random.choice(best_k_indices)\n",
    "    else:\n",
    "        chosen_index = best_k_indices[-1]\n",
    "    \n",
    "    chosen_letter = vocab[chosen_index]\n",
    "    if verbose:\n",
    "        print(f\"Chosen letter: {chosen_letter}\")\n",
    "    \n",
    "    return chosen_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we have all the tools to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_predict_new_name(tokens: list[str], vocab: list[str], probabilities: np.array, n: int, max_inter_count : int = 10, k: int = 5, verbose: bool = False) -> str:\n",
    "    \"\"\"Generates a new name using the n-gram model with <UNK> token handling.\"\"\"\n",
    "    generated_name = \"\"  # Start with an empty string\n",
    "    token = \"0\" * n  # Initial token is the start token\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nStarting name generation:\")\n",
    "    \n",
    "    inter_count = 0\n",
    "    while inter_count < max_inter_count:\n",
    "        # Handle unknown token by using <UNK> token\n",
    "        token_index = tokens.index(token) if token in tokens else tokens.index(\"<UNK>\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nCurrent token: {token}\")\n",
    "            print(f\"Name under construction: {generated_name}\")\n",
    "        \n",
    "        if token == \"0\" * n:  # Start token: choose any letter\n",
    "            next_letter = choose_top_k_letters(probabilities, token_index, vocab, k=len(vocab)-1, verbose=verbose)\n",
    "        else:\n",
    "            # Find the next letter using one of the top k probabilities\n",
    "            next_letter = choose_top_k_letters(probabilities, token_index, vocab, k=k, verbose=verbose)\n",
    "        \n",
    "        if next_letter == \"1\":  # End of name (using '1')\n",
    "            if verbose:\n",
    "                print(f\"End of name reached with letter: 1\\n\")\n",
    "            break\n",
    "        \n",
    "        generated_name += next_letter\n",
    "        token = (token + next_letter)[-n:]  # Shift the token by one letter, keeping it at length n\n",
    "        inter_count += 1\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Final generated name: {generated_name}\\n\")\n",
    "    return generated_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_model(names: list[str], n: int = 4, num_predictions: int = 5, max_length_output : int = 10, k: int = 5, verbose: bool = False) -> list[str]:\n",
    "    \"\"\"Trains an n-gram model and generates new names.\"\"\"\n",
    "    # Add start/end tokens to names and build model components\n",
    "    n = n - 1 # n-gram model uses n-1 letters to predict the new one. So I'll adjust n here. \n",
    "    names = add_start_end_tokens(names, n)\n",
    "    tokens = list_all_tokens(names, n)\n",
    "    vocab = build_vocabulary(names)\n",
    "    probabilities = compute_probabilities(names, tokens, vocab, n)\n",
    "    \n",
    "    # Generate new names based on the model\n",
    "    generated_names = []\n",
    "    for _ in range(num_predictions):\n",
    "        name = ngram_predict_new_name(tokens, vocab, probabilities, n, max_inter_count=max_length_output, k=k, verbose=verbose)\n",
    "        generated_names.append(name)\n",
    "    \n",
    "    return generated_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 000\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.10807291666666667\n",
      "Letter: s, Probability: 0.09505208333333333\n",
      "Letter: p, Probability: 0.08138020833333333\n",
      "Letter: c, Probability: 0.07096354166666667\n",
      "Letter: t, Probability: 0.064453125\n",
      "Letter: m, Probability: 0.059244791666666664\n",
      "Letter: l, Probability: 0.053385416666666664\n",
      "Letter: d, Probability: 0.052734375\n",
      "Letter: b, Probability: 0.048828125\n",
      "Letter: e, Probability: 0.042317708333333336\n",
      "Letter: h, Probability: 0.041666666666666664\n",
      "Letter: g, Probability: 0.039713541666666664\n",
      "Letter: n, Probability: 0.03125\n",
      "Letter: o, Probability: 0.026692708333333332\n",
      "Letter: r, Probability: 0.026041666666666668\n",
      "Letter: k, Probability: 0.026041666666666668\n",
      "Letter: j, Probability: 0.016927083333333332\n",
      "Letter: z, Probability: 0.016927083333333332\n",
      "Letter: i, Probability: 0.015625\n",
      "Letter: y, Probability: 0.015625\n",
      "Letter: v, Probability: 0.013671875\n",
      "Letter: f, Probability: 0.013671875\n",
      "Letter: u, Probability: 0.01171875\n",
      "Letter: w, Probability: 0.011067708333333334\n",
      "Letter: x, Probability: 0.010416666666666666\n",
      "Letter: q, Probability: 0.006510416666666667\n",
      "Chosen letter: p\n",
      "\n",
      "Current token: 00p\n",
      "Name under construction: p\n",
      "\n",
      "Top 5 predicted letters for token index 2206:\n",
      "Letter: a, Probability: 0.344\n",
      "Letter: r, Probability: 0.248\n",
      "Letter: e, Probability: 0.104\n",
      "Letter: o, Probability: 0.08\n",
      "Letter: l, Probability: 0.056\n",
      "Chosen letter: l\n",
      "\n",
      "Current token: 0pl\n",
      "Name under construction: pl\n",
      "\n",
      "Top 2 predicted letters for token index 2273:\n",
      "Letter: a, Probability: 0.5714285714285714\n",
      "Letter: e, Probability: 0.42857142857142855\n",
      "Chosen letter: e\n",
      "\n",
      "Current token: ple\n",
      "Name under construction: ple\n",
      "\n",
      "Top 3 predicted letters for token index 1168:\n",
      "Letter: u, Probability: 0.6\n",
      "Letter: s, Probability: 0.2\n",
      "Letter: t, Probability: 0.2\n",
      "Chosen letter: t\n",
      "\n",
      "Current token: let\n",
      "Name under construction: plet\n",
      "\n",
      "Top 1 predicted letters for token index 295:\n",
      "Letter: o, Probability: 1.0\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: eto\n",
      "Name under construction: pleto\n",
      "\n",
      "Top 3 predicted letters for token index 159:\n",
      "Letter: n, Probability: 0.5454545454545454\n",
      "Letter: s, Probability: 0.36363636363636365\n",
      "Letter: p, Probability: 0.09090909090909091\n",
      "Chosen letter: p\n",
      "\n",
      "Current token: top\n",
      "Name under construction: pletop\n",
      "\n",
      "Top 4 predicted letters for token index 207:\n",
      "Letter: s, Probability: 0.9066666666666666\n",
      "Letter: e, Probability: 0.04\n",
      "Letter: h, Probability: 0.02666666666666667\n",
      "Letter: u, Probability: 0.02666666666666667\n",
      "Chosen letter: e\n",
      "\n",
      "Current token: ope\n",
      "Name under construction: pletope\n",
      "\n",
      "Top 2 predicted letters for token index 296:\n",
      "Letter: l, Probability: 0.9333333333333333\n",
      "Letter: n, Probability: 0.06666666666666667\n",
      "Chosen letter: l\n",
      "\n",
      "Current token: pel\n",
      "Name under construction: pletopel\n",
      "\n",
      "Top 5 predicted letters for token index 225:\n",
      "Letter: t, Probability: 0.7407407407407407\n",
      "Letter: o, Probability: 0.1111111111111111\n",
      "Letter: i, Probability: 0.037037037037037035\n",
      "Letter: y, Probability: 0.037037037037037035\n",
      "Letter: l, Probability: 0.037037037037037035\n",
      "Chosen letter: t\n",
      "\n",
      "Current token: elt\n",
      "Name under construction: pletopelt\n",
      "\n",
      "Top 3 predicted letters for token index 226:\n",
      "Letter: a, Probability: 0.8181818181818182\n",
      "Letter: o, Probability: 0.13636363636363635\n",
      "Letter: u, Probability: 0.045454545454545456\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: lta\n",
      "Name under construction: pletopelta\n",
      "\n",
      "Top 3 predicted letters for token index 227:\n",
      "Letter: 1, Probability: 0.8947368421052632\n",
      "Letter: d, Probability: 0.05263157894736842\n",
      "Letter: s, Probability: 0.05263157894736842\n",
      "Chosen letter: 1\n",
      "End of name reached with letter: 1\n",
      "\n",
      "Final generated name: pletopelta\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 000\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.10807291666666667\n",
      "Letter: s, Probability: 0.09505208333333333\n",
      "Letter: p, Probability: 0.08138020833333333\n",
      "Letter: c, Probability: 0.07096354166666667\n",
      "Letter: t, Probability: 0.064453125\n",
      "Letter: m, Probability: 0.059244791666666664\n",
      "Letter: l, Probability: 0.053385416666666664\n",
      "Letter: d, Probability: 0.052734375\n",
      "Letter: b, Probability: 0.048828125\n",
      "Letter: e, Probability: 0.042317708333333336\n",
      "Letter: h, Probability: 0.041666666666666664\n",
      "Letter: g, Probability: 0.039713541666666664\n",
      "Letter: n, Probability: 0.03125\n",
      "Letter: o, Probability: 0.026692708333333332\n",
      "Letter: r, Probability: 0.026041666666666668\n",
      "Letter: k, Probability: 0.026041666666666668\n",
      "Letter: j, Probability: 0.016927083333333332\n",
      "Letter: z, Probability: 0.016927083333333332\n",
      "Letter: i, Probability: 0.015625\n",
      "Letter: y, Probability: 0.015625\n",
      "Letter: v, Probability: 0.013671875\n",
      "Letter: f, Probability: 0.013671875\n",
      "Letter: u, Probability: 0.01171875\n",
      "Letter: w, Probability: 0.011067708333333334\n",
      "Letter: x, Probability: 0.010416666666666666\n",
      "Letter: q, Probability: 0.006510416666666667\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: 00a\n",
      "Name under construction: a\n",
      "\n",
      "Top 5 predicted letters for token index 2:\n",
      "Letter: n, Probability: 0.1566265060240964\n",
      "Letter: l, Probability: 0.15060240963855423\n",
      "Letter: r, Probability: 0.13855421686746988\n",
      "Letter: m, Probability: 0.0783132530120482\n",
      "Letter: u, Probability: 0.07228915662650602\n",
      "Chosen letter: m\n",
      "\n",
      "Current token: 0am\n",
      "Name under construction: am\n",
      "\n",
      "Top 5 predicted letters for token index 356:\n",
      "Letter: p, Probability: 0.3076923076923077\n",
      "Letter: a, Probability: 0.3076923076923077\n",
      "Letter: t, Probability: 0.15384615384615385\n",
      "Letter: y, Probability: 0.07692307692307693\n",
      "Letter: m, Probability: 0.07692307692307693\n",
      "Chosen letter: y\n",
      "\n",
      "Current token: amy\n",
      "Name under construction: amy\n",
      "\n",
      "Top 1 predicted letters for token index 399:\n",
      "Letter: g, Probability: 1.0\n",
      "Chosen letter: g\n",
      "\n",
      "Current token: myg\n",
      "Name under construction: amyg\n",
      "\n",
      "Top 1 predicted letters for token index 400:\n",
      "Letter: d, Probability: 1.0\n",
      "Chosen letter: d\n",
      "\n",
      "Current token: ygd\n",
      "Name under construction: amygd\n",
      "\n",
      "Top 1 predicted letters for token index 401:\n",
      "Letter: a, Probability: 1.0\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: gda\n",
      "Name under construction: amygda\n",
      "\n",
      "Top 1 predicted letters for token index 402:\n",
      "Letter: l, Probability: 1.0\n",
      "Chosen letter: l\n",
      "\n",
      "Current token: dal\n",
      "Name under construction: amygdal\n",
      "\n",
      "Top 3 predicted letters for token index 26:\n",
      "Letter: i, Probability: 0.3333333333333333\n",
      "Letter: l, Probability: 0.3333333333333333\n",
      "Letter: o, Probability: 0.3333333333333333\n",
      "Chosen letter: l\n",
      "\n",
      "Current token: all\n",
      "Name under construction: amygdall\n",
      "\n",
      "Top 3 predicted letters for token index 27:\n",
      "Letter: o, Probability: 0.5\n",
      "Letter: i, Probability: 0.375\n",
      "Letter: a, Probability: 0.125\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: lla\n",
      "Name under construction: amygdalla\n",
      "\n",
      "Top 4 predicted letters for token index 28:\n",
      "Letter: s, Probability: 0.5714285714285714\n",
      "Letter: h, Probability: 0.14285714285714285\n",
      "Letter: c, Probability: 0.14285714285714285\n",
      "Letter: d, Probability: 0.14285714285714285\n",
      "Chosen letter: h\n",
      "\n",
      "Current token: lah\n",
      "Name under construction: amygdallah\n",
      "\n",
      "Top 1 predicted letters for token index 29:\n",
      "Letter: s, Probability: 1.0\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: ahs\n",
      "Name under construction: amygdallahs\n",
      "\n",
      "Top 2 predicted letters for token index 30:\n",
      "Letter: a, Probability: 0.6666666666666666\n",
      "Letter: h, Probability: 0.3333333333333333\n",
      "Chosen letter: h\n",
      "\n",
      "Current token: hsh\n",
      "Name under construction: amygdallahsh\n",
      "\n",
      "Top 1 predicted letters for token index 218:\n",
      "Letter: i, Probability: 1.0\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: shi\n",
      "Name under construction: amygdallahshi\n",
      "\n",
      "Top 5 predicted letters for token index 219:\n",
      "Letter: s, Probability: 0.42857142857142855\n",
      "Letter: d, Probability: 0.14285714285714285\n",
      "Letter: u, Probability: 0.14285714285714285\n",
      "Letter: x, Probability: 0.14285714285714285\n",
      "Letter: n, Probability: 0.14285714285714285\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: his\n",
      "Name under construction: amygdallahshis\n",
      "\n",
      "Top 4 predicted letters for token index 220:\n",
      "Letter: a, Probability: 0.7894736842105263\n",
      "Letter: t, Probability: 0.10526315789473684\n",
      "Letter: l, Probability: 0.05263157894736842\n",
      "Letter: 1, Probability: 0.05263157894736842\n",
      "Chosen letter: t\n",
      "\n",
      "Current token: ist\n",
      "Name under construction: amygdallahshist\n",
      "\n",
      "Top 5 predicted letters for token index 89:\n",
      "Letter: a, Probability: 0.3\n",
      "Letter: o, Probability: 0.3\n",
      "Letter: r, Probability: 0.2\n",
      "Letter: h, Probability: 0.1\n",
      "Letter: i, Probability: 0.1\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: sti\n",
      "Name under construction: amygdallahshisti\n",
      "\n",
      "Top 3 predicted letters for token index 212:\n",
      "Letter: a, Probability: 0.5\n",
      "Letter: s, Probability: 0.25\n",
      "Letter: n, Probability: 0.25\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: tin\n",
      "Name under construction: amygdallahshistin\n",
      "\n",
      "Top 3 predicted letters for token index 213:\n",
      "Letter: o, Probability: 0.5\n",
      "Letter: a, Probability: 0.25\n",
      "Letter: i, Probability: 0.25\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: ini\n",
      "Name under construction: amygdallahshistini\n",
      "\n",
      "Top 5 predicted letters for token index 214:\n",
      "Letter: s, Probability: 0.375\n",
      "Letter: o, Probability: 0.125\n",
      "Letter: n, Probability: 0.125\n",
      "Letter: r, Probability: 0.125\n",
      "Letter: z, Probability: 0.125\n",
      "Chosen letter: z\n",
      "\n",
      "Current token: niz\n",
      "Name under construction: amygdallahshistiniz\n",
      "\n",
      "Top 1 predicted letters for token index 1036:\n",
      "Letter: a, Probability: 1.0\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: iza\n",
      "Name under construction: amygdallahshistiniza\n",
      "\n",
      "Top 1 predicted letters for token index 1037:\n",
      "Letter: s, Probability: 1.0\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: zas\n",
      "Name under construction: amygdallahshistinizas\n",
      "\n",
      "Top 1 predicted letters for token index 1038:\n",
      "Letter: a, Probability: 1.0\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: asa\n",
      "Name under construction: amygdallahshistinizasa\n",
      "\n",
      "Top 3 predicted letters for token index 114:\n",
      "Letter: u, Probability: 0.9813084112149533\n",
      "Letter: s, Probability: 0.009345794392523364\n",
      "Letter: z, Probability: 0.009345794392523364\n",
      "Chosen letter: z\n",
      "\n",
      "Current token: saz\n",
      "Name under construction: amygdallahshistinizasaz\n",
      "\n",
      "Top 1 predicted letters for token index 412:\n",
      "Letter: i, Probability: 1.0\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: azi\n",
      "Name under construction: amygdallahshistinizasazi\n",
      "\n",
      "Top 1 predicted letters for token index 413:\n",
      "Letter: s, Probability: 1.0\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: zis\n",
      "Name under construction: amygdallahshistinizasazis\n",
      "\n",
      "Top 1 predicted letters for token index 414:\n",
      "Letter: a, Probability: 1.0\n",
      "Chosen letter: a\n",
      "Final generated name: amygdallahshistinizasazisa\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 000\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.10807291666666667\n",
      "Letter: s, Probability: 0.09505208333333333\n",
      "Letter: p, Probability: 0.08138020833333333\n",
      "Letter: c, Probability: 0.07096354166666667\n",
      "Letter: t, Probability: 0.064453125\n",
      "Letter: m, Probability: 0.059244791666666664\n",
      "Letter: l, Probability: 0.053385416666666664\n",
      "Letter: d, Probability: 0.052734375\n",
      "Letter: b, Probability: 0.048828125\n",
      "Letter: e, Probability: 0.042317708333333336\n",
      "Letter: h, Probability: 0.041666666666666664\n",
      "Letter: g, Probability: 0.039713541666666664\n",
      "Letter: n, Probability: 0.03125\n",
      "Letter: o, Probability: 0.026692708333333332\n",
      "Letter: r, Probability: 0.026041666666666668\n",
      "Letter: k, Probability: 0.026041666666666668\n",
      "Letter: j, Probability: 0.016927083333333332\n",
      "Letter: z, Probability: 0.016927083333333332\n",
      "Letter: i, Probability: 0.015625\n",
      "Letter: y, Probability: 0.015625\n",
      "Letter: v, Probability: 0.013671875\n",
      "Letter: f, Probability: 0.013671875\n",
      "Letter: u, Probability: 0.01171875\n",
      "Letter: w, Probability: 0.011067708333333334\n",
      "Letter: x, Probability: 0.010416666666666666\n",
      "Letter: q, Probability: 0.006510416666666667\n",
      "Chosen letter: v\n",
      "\n",
      "Current token: 00v\n",
      "Name under construction: v\n",
      "\n",
      "Top 5 predicted letters for token index 2646:\n",
      "Letter: e, Probability: 0.47619047619047616\n",
      "Letter: a, Probability: 0.23809523809523808\n",
      "Letter: i, Probability: 0.14285714285714285\n",
      "Letter: o, Probability: 0.09523809523809523\n",
      "Letter: u, Probability: 0.047619047619047616\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: 0vi\n",
      "Name under construction: vi\n",
      "\n",
      "Top 2 predicted letters for token index 2660:\n",
      "Letter: t, Probability: 0.6666666666666666\n",
      "Letter: a, Probability: 0.3333333333333333\n",
      "Chosen letter: t\n",
      "\n",
      "Current token: vit\n",
      "Name under construction: vit\n",
      "\n",
      "Top 2 predicted letters for token index 1548:\n",
      "Letter: a, Probability: 0.6666666666666666\n",
      "Letter: h, Probability: 0.3333333333333333\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: ita\n",
      "Name under construction: vita\n",
      "\n",
      "Top 5 predicted letters for token index 368:\n",
      "Letter: n, Probability: 0.8333333333333334\n",
      "Letter: d, Probability: 0.041666666666666664\n",
      "Letter: k, Probability: 0.041666666666666664\n",
      "Letter: t, Probability: 0.020833333333333332\n",
      "Letter: l, Probability: 0.020833333333333332\n",
      "Chosen letter: l\n",
      "\n",
      "Current token: tal\n",
      "Name under construction: vital\n",
      "\n",
      "Top 5 predicted letters for token index 918:\n",
      "Letter: o, Probability: 0.375\n",
      "Letter: i, Probability: 0.25\n",
      "Letter: a, Probability: 0.125\n",
      "Letter: s, Probability: 0.125\n",
      "Letter: e, Probability: 0.125\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: alo\n",
      "Name under construction: vitalo\n",
      "\n",
      "Top 5 predicted letters for token index 265:\n",
      "Letter: s, Probability: 0.28\n",
      "Letter: d, Probability: 0.16\n",
      "Letter: n, Probability: 0.16\n",
      "Letter: c, Probability: 0.12\n",
      "Letter: t, Probability: 0.08\n",
      "Chosen letter: d\n",
      "\n",
      "Current token: lod\n",
      "Name under construction: vitalod\n",
      "\n",
      "Top 1 predicted letters for token index 403:\n",
      "Letter: o, Probability: 1.0\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: odo\n",
      "Name under construction: vitalodo\n",
      "\n",
      "Top 4 predicted letters for token index 324:\n",
      "Letter: n, Probability: 0.8863636363636364\n",
      "Letter: s, Probability: 0.056818181818181816\n",
      "Letter: c, Probability: 0.045454545454545456\n",
      "Letter: k, Probability: 0.011363636363636364\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: don\n",
      "Name under construction: vitalodon\n",
      "\n",
      "Top 5 predicted letters for token index 19:\n",
      "Letter: 1, Probability: 0.7777777777777778\n",
      "Letter: t, Probability: 0.13333333333333333\n",
      "Letter: g, Probability: 0.044444444444444446\n",
      "Letter: i, Probability: 0.022222222222222223\n",
      "Letter: d, Probability: 0.011111111111111112\n",
      "Chosen letter: t\n",
      "\n",
      "Current token: ont\n",
      "Name under construction: vitalodont\n",
      "\n",
      "Top 2 predicted letters for token index 471:\n",
      "Letter: o, Probability: 0.9\n",
      "Letter: a, Probability: 0.1\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: nta\n",
      "Name under construction: vitalodonta\n",
      "\n",
      "Top 5 predicted letters for token index 457:\n",
      "Letter: s, Probability: 0.26666666666666666\n",
      "Letter: r, Probability: 0.26666666666666666\n",
      "Letter: n, Probability: 0.13333333333333333\n",
      "Letter: i, Probability: 0.06666666666666667\n",
      "Letter: v, Probability: 0.06666666666666667\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: tas\n",
      "Name under construction: vitalodontas\n",
      "\n",
      "Top 4 predicted letters for token index 761:\n",
      "Letter: a, Probability: 0.7333333333333333\n",
      "Letter: t, Probability: 0.13333333333333333\n",
      "Letter: u, Probability: 0.06666666666666667\n",
      "Letter: s, Probability: 0.06666666666666667\n",
      "Chosen letter: u\n",
      "\n",
      "Current token: asu\n",
      "Name under construction: vitalodontasu\n",
      "\n",
      "Top 4 predicted letters for token index 710:\n",
      "Letter: c, Probability: 0.4444444444444444\n",
      "Letter: s, Probability: 0.2222222222222222\n",
      "Letter: t, Probability: 0.2222222222222222\n",
      "Letter: 1, Probability: 0.1111111111111111\n",
      "Chosen letter: t\n",
      "\n",
      "Current token: sut\n",
      "Name under construction: vitalodontasut\n",
      "\n",
      "Top 2 predicted letters for token index 711:\n",
      "Letter: o, Probability: 0.6666666666666666\n",
      "Letter: i, Probability: 0.3333333333333333\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: uti\n",
      "Name under construction: vitalodontasuti\n",
      "\n",
      "Top 3 predicted letters for token index 720:\n",
      "Letter: t, Probability: 0.6\n",
      "Letter: c, Probability: 0.2\n",
      "Letter: s, Probability: 0.2\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: tis\n",
      "Name under construction: vitalodontasutis\n",
      "\n",
      "Top 2 predicted letters for token index 112:\n",
      "Letter: a, Probability: 0.8333333333333334\n",
      "Letter: p, Probability: 0.16666666666666666\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: isa\n",
      "Name under construction: vitalodontasutisa\n",
      "\n",
      "Top 3 predicted letters for token index 36:\n",
      "Letter: u, Probability: 0.9473684210526315\n",
      "Letter: n, Probability: 0.039473684210526314\n",
      "Letter: b, Probability: 0.013157894736842105\n",
      "Chosen letter: b\n",
      "\n",
      "Current token: sab\n",
      "Name under construction: vitalodontasutisab\n",
      "\n",
      "Top 1 predicted letters for token index 1701:\n",
      "Letter: e, Probability: 1.0\n",
      "Chosen letter: e\n",
      "\n",
      "Current token: abe\n",
      "Name under construction: vitalodontasutisabe\n",
      "\n",
      "Top 3 predicted letters for token index 32:\n",
      "Letter: l, Probability: 0.5\n",
      "Letter: i, Probability: 0.25\n",
      "Letter: r, Probability: 0.25\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: ber\n",
      "Name under construction: vitalodontasutisaber\n",
      "\n",
      "Top 5 predicted letters for token index 267:\n",
      "Letter: t, Probability: 0.46153846153846156\n",
      "Letter: g, Probability: 0.15384615384615385\n",
      "Letter: o, Probability: 0.15384615384615385\n",
      "Letter: b, Probability: 0.07692307692307693\n",
      "Letter: a, Probability: 0.07692307692307693\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: era\n",
      "Name under construction: vitalodontasutisabera\n",
      "\n",
      "Top 5 predicted letters for token index 205:\n",
      "Letter: t, Probability: 0.891566265060241\n",
      "Letter: s, Probability: 0.060240963855421686\n",
      "Letter: p, Probability: 0.024096385542168676\n",
      "Letter: b, Probability: 0.012048192771084338\n",
      "Letter: n, Probability: 0.012048192771084338\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: ras\n",
      "Name under construction: vitalodontasutisaberas\n",
      "\n",
      "Top 5 predicted letters for token index 427:\n",
      "Letter: a, Probability: 0.6923076923076923\n",
      "Letter: i, Probability: 0.11538461538461539\n",
      "Letter: p, Probability: 0.038461538461538464\n",
      "Letter: u, Probability: 0.038461538461538464\n",
      "Letter: 1, Probability: 0.038461538461538464\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: asa\n",
      "Name under construction: vitalodontasutisaberasa\n",
      "\n",
      "Top 3 predicted letters for token index 114:\n",
      "Letter: u, Probability: 0.9813084112149533\n",
      "Letter: s, Probability: 0.009345794392523364\n",
      "Letter: z, Probability: 0.009345794392523364\n",
      "Chosen letter: u\n",
      "\n",
      "Current token: sau\n",
      "Name under construction: vitalodontasutisaberasau\n",
      "\n",
      "Top 1 predicted letters for token index 11:\n",
      "Letter: r, Probability: 1.0\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: aur\n",
      "Name under construction: vitalodontasutisaberasaur\n",
      "\n",
      "Top 5 predicted letters for token index 12:\n",
      "Letter: u, Probability: 0.9424083769633508\n",
      "Letter: o, Probability: 0.0274869109947644\n",
      "Letter: a, Probability: 0.02225130890052356\n",
      "Letter: i, Probability: 0.006544502617801047\n",
      "Letter: 1, Probability: 0.0013089005235602095\n",
      "Chosen letter: a\n",
      "Final generated name: vitalodontasutisaberasaura\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 000\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.10807291666666667\n",
      "Letter: s, Probability: 0.09505208333333333\n",
      "Letter: p, Probability: 0.08138020833333333\n",
      "Letter: c, Probability: 0.07096354166666667\n",
      "Letter: t, Probability: 0.064453125\n",
      "Letter: m, Probability: 0.059244791666666664\n",
      "Letter: l, Probability: 0.053385416666666664\n",
      "Letter: d, Probability: 0.052734375\n",
      "Letter: b, Probability: 0.048828125\n",
      "Letter: e, Probability: 0.042317708333333336\n",
      "Letter: h, Probability: 0.041666666666666664\n",
      "Letter: g, Probability: 0.039713541666666664\n",
      "Letter: n, Probability: 0.03125\n",
      "Letter: o, Probability: 0.026692708333333332\n",
      "Letter: r, Probability: 0.026041666666666668\n",
      "Letter: k, Probability: 0.026041666666666668\n",
      "Letter: j, Probability: 0.016927083333333332\n",
      "Letter: z, Probability: 0.016927083333333332\n",
      "Letter: i, Probability: 0.015625\n",
      "Letter: y, Probability: 0.015625\n",
      "Letter: v, Probability: 0.013671875\n",
      "Letter: f, Probability: 0.013671875\n",
      "Letter: u, Probability: 0.01171875\n",
      "Letter: w, Probability: 0.011067708333333334\n",
      "Letter: x, Probability: 0.010416666666666666\n",
      "Letter: q, Probability: 0.006510416666666667\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: 00s\n",
      "Name under construction: s\n",
      "\n",
      "Top 5 predicted letters for token index 1515:\n",
      "Letter: a, Probability: 0.2054794520547945\n",
      "Letter: i, Probability: 0.1917808219178082\n",
      "Letter: t, Probability: 0.136986301369863\n",
      "Letter: h, Probability: 0.1095890410958904\n",
      "Letter: e, Probability: 0.07534246575342465\n",
      "Chosen letter: h\n",
      "\n",
      "Current token: 0sh\n",
      "Name under construction: sh\n",
      "\n",
      "Top 4 predicted letters for token index 2443:\n",
      "Letter: a, Probability: 0.4375\n",
      "Letter: u, Probability: 0.3125\n",
      "Letter: i, Probability: 0.1875\n",
      "Letter: e, Probability: 0.0625\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: sha\n",
      "Name under construction: sha\n",
      "\n",
      "Top 5 predicted letters for token index 751:\n",
      "Letter: n, Probability: 0.7692307692307693\n",
      "Letter: d, Probability: 0.07692307692307693\n",
      "Letter: m, Probability: 0.07692307692307693\n",
      "Letter: k, Probability: 0.038461538461538464\n",
      "Letter: o, Probability: 0.038461538461538464\n",
      "Chosen letter: d\n",
      "\n",
      "Current token: had\n",
      "Name under construction: shad\n",
      "\n",
      "Top 3 predicted letters for token index 1331:\n",
      "Letter: r, Probability: 0.8\n",
      "Letter: e, Probability: 0.1\n",
      "Letter: i, Probability: 0.1\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: adi\n",
      "Name under construction: shadi\n",
      "\n",
      "Top 4 predicted letters for token index 1074:\n",
      "Letter: s, Probability: 0.4\n",
      "Letter: n, Probability: 0.2\n",
      "Letter: a, Probability: 0.2\n",
      "Letter: l, Probability: 0.2\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: dis\n",
      "Name under construction: shadis\n",
      "\n",
      "Top 1 predicted letters for token index 1075:\n",
      "Letter: a, Probability: 1.0\n",
      "Chosen letter: a\n",
      "\n",
      "Current token: isa\n",
      "Name under construction: shadisa\n",
      "\n",
      "Top 3 predicted letters for token index 36:\n",
      "Letter: u, Probability: 0.9473684210526315\n",
      "Letter: n, Probability: 0.039473684210526314\n",
      "Letter: b, Probability: 0.013157894736842105\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: san\n",
      "Name under construction: shadisan\n",
      "\n",
      "Top 5 predicted letters for token index 1625:\n",
      "Letter: o, Probability: 0.4\n",
      "Letter: p, Probability: 0.2\n",
      "Letter: g, Probability: 0.1\n",
      "Letter: j, Probability: 0.1\n",
      "Letter: t, Probability: 0.1\n",
      "Chosen letter: j\n",
      "\n",
      "Current token: anj\n",
      "Name under construction: shadisanj\n",
      "\n",
      "Top 3 predicted letters for token index 682:\n",
      "Letter: i, Probability: 0.6\n",
      "Letter: a, Probability: 0.2\n",
      "Letter: u, Probability: 0.2\n",
      "Chosen letter: i\n",
      "\n",
      "Current token: nji\n",
      "Name under construction: shadisanji\n",
      "\n",
      "Top 3 predicted letters for token index 683:\n",
      "Letter: a, Probability: 0.6\n",
      "Letter: 1, Probability: 0.2\n",
      "Letter: e, Probability: 0.2\n",
      "Chosen letter: 1\n",
      "End of name reached with letter: 1\n",
      "\n",
      "Final generated name: shadisanji\n",
      "\n",
      "\n",
      "Starting name generation:\n",
      "\n",
      "Current token: 000\n",
      "Name under construction: \n",
      "\n",
      "Top 26 predicted letters for token index 1:\n",
      "Letter: a, Probability: 0.10807291666666667\n",
      "Letter: s, Probability: 0.09505208333333333\n",
      "Letter: p, Probability: 0.08138020833333333\n",
      "Letter: c, Probability: 0.07096354166666667\n",
      "Letter: t, Probability: 0.064453125\n",
      "Letter: m, Probability: 0.059244791666666664\n",
      "Letter: l, Probability: 0.053385416666666664\n",
      "Letter: d, Probability: 0.052734375\n",
      "Letter: b, Probability: 0.048828125\n",
      "Letter: e, Probability: 0.042317708333333336\n",
      "Letter: h, Probability: 0.041666666666666664\n",
      "Letter: g, Probability: 0.039713541666666664\n",
      "Letter: n, Probability: 0.03125\n",
      "Letter: o, Probability: 0.026692708333333332\n",
      "Letter: r, Probability: 0.026041666666666668\n",
      "Letter: k, Probability: 0.026041666666666668\n",
      "Letter: j, Probability: 0.016927083333333332\n",
      "Letter: z, Probability: 0.016927083333333332\n",
      "Letter: i, Probability: 0.015625\n",
      "Letter: y, Probability: 0.015625\n",
      "Letter: v, Probability: 0.013671875\n",
      "Letter: f, Probability: 0.013671875\n",
      "Letter: u, Probability: 0.01171875\n",
      "Letter: w, Probability: 0.011067708333333334\n",
      "Letter: x, Probability: 0.010416666666666666\n",
      "Letter: q, Probability: 0.006510416666666667\n",
      "Chosen letter: c\n",
      "\n",
      "Current token: 00c\n",
      "Name under construction: c\n",
      "\n",
      "Top 5 predicted letters for token index 896:\n",
      "Letter: h, Probability: 0.26605504587155965\n",
      "Letter: a, Probability: 0.22935779816513763\n",
      "Letter: o, Probability: 0.1834862385321101\n",
      "Letter: r, Probability: 0.12844036697247707\n",
      "Letter: e, Probability: 0.10091743119266056\n",
      "Chosen letter: e\n",
      "\n",
      "Current token: 0ce\n",
      "Name under construction: ce\n",
      "\n",
      "Top 4 predicted letters for token index 935:\n",
      "Letter: r, Probability: 0.36363636363636365\n",
      "Letter: d, Probability: 0.2727272727272727\n",
      "Letter: n, Probability: 0.18181818181818182\n",
      "Letter: t, Probability: 0.18181818181818182\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: cer\n",
      "Name under construction: cer\n",
      "\n",
      "Top 5 predicted letters for token index 204:\n",
      "Letter: a, Probability: 0.9135802469135802\n",
      "Letter: o, Probability: 0.04938271604938271\n",
      "Letter: n, Probability: 0.012345679012345678\n",
      "Letter: c, Probability: 0.012345679012345678\n",
      "Letter: v, Probability: 0.012345679012345678\n",
      "Chosen letter: n\n",
      "\n",
      "Current token: ern\n",
      "Name under construction: cern\n",
      "\n",
      "Top 3 predicted letters for token index 965:\n",
      "Letter: b, Probability: 0.3333333333333333\n",
      "Letter: u, Probability: 0.3333333333333333\n",
      "Letter: o, Probability: 0.3333333333333333\n",
      "Chosen letter: u\n",
      "\n",
      "Current token: rnu\n",
      "Name under construction: cernu\n",
      "\n",
      "Top 1 predicted letters for token index 1929:\n",
      "Letter: s, Probability: 1.0\n",
      "Chosen letter: s\n",
      "\n",
      "Current token: nus\n",
      "Name under construction: cernus\n",
      "\n",
      "Top 3 predicted letters for token index 332:\n",
      "Letter: 1, Probability: 0.85\n",
      "Letter: a, Probability: 0.1\n",
      "Letter: o, Probability: 0.05\n",
      "Chosen letter: o\n",
      "\n",
      "Current token: uso\n",
      "Name under construction: cernuso\n",
      "\n",
      "Top 3 predicted letters for token index 1969:\n",
      "Letter: r, Probability: 0.5\n",
      "Letter: n, Probability: 0.25\n",
      "Letter: t, Probability: 0.25\n",
      "Chosen letter: r\n",
      "\n",
      "Current token: sor\n",
      "Name under construction: cernusor\n",
      "\n",
      "Top 4 predicted letters for token index 793:\n",
      "Letter: 1, Probability: 0.4444444444444444\n",
      "Letter: n, Probability: 0.2222222222222222\n",
      "Letter: i, Probability: 0.2222222222222222\n",
      "Letter: k, Probability: 0.1111111111111111\n",
      "Chosen letter: 1\n",
      "End of name reached with letter: 1\n",
      "\n",
      "Final generated name: cernusor\n",
      "\n",
      "['pletopelta', 'amygdallahshistinizasazisa', 'vitalodontasutisaberasaura', 'shadisanji', 'cernusor']\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 names with n=4, top 5 letters considered, and verbose logging enabled\n",
    "names = data[\"dino_name\"].values\n",
    "generated_names = ngram_model(names, n=4, max_length_output=max_word_length, num_predictions=5, k=5, verbose=True)\n",
    "\n",
    "print(generated_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of my generator with different parameters' values : \n",
    "-  `n = 3` and `k = 2`<br>\n",
    "['neoversosuccingshadros', 'bator', 'quilmayisaurutichodosuccin', 'dasylossus', 'inosphagros']\n",
    "-  `n = 3` and `k = 3`<br>\n",
    "['yungonius', 'elaplossuesiohadromaia', 'venescelusothostospinax', 'xingsauros', 'euskelyx']\n",
    "-  `n = 2` and `k = 3`<br>\n",
    "['heisaudasilis', 'kan', 'ale', 'xiasaustesaudiangobistrops', 'raptastriong']\n",
    "- `n = 4` and `k=3`<br>\n",
    "['unicerosaurophale', 'yurgovuchia', 'ischyrophus', 'ovirapterovenatosaurus', 'magnapartenykus']\n",
    "- `n = 4` and `k=5`<br>\n",
    "['cristatus', 'vouivria', 'yongjianosaurutitanius', 'mojoceratusauravusaurornit', 'epachthosuchomimoides']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like with a 4-gram model, we generate name that looks like real dino names. Even with a high randomness (k=5), results are still good.\n",
    "\n",
    "Even with the 3-gram model, the results are good (with low randomness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **n-gram model** is a type of probabilistic model used for generating sequences (in this case, names) by predicting the next element in a sequence based on the previous **n-1** elements. The model learns the probability distribution of letters following specific **n-grams** (substrings of length `n`) from a training dataset.\n",
    "\n",
    "This implementation generates new names one letter at a time using the learned probability distribution from the training data. The generated name is built step by step by predicting the next letter based on the preceding **n-1** letters.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Components and Parameters\n",
    "\n",
    "#### 1. **`n` (N-gram size)**\n",
    "- Defines the length of the n-grams. \n",
    "- **Example**: If `n=3`, the model will use 2 previous letters to predict the next one (trigram).\n",
    "\n",
    "#### 2. **`list_all_tokens(names, n)`**\n",
    "- **Description**: Generates all unique n-grams from the names and adds a special `<UNK>` token for unknown or unseen tokens.\n",
    "\n",
    "#### 3. **`build_vocabulary(names)`**\n",
    "- **Description**: Builds a vocabulary of all unique letters (characters) in the training data, including the `<UNK>` token.\n",
    "\n",
    "#### 4. **`compute_probabilities(names, tokens, vocab, n)`**\n",
    "- **Description**: Computes the conditional probabilities of generating a letter from the vocabulary based on the preceding n-gram (token). These probabilities are used during name generation.\n",
    "- **Impact**: Determines how likely certain letters are to follow particular n-grams. This affects the diversity and realism of generated names.\n",
    "\n",
    "#### 5. **`choose_top_k_letters(probabilities, token_index, vocab, k)`**\n",
    "- **Description**: Selects the next letter from the top `k` most probable letters based on the learned probabilities.\n",
    "- **Parameters**:\n",
    "  - **`k`**: The number of top letters to consider when selecting the next letter. If `k > 1`, one letter is chosen randomly from the top `k`.\n",
    "  - When selecting the best `k`, if a selected letter has a probability of 0. It is __excluded__ and `k`is automatically decremented for this letter prediction.\n",
    "  - **Impact**: \n",
    "    - Higher `k` introduces more randomness (more variation).\n",
    "    - Lower `k` makes the model pick the highest probability letter, leading to more deterministic behavior.\n",
    "\n",
    "#### 6. **`ngram_predict_new_name(tokens, vocab, probabilities, n, max_inter_count, k)`**\n",
    "- **Description**: Generates a new name by predicting one letter at a time using the n-gram model.\n",
    "- **Parameters**:\n",
    "  - **`max_inter_count`**: The maximum length of the generated name (or maximum number of prediction steps).\n",
    "  - **`k`**: How many of the top predicted letters are considered for the next letter.\n",
    "\n",
    "#### 7. **`ngram_model(names, n, num_predictions, max_length_output, k, verbose)`**\n",
    "- **Description**: Trains the n-gram model and generates `num_predictions` new names.\n",
    "- **Parameters**:\n",
    "  - **`num_predictions`**: Number of new names to generate.\n",
    "  - **`max_length_output`**: Maximum number of characters in each generated name.\n",
    "  - **`verbose`**: Whether to print detailed logs of the name generation process.\n",
    "\n",
    "---\n",
    "\n",
    "### How the Model Works:\n",
    "1. **Training Phase**:\n",
    "   - The model processes the list of names to build the vocabulary and n-gram tokens.\n",
    "   - It calculates the probability of each letter occurring after each token based on the training data.\n",
    "   \n",
    "2. **Generation Phase**:\n",
    "   - The model generates new names by starting with a special start token (e.g., `\"000\"` for `n=4`).\n",
    "   - For each step, it uses the previous n-1 letters to predict the next letter.\n",
    "   - The next letter is chosen based on the learned probabilities, and the process continues until an end token (`\"1\"`) is generated or the name reaches the maximum length (`max_length_output`).\n",
    "\n",
    "---\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "```python\n",
    "# Example test data (dinosaur names)\n",
    "dino_names = [\"Tyrannosaurus\", \"Stegosaurus\", \"Triceratops\"]\n",
    "\n",
    "# Generate 5 names with n=4, maximum name length of 10, and top 3 letters considered\n",
    "generated_names = ngram_model(dino_names, n=4, num_predictions=5, max_length_output=10, k=3, verbose=True)\n",
    "\n",
    "print(generated_names)\n",
    "```\n",
    "\n",
    "This example generates 5 names with a trigram model, considers the top 3 letters at each step, and limits the names to 10 characters max."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino_name_generator-CGxwSDO1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
